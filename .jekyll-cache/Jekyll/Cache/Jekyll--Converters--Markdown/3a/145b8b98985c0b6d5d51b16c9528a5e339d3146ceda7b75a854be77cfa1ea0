I"3.<p>Continuando com a nossa <a href="/categorias/#machine-learning-learning-from-data">série de textos</a>, e agora falando sobre um assunto um pouco diferente do que vínhamos discutindo até então; vamos tratar do problema de <strong>sobreajuste</strong> (ou <em>overfitting</em>, do inglês $-$ como é mais conhecido). Veremos como a ideia de “ruído” (apresentada na <a href="/erro-e-ruido/">parte 07</a>) é causa direta desse tipo de fenômento e vamos, ainda, introduzir um novo conceito, o de “ruído determinístico”.</p>

<p><strong><em>Overfitting</em></strong> pode ser entendido como o fenômeno no qual um bom ajuste do modelo escolhido com dados pertencentes ao conjunto de trainamento NÃO se traduz em $E_{out}$ proporcionalmente pequeno; na verdade, o contrário pode acontecer: o erro fora da amostra pode aumentar conforme o erro dentro da amostra diminui.</p>

<p>Para conseguirmos enxergar o que definimos como <em>overfitting</em> acontecendo, considere o exercício a seguir.</p>

<p><strong>Exemplo:</strong> trabalhando com conjunto de dados em $1$ dimensão e ajustando modelos da classe de regressão polinomial (esse é só um nome diferente para uma regressão linear com uma transformação do tipo $x \mapsto (1, x, x^2, \cdots)$ para dados unidimensionais), vamos definir dois cenários:</p>

<ol>
  <li>A função alvo é um polinômio de ordem $10$ <strong>com</strong> ruído associado. Aqui, $\mathcal{D}$ contém 15 pontos.</li>
  <li>A função alvo é um polinômio de ordem $50$ <strong>sem</strong> ruído associado. Aqui, $\mathcal{D}$ também contém 15 pontos.</li>
</ol>

<p>A figura a seguir ilustra o que acabamos de descrever:</p>

<p><img src="sobreajuste_files/exemplo_inicial.png" alt="Ilustração do exemplo" />
<em>Figura 1 [fonte: “<a href="http://www.work.caltech.edu/textbook.html">Learning from Data</a>”] $-$ Ilustração do exemplo.</em></p>

<p>Agora suponha que, para lidar com essas funções alvo, vamos ajustar dois modelos de regressão: um de ordem $2$ e outro de ordem $10$.</p>

<p><img src="sobreajuste_files/dados_ajustados.png" alt="Modelos ajustados" />
<em>Figura 2 [fonte: “<a href="http://www.work.caltech.edu/textbook.html">Learning from Data</a>”] $-$ Modelos ajustados.</em></p>

<p>Em seguida, vamos ver como os erros ($E_{in}$ e $E_{out}$) se comportam para esses dois modelos ajustados. <strong>Observação:</strong> lembre-se de que, como ainda estamos trabalhando com modelos de regressão, a medida de erro mais utilizada é o “erro quadrático”, como vimos pela primeira vez na <a href="/modelo-de-regressao-linear/">parte 05</a>.</p>

<p><img src="sobreajuste_files/tabela_erros.png" alt="Tabela de erros" />
<em>Figura 3 [fonte: “<a href="http://www.work.caltech.edu/textbook.html">Learning from Data</a>”] $-$ Tabela de erros para todos os cenários considerados.</em></p>

<p>Vamos, primeiro, analisar a situação na qual a função alvo é um polinômio de grau $10$ <strong>com</strong> ruído. Nesse caso, note que o modelo mais simples (polinômio de grau $2$) teve erro fora da amostra ($E_{out}$) menor $-$ se comparado ao modelo ajustado com polinômio de grau $10$. Isso aconteceu porque, apesar de o conjunto de hipóteses $\mathcal{H}<em>{10}$ conter a função alvo (<strong>a menos do ruído</strong>), a quantidade de dados de treinamento não foi suficiente para permitir generalização; sendo assim, o modelo apenas “memorizou” $\mathcal{D}$ e, por isso, teve $E</em>{in}$ muito pequeno. Dizemos que, aqui, houve <strong>sobreajuste</strong>. Observe, por fim, que, contrário à ideia de que “mais informações” se traduz em um modelo melhor, vimos que um modelo mais simples apresentou erro fora da amostra (que, no final das contas, é o que importa) bem mais interessante.</p>

<p>Agora, vamos olhar para a situação onde a função alvo é um polinômio de grau $50$ <strong>sem</strong> ruído. Aqui, mais uma vez, o modelo mais complexo $-$ o polinômio de grau $10$ - teve erro dentro da amostra menor; porém, perdeu “muito feio” para o desempenho do modelo mais simples para $x \not\in \mathcal{D}$. Nesse caso, também houve <strong>sobreajuste</strong>. Entretanto, a razão aqui é outra: no primeiro cenário, onde existia ruído associado a $f$, o que aconteceu foi que o modelo com mais parâmetros incorporou $\epsilon$ como parte do que seria a função alvo (uma amostra muito maior preveniria esse comportamento); agora, nesse segundo cenário, não há ruído. Sendo assim, o que aconteceu? A resposta é que $f$ é muito mais complexa que os dois possíveis conjuntos de hipóteses ($\mathcal{H_2}$ e $\mathcal{H}<em>{10}$); dessa forma, o algoritmo $\mathcal{A}$ tenta usar $\mathcal{H}</em>{10}$ para  modelar uma função que ele não é capaz, e, por isso, acaba “memorizando” os dados ao invés de, de novo, “aprender”.</p>

<p>A ideia aqui é que o <em>overfitting</em> pode estar relacionado a, principalmente, duas coisas: o nível de ruído (que denotaremos por $\sigma^2$) e a complexidade da função alvo (que denotaremos por $Q_f$). Ao primeiro distúrbio, danos o nome de <strong><em>ruído estocástico</em></strong> (<strong>não há nada de novo aqui</strong>, estamos apenas utilizando um termo maior para falar do mesmo “ruído” que temos considerado até então); ao passo que, ao segundo, damos o nome de <strong><em>ruído determinístico</em></strong>. Em ambos os casos, $g \in \mathcal{H}$ perde o poder de generalização para dados fora da amostra.</p>

<p>Dito isso, podemos tentar estebeler uma <strong>medida de sobreajuste</strong>. Nesse sentido, defina:</p>

<script type="math/tex; mode=display">\begin{align}
\text{Medida de sobreajuste } (\mathcal{M}_s) = E_{out}(g_{10}) - E_{out}(g_{2}),
\end{align}</script>

<p>onde $g_{10}$ e $g_{2}$ podem ser substituídas pelas funções (do tipo: $g \in \mathcal{H}$) escolhidas pelo modelo mais complexo e pelo modelo mais simples, respectivamente.</p>

<p>Assim, se $\mathcal{M}_s$ for positivo, quer dizer que o modelo mais simples ganha (que, em outras palavras, é o mesmo que dizer que o modelo complexo generaliza mal dados fora de $\mathcal{D}$); e o inverso acontece no caso de $\mathcal{M}_s$ ser negativo. Perceba que essa medida é fundamentalmente de comparação.</p>

<p>A imagem a seguir apresenta o resultado de um processo de simulação que estuda essas quantidades. A explicação do procedimento vem imediatamente abaixo.</p>

<p><img src="sobreajuste_files/heat_map.png" alt="Simulação para a quantidade &quot;medida de sobreajuste&quot;" />
<em>Figura 4 [fonte: “<a href="http://www.work.caltech.edu/textbook.html">Learning from Data</a>”] $-$ Simulação para a quantidade “$E_{out}(g_{10}) - E_{out}(g_{2})$”.</em></p>

<p>No mapa de calor da esquerda, vemos como a medida de sobreajuste (definida pela cor) depende de $\sigma^2$ e do tamanho da amostra (com $Q_f = 20$ fixo). Perceba que, nesse caso, se o ruído estocástico aumenta e o $N$ é pequeno, modelos mais complexos (nesse caso, $\mathcal{H}_{10}$) tem desempenho ruim; entretanto, se o tamanho da amostra aumenta, esse efeito é corrigido.</p>

<p>Já no mapa de calor da direita, é possível enxergar como a medida de sobreajuste depende da complexidade da função alvo e, mais uma vez, do tamanho da amostra (com $\sigma^2 = 0.1$ fixo). Note que, quando $Q_f &gt; 10$, a classe de modelos polinomiais de ordem $10$ começa a perder capacidade de aprendizado, abrindo espaço para que o modelo mais simples tenha melhor desempenho no que se diz respeito a $E_{out}$. Isso, de novo, é corrigido com o aumento do tamanho da amostra.</p>

<p>Aqui, é possível perceber o porquê do “ruído determinístico” receber esse nome. Quando a classe de modelos passa a não ser capaz mais de representar adequadamente a função alvo, a porção de dados não explicada pelo modelo é tratada como uma espécie de ruído.</p>

<h3 id="overfitting-e-o-trade-off-entre-viés-e-variância"><em>Overfitting</em> e o <em>trade-off</em> entre viés e variância</h3>

<p>Antes de finalizarmos, vamos ver como a questão do “<em>trade-off</em> entre viés e variância” se relaciona com as quantidades que acabamos de estudar. Relembrando o que foi apresentado na <a href="/vies-variancia-tradeoff/">parte 10</a>, podemos decompor o valor esperado do erro fora da amostra em duas componentes: viés e variância. A equação a seguir representa essa relação:</p>

<p><script type="math/tex">\begin{align*}
\mathbb{E}_{\mathcal{D}}\left[E_{out}(g^{(\mathcal{D})})\right] = \text{Var} + \text{Viés},
\end{align*}</script>
onde $\text{Viés} = \mathbb{E}<em>{\mathbf{x}}(\bar{g}(\mathbf{x}) - f(\mathbf{x}))^2$ e que $\text{Var} = \mathbb{E}</em>{\mathcal{D},\mathbf{x}}\left[( g^{(\mathcal{D})}(\mathbf{x}) - \bar{g}(\mathbf{x}))^2\right]$.</p>

<p>Lembre-se, porém, de que na equação acima, <strong>não</strong> consideramos que existia ruído. Alternativamente, se agora dissermos que $y = f(x) + \epsilon$ (tal que $\mathbb{E}(\epsilon) = 0$ e $\mathbb{V}(\epsilon) = \sigma^2$), então, de maneira análoga, podemos deduzir que</p>

<p><script type="math/tex">\begin{align*}
\mathbb{E}_{\mathcal{D}, \epsilon}\left[E_{out}(g^{(\mathcal{D})})\right] = \text{Var} + \text{Viés} + \sigma^2,
\end{align*}</script>
com $\sigma^2 = \mathbf{E}_{\epsilon,\mathbf{x}}\left[(\epsilon(\mathbf{x}))^2\right]$.</p>

<p>Da equação acima, perceba que o $\text{Viés} = \mathbb{E}<em>{\mathbf{x}}(\bar{g}(\mathbf{x}) - f(\mathbf{x}))^2$ pode ser visto como o que chamamos de “ruído determinístico” $-$ à medida que essa quantidade captura a inabilidade do modelo de aproximar a função alvo $f$. Aqui, lembre-se de que $\bar{g}(\mathbf{x}) = \mathbb{E}</em>{\mathcal{D}}\left[g^{(\mathcal{D})}(\mathbf{x})\right]$.</p>

<p>No final das contas, o que toda essa última seção quer dizer é que, similarmente ao que já fizemos antes, o valor esperado para o erro fora da amostra pode ser decomposto em:</p>

<ul>
  <li>“Ruído determinístico” e “ruído aleatório” que, dado um conjunto de hipóteses $\mathcal{H}$, são quantidades fixas; e</li>
  <li>”$\text{Var}$”, que é afetada indiretamente pelos dois tipos de ruídos - no sentido de que o modelo torna-se mais suscetível às variações advindas das componentes de ruído.</li>
</ul>

<h2 id="conclusão">Conclusão</h2>

<p>Nesse post, introduzimos a ideia de <strong>sobreajuste</strong>, bem como quais quantidades estão relacionadas a esse fenômeno: o “ruído estocástico” e o “ruído determinístico” (que tem ligação direta com a complexidade da função alvo). Via de regra, vimos que: ${}^{1)}$ se o tamanho de $N$ cresce, então $\mathcal{M}_s$ decresce, ${}^{2)}$ se o ruído estocástico aumenta, $\mathcal{M}_s$ também assume valores maiores; e, por fim, ${}^{3)}$ se $f$ é arbitrariamente complexa, então $\mathcal{M}_s$ é potencialmente maior (vide Fig. 4). Esse, como deve ter ficado bem claro no ponto do texto em que estamos, é um problema bastante importante no que se diz respeito ao poder de generalização dos nossos modelos $-$ e, por isso, é importante estudarmos formas de mitigá-lo. A próxima postagem fará isso, apresentando a técnica de regularização.</p>

<p>Qualquer dúvida, sugestão ou <em>feedback</em>, por favor, deixe um comentário abaixo.</p>

<blockquote>
  <p>Essa postagem faz parte de uma <a href="/categorias/#machine-learning-learning-from-data">série</a> de textos que tem o objetivo de estudar, principalmente, o curso “<a href="http://www.work.caltech.edu/telecourse.html">Learning from Data</a>”, ministrado pelo Professor Yaser Abu-Mostafa. Outros materiais utilizados serão sempre referenciados.</p>
</blockquote>
:ET