I"Õ.<p>Continuando com a nossa <a href="/categorias/#machine-learning-learning-from-data">s√©rie de textos</a>, e agora falando sobre um assunto um pouco diferente do que v√≠nhamos discutindo at√© ent√£o; vamos tratar do problema de <strong>sobreajuste</strong> (ou <em>overfitting</em>, do ingl√™s $-$ como √© mais conhecido). Veremos como a ideia de ‚Äúru√≠do‚Äù (apresentada na <a href="/erro-e-ruido/">parte 07</a>) √© causa direta desse tipo de fen√¥mento e vamos, ainda, introduzir um novo conceito, o de ‚Äúru√≠do determin√≠stico‚Äù.</p>

<p><strong><em>Overfitting</em></strong> pode ser entendido como o fen√¥meno no qual um bom ajuste do modelo escolhido com dados pertencentes ao conjunto de trainamento N√ÉO se traduz em $E_{out}$ proporcionalmente pequeno; na verdade, o contr√°rio pode acontecer: o erro fora da amostra pode aumentar conforme o erro dentro da amostra diminui.</p>

<p>Para conseguirmos enxergar o que definimos como <em>overfitting</em> acontecendo, considere o exerc√≠cio a seguir.</p>

<p><strong>Exemplo:</strong> trabalhando com conjunto de dados em $1$ dimens√£o e ajustando modelos da classe de regress√£o polinomial (esse √© s√≥ um nome diferente para uma regress√£o linear com uma transforma√ß√£o do tipo $x \mapsto (1, x, x^2, \cdots)$ para dados unidimensionais), vamos definir dois cen√°rios:</p>

<ol>
  <li>A fun√ß√£o alvo √© um polin√¥mio de ordem $10$ <strong>com</strong> ru√≠do associado. Aqui, $\mathcal{D}$ cont√©m 15 pontos.</li>
  <li>A fun√ß√£o alvo √© um polin√¥mio de ordem $50$ <strong>sem</strong> ru√≠do associado. Aqui, $\mathcal{D}$ tamb√©m cont√©m 15 pontos.</li>
</ol>

<p>A figura a seguir ilustra o que acabamos de descrever:</p>

<p><img src="/assets/images/sobreajuste_files/exemplo_inicial.png" alt="Ilustra√ß√£o do exemplo" />
<em>Figura 1 [fonte: ‚Äú<a href="http://www.work.caltech.edu/textbook.html">Learning from Data</a>‚Äù] $-$ Ilustra√ß√£o do exemplo.</em></p>

<p>Agora suponha que, para lidar com essas fun√ß√µes alvo, vamos ajustar dois modelos de regress√£o: um de ordem $2$ e outro de ordem $10$.</p>

<p><img src="/assets/images/sobreajuste_files/dados_ajustados.png" alt="Modelos ajustados" />
<em>Figura 2 [fonte: ‚Äú<a href="http://www.work.caltech.edu/textbook.html">Learning from Data</a>‚Äù] $-$ Modelos ajustados.</em></p>

<p>Em seguida, vamos ver como os erros ($E_{in}$ e $E_{out}$) se comportam para esses dois modelos ajustados. <strong>Observa√ß√£o:</strong> lembre-se de que, como ainda estamos trabalhando com modelos de regress√£o, a medida de erro mais utilizada √© o ‚Äúerro quadr√°tico‚Äù, como vimos pela primeira vez na <a href="/modelo-de-regressao-linear/">parte 05</a>.</p>

<p><img src="/assets/images/sobreajuste_files/tabela_erros.png" alt="Tabela de erros" />
<em>Figura 3 [fonte: ‚Äú<a href="http://www.work.caltech.edu/textbook.html">Learning from Data</a>‚Äù] $-$ Tabela de erros para todos os cen√°rios considerados.</em></p>

<p>Vamos, primeiro, analisar a situa√ß√£o na qual a fun√ß√£o alvo √© um polin√¥mio de grau $10$ <strong>com</strong> ru√≠do. Nesse caso, note que o modelo mais simples (polin√¥mio de grau $2$) teve erro fora da amostra (<script type="math/tex">E_{out}</script>) menor $-$ se comparado ao modelo ajustado com polin√¥mio de grau $10$. Isso aconteceu porque, apesar de o conjunto de hip√≥teses <script type="math/tex">\mathcal{H}_{10}</script> conter a fun√ß√£o alvo (<strong>a menos do ru√≠do</strong>), a quantidade de dados de treinamento n√£o foi suficiente para permitir generaliza√ß√£o; sendo assim, o modelo apenas ‚Äúmemorizou‚Äù $\mathcal{D}$ e, por isso, teve $E_{in}$ muito pequeno. Dizemos que, aqui, houve <strong>sobreajuste</strong>. Observe, por fim, que, contr√°rio √† ideia de que ‚Äúmais informa√ß√µes‚Äù se traduz em um modelo melhor, vimos que um modelo mais simples apresentou erro fora da amostra (que, no final das contas, √© o que importa) bem mais interessante.</p>

<p>Agora, vamos olhar para a situa√ß√£o onde a fun√ß√£o alvo √© um polin√¥mio de grau $50$ <strong>sem</strong> ru√≠do. Aqui, mais uma vez, o modelo mais complexo $-$ o polin√¥mio de grau $10$ - teve erro dentro da amostra menor; por√©m, perdeu ‚Äúmuito feio‚Äù para o desempenho do modelo mais simples para $x \not\in \mathcal{D}$. Nesse caso, tamb√©m houve <strong>sobreajuste</strong>. Entretanto, a raz√£o aqui √© outra: no primeiro cen√°rio, onde existia ru√≠do associado a $f$, o que aconteceu foi que o modelo com mais par√¢metros incorporou $\epsilon$ como parte do que seria a fun√ß√£o alvo (uma amostra muito maior preveniria esse comportamento); agora, nesse segundo cen√°rio, n√£o h√° ru√≠do. Sendo assim, o que aconteceu? A resposta √© que $f$ √© muito mais complexa que os dois poss√≠veis conjuntos de hip√≥teses ($\mathcal{H_2}$ e <script type="math/tex">\mathcal{H}_{10}</script>); dessa forma, o algoritmo $\mathcal{A}$ tenta usar $\mathcal{H}_{10}$ para  modelar uma fun√ß√£o que ele n√£o √© capaz, e, por isso, acaba ‚Äúmemorizando‚Äù os dados ao inv√©s de, de novo, ‚Äúaprender‚Äù.</p>

<p>A ideia aqui √© que o <em>overfitting</em> pode estar relacionado a, principalmente, duas coisas: o n√≠vel de ru√≠do (que denotaremos por $\sigma^2$) e a complexidade da fun√ß√£o alvo (que denotaremos por $Q_f$). Ao primeiro dist√∫rbio, danos o nome de <strong><em>ru√≠do estoc√°stico</em></strong> (<strong>n√£o h√° nada de novo aqui</strong>, estamos apenas utilizando um termo maior para falar do mesmo ‚Äúru√≠do‚Äù que temos considerado at√© ent√£o); ao passo que, ao segundo, damos o nome de <strong><em>ru√≠do determin√≠stico</em></strong>. Em ambos os casos, $g \in \mathcal{H}$ perde o poder de generaliza√ß√£o para dados fora da amostra.</p>

<p>Dito isso, podemos tentar estebeler uma <strong>medida de sobreajuste</strong>. Nesse sentido, defina:</p>

<script type="math/tex; mode=display">\begin{align}
\text{Medida de sobreajuste } (\mathcal{M}_s) = E_{out}(g_{10}) - E_{out}(g_{2}),
\end{align}</script>

<p>onde $g_{10}$ e $g_{2}$ podem ser substitu√≠das pelas fun√ß√µes (do tipo: $g \in \mathcal{H}$) escolhidas pelo modelo mais complexo e pelo modelo mais simples, respectivamente.</p>

<p>Assim, se $\mathcal{M}_s$ for positivo, quer dizer que o modelo mais simples ganha (que, em outras palavras, √© o mesmo que dizer que o modelo complexo generaliza mal dados fora de $\mathcal{D}$); e o inverso acontece no caso de $\mathcal{M}_s$ ser negativo. Perceba que essa medida √© fundamentalmente de compara√ß√£o.</p>

<p>A imagem a seguir apresenta o resultado de um processo de simula√ß√£o que estuda essas quantidades. A explica√ß√£o do procedimento vem imediatamente abaixo.</p>

<p><img src="/assets/images/sobreajuste_files/heat_map.png" alt="Simula√ß√£o para a quantidade &quot;medida de sobreajuste&quot;" />
<em>Figura 4 [fonte: ‚Äú<a href="http://www.work.caltech.edu/textbook.html">Learning from Data</a>‚Äù] $-$ Simula√ß√£o para a quantidade ‚Äú$E_{out}(g_{10}) - E_{out}(g_{2})$‚Äù.</em></p>

<p>No mapa de calor da esquerda, vemos como a medida de sobreajuste (definida pela cor) depende de $\sigma^2$ e do tamanho da amostra (com $Q_f = 20$ fixo). Perceba que, nesse caso, se o ru√≠do estoc√°stico aumenta e o $N$ √© pequeno, modelos mais complexos (nesse caso, $\mathcal{H}_{10}$) tem desempenho ruim; entretanto, se o tamanho da amostra aumenta, esse efeito √© corrigido.</p>

<p>J√° no mapa de calor da direita, √© poss√≠vel enxergar como a medida de sobreajuste depende da complexidade da fun√ß√£o alvo e, mais uma vez, do tamanho da amostra (com $\sigma^2 = 0.1$ fixo). Note que, quando $Q_f &gt; 10$, a classe de modelos polinomiais de ordem $10$ come√ßa a perder capacidade de aprendizado, abrindo espa√ßo para que o modelo mais simples tenha melhor desempenho no que se diz respeito a $E_{out}$. Isso, de novo, √© corrigido com o aumento do tamanho da amostra.</p>

<p>Aqui, √© poss√≠vel perceber o porqu√™ do ‚Äúru√≠do determin√≠stico‚Äù receber esse nome. Quando a classe de modelos passa a n√£o ser capaz mais de representar adequadamente a fun√ß√£o alvo, a por√ß√£o de dados n√£o explicada pelo modelo √© tratada como uma esp√©cie de ru√≠do.</p>

<h3 id="overfitting-e-o-trade-off-entre-vi√©s-e-vari√¢ncia"><em>Overfitting</em> e o <em>trade-off</em> entre vi√©s e vari√¢ncia</h3>

<p>Antes de finalizarmos, vamos ver como a quest√£o do ‚Äú<em>trade-off</em> entre vi√©s e vari√¢ncia‚Äù se relaciona com as quantidades que acabamos de estudar. Relembrando o que foi apresentado na <a href="/vies-variancia-tradeoff/">parte 10</a>, podemos decompor o valor esperado do erro fora da amostra em duas componentes: vi√©s e vari√¢ncia. A equa√ß√£o a seguir representa essa rela√ß√£o:</p>

<script type="math/tex; mode=display">\begin{align*}
\mathbb{E}_{\mathcal{D}}\left[E_{out}(g^{(\mathcal{D})})\right] = \text{Var} + \text{Vi√©s},
\end{align*}</script>

<p>onde $\text{Vi√©s} = \mathbb{E}<em>{\mathbf{x}}(\bar{g}(\mathbf{x}) - f(\mathbf{x}))^2$ e que $\text{Var} = \mathbb{E}</em>{\mathcal{D},\mathbf{x}}\left[( g^{(\mathcal{D})}(\mathbf{x}) - \bar{g}(\mathbf{x}))^2\right]$.</p>

<p>Lembre-se, por√©m, de que na equa√ß√£o acima, <strong>n√£o</strong> consideramos que existia ru√≠do. Alternativamente, se agora dissermos que $y = f(x) + \epsilon$ (tal que $\mathbb{E}(\epsilon) = 0$ e $\mathbb{V}(\epsilon) = \sigma^2$), ent√£o, de maneira an√°loga, podemos deduzir que</p>

<p><script type="math/tex">\begin{align*}
\mathbb{E}_{\mathcal{D}, \epsilon}\left[E_{out}(g^{(\mathcal{D})})\right] = \text{Var} + \text{Vi√©s} + \sigma^2,
\end{align*}</script>
com $\sigma^2 = \mathbf{E}_{\epsilon,\mathbf{x}}\left[(\epsilon(\mathbf{x}))^2\right]$.</p>

<p>Da equa√ß√£o acima, perceba que o $\text{Vi√©s} = \mathbb{E}<em>{\mathbf{x}}(\bar{g}(\mathbf{x}) - f(\mathbf{x}))^2$ pode ser visto como o que chamamos de ‚Äúru√≠do determin√≠stico‚Äù $-$ √† medida que essa quantidade captura a inabilidade do modelo de aproximar a fun√ß√£o alvo $f$. Aqui, lembre-se de que $\bar{g}(\mathbf{x}) = \mathbb{E}</em>{\mathcal{D}}\left[g^{(\mathcal{D})}(\mathbf{x})\right]$.</p>

<p>No final das contas, o que toda essa √∫ltima se√ß√£o quer dizer √© que, similarmente ao que j√° fizemos antes, o valor esperado para o erro fora da amostra pode ser decomposto em:</p>

<ul>
  <li>‚ÄúRu√≠do determin√≠stico‚Äù e ‚Äúru√≠do aleat√≥rio‚Äù que, dado um conjunto de hip√≥teses $\mathcal{H}$, s√£o quantidades fixas; e</li>
  <li>‚Äù$\text{Var}$‚Äù, que √© afetada indiretamente pelos dois tipos de ru√≠dos - no sentido de que o modelo torna-se mais suscet√≠vel √†s varia√ß√µes advindas das componentes de ru√≠do.</li>
</ul>

<h2 id="conclus√£o">Conclus√£o</h2>

<p>Nesse post, introduzimos a ideia de <strong>sobreajuste</strong>, bem como quais quantidades est√£o relacionadas a esse fen√¥meno: o ‚Äúru√≠do estoc√°stico‚Äù e o ‚Äúru√≠do determin√≠stico‚Äù (que tem liga√ß√£o direta com a complexidade da fun√ß√£o alvo). Via de regra, vimos que: ${}^{1)}$ se o tamanho de $N$ cresce, ent√£o $\mathcal{M}_s$ decresce, ${}^{2)}$ se o ru√≠do estoc√°stico aumenta, $\mathcal{M}_s$ tamb√©m assume valores maiores; e, por fim, ${}^{3)}$ se $f$ √© arbitrariamente complexa, ent√£o $\mathcal{M}_s$ √© potencialmente maior (vide Fig. 4). Esse, como deve ter ficado bem claro no ponto do texto em que estamos, √© um problema bastante importante no que se diz respeito ao poder de generaliza√ß√£o dos nossos modelos $-$ e, por isso, √© importante estudarmos formas de mitig√°-lo. A pr√≥xima postagem far√° isso, apresentando a t√©cnica de regulariza√ß√£o.</p>

<p>Qualquer d√∫vida, sugest√£o ou <em>feedback</em>, por favor, deixe um coment√°rio abaixo.</p>

<blockquote>
  <p>Essa postagem faz parte de uma <a href="/categorias/#machine-learning-learning-from-data">s√©rie</a> de textos que tem o objetivo de estudar, principalmente, o curso ‚Äú<a href="http://www.work.caltech.edu/telecourse.html">Learning from Data</a>‚Äù, ministrado pelo Professor Yaser Abu-Mostafa. Outros materiais utilizados ser√£o sempre referenciados.</p>
</blockquote>
:ET