I"}Õ<p>Como vimos at√© agora <a href="/categorias/#machine-learning-learning-from-data">nessa s√©rie de textos</a>, modelos lineares (tanto de classifica√ß√£o quanto de regress√£o) utilizam a quantidade $\sum_{i = 0}^{d} w_i x_i$ para calcular a fun√ß√£o $h \in \mathcal{H}$. Note que essa express√£o √© linear para os $x_i$‚Äôs e $w_i$‚Äôs; por√©m, como discutimos na <a href="/modelo-de-regressao-linear/">parte 05</a>, os $x_i$‚Äôs podem, do ponto de vista do algoritmo, ser encaradados como constantes (pense que o conjunto de dados $\mathcal{D}$, no momento que vamos ajustar o modelo, j√° est√° definido). Dessa forma, basta que a express√£o que estamos considerando seja linear para o vetor de pesos $-$ o que, em outras palavras, significa dizer que podemos aplicar tranforma√ß√µes n√£o-lineares em $\mathbf{x} \in \mathcal{D}$.</p>

<p>Nessa postagem vamos discutir (e implementar) dois exemplos: um de classifica√ß√£o $-$ utilizando o algoritmo Perceptron $-$, e outro de regress√£o; ambos com transforma√ß√µes n√£o lineares aplicadas no conjunto de dados.</p>

<h3 id="classifica√ß√£o">Classifica√ß√£o</h3>

<p>Para o primeiro caso, vamos gerar um conjunto de dados que ser√° classificado de acordo com a posi√ß√£o de um ponto dentro (ou fora) de um circunfer√™ncia com centro na origem.</p>

<p>Veja como o conjunto de dados foi gerado, bem como uma representa√ß√£o gr√°fica dos pontos.</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="o">%</span><span class="n">matplotlib</span> <span class="n">inline</span>
<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="n">np</span>
<span class="kn">import</span> <span class="nn">pandas</span> <span class="k">as</span> <span class="n">pd</span>
<span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="k">as</span> <span class="n">plt</span>

<span class="n">rn</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">RandomState</span><span class="p">(</span><span class="mi">999</span><span class="p">)</span>
<span class="n">x1</span> <span class="o">=</span> <span class="n">rn</span><span class="o">.</span><span class="n">normal</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mf">1.00</span><span class="p">,</span> <span class="mi">100</span><span class="p">)</span>
<span class="n">x2</span> <span class="o">=</span> <span class="n">rn</span><span class="o">.</span><span class="n">normal</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mf">1.00</span><span class="p">,</span> <span class="mi">100</span><span class="p">)</span>

<span class="n">mask_in</span>  <span class="o">=</span> <span class="p">((</span><span class="n">x1</span> <span class="o">**</span> <span class="mi">2</span><span class="p">)</span> <span class="o">+</span> <span class="p">(</span><span class="n">x2</span> <span class="o">**</span> <span class="mi">2</span><span class="p">)</span> <span class="o">-</span> <span class="mf">1.00</span> <span class="o">&lt;</span> <span class="mi">0</span><span class="p">)</span>
<span class="n">mask_out</span> <span class="o">=</span> <span class="p">((</span><span class="n">x1</span> <span class="o">**</span> <span class="mi">2</span><span class="p">)</span> <span class="o">+</span> <span class="p">(</span><span class="n">x2</span> <span class="o">**</span> <span class="mi">2</span><span class="p">)</span> <span class="o">-</span> <span class="mf">1.44</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="p">)</span> <span class="o">&amp;</span> <span class="p">((</span><span class="n">x1</span> <span class="o">**</span> <span class="mi">2</span><span class="p">)</span> <span class="o">+</span> <span class="p">(</span><span class="n">x2</span> <span class="o">**</span> <span class="mi">2</span><span class="p">)</span> <span class="o">-</span> <span class="mf">4.00</span> <span class="o">&lt;</span> <span class="mi">0</span><span class="p">)</span> 

<span class="n">x1_in</span>  <span class="o">=</span> <span class="n">x1</span><span class="p">[</span><span class="n">mask_in</span><span class="p">]</span>
<span class="n">x2_in</span>  <span class="o">=</span> <span class="n">x2</span><span class="p">[</span><span class="n">mask_in</span><span class="p">]</span>
<span class="n">x1_out</span> <span class="o">=</span> <span class="n">x1</span><span class="p">[</span><span class="n">mask_out</span><span class="p">]</span>
<span class="n">x2_out</span> <span class="o">=</span> <span class="n">x2</span><span class="p">[</span><span class="n">mask_out</span><span class="p">]</span>

<span class="n">X</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">c_</span><span class="p">[</span><span class="n">x1_in</span><span class="o">.</span><span class="n">tolist</span><span class="p">()</span> <span class="o">+</span> <span class="n">x1_out</span><span class="o">.</span><span class="n">tolist</span><span class="p">(),</span> <span class="n">x2_in</span><span class="o">.</span><span class="n">tolist</span><span class="p">()</span> <span class="o">+</span> <span class="n">x2_out</span><span class="o">.</span><span class="n">tolist</span><span class="p">()])</span>
<span class="n">y</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">asarray</span><span class="p">([</span><span class="n">np</span><span class="o">.</span><span class="n">where</span><span class="p">(</span><span class="n">y</span> <span class="o">&lt;</span> <span class="n">x1_in</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span> <span class="k">for</span> <span class="n">y</span> <span class="ow">in</span> <span class="n">np</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="n">x1_in</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">+</span> <span class="n">x1_out</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">])])</span>

<span class="n">plt</span><span class="o">.</span><span class="n">scatter</span><span class="p">(</span><span class="n">X</span><span class="p">[:</span><span class="n">x1_in</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="mi">0</span><span class="p">],</span> <span class="n">X</span><span class="p">[:</span><span class="n">x1_in</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="mi">1</span><span class="p">],</span> <span class="n">color</span> <span class="o">=</span> <span class="s">"red"</span><span class="p">,</span> <span class="n">marker</span> <span class="o">=</span> <span class="s">"o"</span><span class="p">,</span> <span class="n">label</span> <span class="o">=</span> <span class="s">"In"</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">scatter</span><span class="p">(</span><span class="n">X</span><span class="p">[</span><span class="n">x1_in</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]:,</span> <span class="mi">0</span><span class="p">],</span> <span class="n">X</span><span class="p">[</span><span class="n">x1_in</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]:,</span> <span class="mi">1</span><span class="p">],</span> <span class="n">color</span> <span class="o">=</span> <span class="s">"green"</span><span class="p">,</span> <span class="n">marker</span> <span class="o">=</span> <span class="s">"s"</span><span class="p">,</span> <span class="n">label</span> <span class="o">=</span> <span class="s">"Out"</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">axis</span><span class="p">(</span><span class="s">"scaled"</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">xlim</span><span class="p">(</span><span class="o">-</span><span class="mf">2.25</span><span class="p">,</span> <span class="mf">2.25</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">ylim</span><span class="p">(</span><span class="o">-</span><span class="mf">2.25</span><span class="p">,</span> <span class="mf">2.25</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s">"original $x_1$"</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s">"original $x_2$"</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">legend</span><span class="p">(</span><span class="n">loc</span> <span class="o">=</span> <span class="mi">1</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</code></pre></div></div>

<p><img src="/assets/images/transformacoes-nao-lineares_files/transformacoes-nao-lineares_4_0.png" alt="png" /></p>

<p>Nesse exemplo, pontos sorteados segundo uma distribui√ß√£o $N(0, 1)$ para cada uma das coordenadas foram definidos como <code class="highlighter-rouge">In</code> $-$ caso o ponto esteja dentro da circunfer√™ncia de raio $1$ $-$ ou <code class="highlighter-rouge">Out</code> $-$ caso o ponto esteja fora da circunfer√™ncia de raio $1.2$ e dentro da circunfer√™ncia de raio $2$. Obviamente, essas duas classes <strong>n√£o</strong> s√£o linearmente separ√°veis.</p>

<p>Assim, vamos aplicar uma transforma√ß√£o nos pontos de $\mathbf{x}$ tal que $\phi: (x_1, x_2) \rightarrow ({x_1}^2, {x_2}^2)$, para todo $\mathbf{x} \in \mathcal{D}$. Veja, agora, como os dados transformados podem ser representados:</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">X_transformed</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">power</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="mi">2</span><span class="p">)</span>

<span class="n">plt</span><span class="o">.</span><span class="n">scatter</span><span class="p">(</span><span class="n">X_transformed</span><span class="p">[:</span><span class="n">x1_in</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="mi">0</span><span class="p">],</span> <span class="n">X_transformed</span><span class="p">[:</span><span class="n">x1_in</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="mi">1</span><span class="p">],</span> <span class="n">color</span> <span class="o">=</span> <span class="s">"red"</span><span class="p">,</span> <span class="n">marker</span> <span class="o">=</span> <span class="s">"o"</span><span class="p">,</span> <span class="n">label</span> <span class="o">=</span> <span class="s">"In"</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">scatter</span><span class="p">(</span><span class="n">X_transformed</span><span class="p">[</span><span class="n">x1_in</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]:,</span> <span class="mi">0</span><span class="p">],</span> <span class="n">X_transformed</span><span class="p">[</span><span class="n">x1_in</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]:,</span> <span class="mi">1</span><span class="p">],</span> <span class="n">color</span> <span class="o">=</span> <span class="s">"green"</span><span class="p">,</span> <span class="n">marker</span> <span class="o">=</span> <span class="s">"s"</span><span class="p">,</span> <span class="n">label</span> <span class="o">=</span> <span class="s">"Out"</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">axis</span><span class="p">(</span><span class="s">"scaled"</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">xlim</span><span class="p">(</span><span class="o">-</span><span class="mf">0.25</span><span class="p">,</span> <span class="mf">4.25</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">ylim</span><span class="p">(</span><span class="o">-</span><span class="mf">0.25</span><span class="p">,</span> <span class="mf">4.25</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s">"transformed $x_1$"</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s">"transformed $x_2$"</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">legend</span><span class="p">(</span><span class="n">loc</span> <span class="o">=</span> <span class="mi">1</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</code></pre></div></div>

<p><img src="/assets/images/transformacoes-nao-lineares_files/transformacoes-nao-lineares_7_0.png" alt="png" /></p>

<p>Feita as transforma√ß√£o nos dados de acordo com a nossa fun√ß√£o $\phi$, para todo $\mathcal{x} \in \mathcal{D}$ (nesse caso, por constru√ß√£o), o meu conjunto de pontos √© linearmente separ√°vel. Sendo assim, posso aplicar, por exemplo, o Perceptron (utilizando o Sklearn $-$ caso queira ver a implementa√ß√£o completa do algoritmo, consulte a <a href="/implementacao-perceptron/">parte 02</a>):</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">from</span> <span class="nn">sklearn.linear_model</span> <span class="kn">import</span> <span class="n">Perceptron</span>

<span class="n">perceptron</span> <span class="o">=</span> <span class="n">Perceptron</span><span class="p">()</span>
<span class="n">perceptron</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_transformed</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span>

<span class="k">print</span><span class="p">(</span><span class="s">"Intercept weight: {}."</span><span class="o">.</span><span class="nb">format</span><span class="p">(</span><span class="n">perceptron</span><span class="o">.</span><span class="n">intercept_</span><span class="p">))</span>
<span class="k">print</span><span class="p">(</span><span class="s">"Weights vector: {}."</span><span class="o">.</span><span class="nb">format</span><span class="p">(</span><span class="n">perceptron</span><span class="o">.</span><span class="n">coef_</span><span class="p">))</span>
</code></pre></div></div>

<div class="highlighter-rouge"><div class="highlight"><pre class="highlight"><code>Intercept weight: [-2.].
Weights vector: [[2.36966542 1.48327095]].
</code></pre></div></div>

<p>De posse do modelo ajustado; i.e., do vetor $\mathbf{w}$ completamente definido, podemos plotar as regi√µes de decis√£o, utilizando a fun√ß√£o <code class="highlighter-rouge">plot_decision_regions()</code> introduzida, pela primeira vez, na <a href="/implementacao-perceptron/">parte 02</a>.</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># modified function to admit data transformation
</span><span class="k">def</span> <span class="nf">plot_decision_regions</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">classifier</span><span class="p">,</span> <span class="n">feature_names</span><span class="p">,</span> <span class="n">modified</span> <span class="o">=</span> <span class="bp">False</span><span class="p">,</span> <span class="n">transf1</span> <span class="o">=</span> <span class="k">lambda</span> <span class="n">x</span><span class="p">:</span> <span class="n">x</span><span class="p">,</span> <span class="n">transf2</span> <span class="o">=</span> <span class="bp">None</span><span class="p">,</span> <span class="n">resolution</span> <span class="o">=</span> <span class="mf">0.01</span><span class="p">,</span> <span class="n">axis_lim</span> <span class="o">=</span> <span class="mi">1</span><span class="p">):</span>
    <span class="c1"># general settings
</span>    <span class="n">markers</span> <span class="o">=</span> <span class="p">[</span><span class="s">"o"</span><span class="p">,</span> <span class="s">"s"</span><span class="p">,</span> <span class="s">"*"</span><span class="p">,</span> <span class="s">"x"</span><span class="p">,</span> <span class="s">"v"</span><span class="p">]</span>
    <span class="n">colors</span>  <span class="o">=</span> <span class="p">(</span><span class="s">"red"</span><span class="p">,</span> <span class="s">"green"</span><span class="p">,</span> <span class="s">"blue"</span><span class="p">,</span> <span class="s">"gray"</span><span class="p">,</span> <span class="s">"cyan"</span><span class="p">)</span>
    <span class="n">x1_min</span><span class="p">,</span> <span class="n">x1_max</span> <span class="o">=</span> <span class="n">X</span><span class="p">[:,</span> <span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="nb">min</span><span class="p">()</span> <span class="o">-</span> <span class="n">axis_lim</span><span class="p">,</span> <span class="n">X</span><span class="p">[:,</span> <span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="nb">max</span><span class="p">()</span> <span class="o">+</span> <span class="n">axis_lim</span>
    <span class="n">x2_min</span><span class="p">,</span> <span class="n">x2_max</span> <span class="o">=</span> <span class="n">X</span><span class="p">[:,</span> <span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="nb">min</span><span class="p">()</span> <span class="o">-</span> <span class="n">axis_lim</span><span class="p">,</span> <span class="n">X</span><span class="p">[:,</span> <span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="nb">max</span><span class="p">()</span> <span class="o">+</span> <span class="n">axis_lim</span>
    <span class="c1"># define a grid
</span>    <span class="n">xx1</span><span class="p">,</span> <span class="n">xx2</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">meshgrid</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="n">x1_min</span><span class="p">,</span> <span class="n">x1_max</span><span class="p">,</span> <span class="n">resolution</span><span class="p">),</span>
                           <span class="n">np</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="n">x2_min</span><span class="p">,</span> <span class="n">x2_max</span><span class="p">,</span> <span class="n">resolution</span><span class="p">))</span>
    <span class="c1"># tranform the point that will be predicted, but NOT the one which will be plotted
</span>    <span class="k">if</span> <span class="n">modified</span><span class="p">:</span>
        <span class="k">if</span> <span class="n">transf2</span> <span class="o">==</span> <span class="bp">None</span><span class="p">:</span>
            <span class="n">transf2</span> <span class="o">=</span> <span class="n">transf1</span>
        <span class="n">xx1_mod</span> <span class="o">=</span> <span class="n">transf1</span><span class="p">(</span><span class="n">xx1</span><span class="p">)</span>
        <span class="n">xx2_mod</span> <span class="o">=</span> <span class="n">transf2</span><span class="p">(</span><span class="n">xx2</span><span class="p">)</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="n">xx1_mod</span> <span class="o">=</span> <span class="n">xx1</span>
        <span class="n">xx2_mod</span> <span class="o">=</span> <span class="n">xx2</span>      
    <span class="c1"># classify each grid point
</span>    <span class="n">result</span> <span class="o">=</span> <span class="n">classifier</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="n">xx1_mod</span><span class="o">.</span><span class="n">ravel</span><span class="p">(),</span> <span class="n">xx2_mod</span><span class="o">.</span><span class="n">ravel</span><span class="p">()])</span><span class="o">.</span><span class="n">T</span><span class="p">)</span>
    <span class="n">result</span> <span class="o">=</span> <span class="n">result</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="n">xx1_mod</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>
    <span class="c1"># make a plot
</span>    <span class="n">plt</span><span class="o">.</span><span class="n">contourf</span><span class="p">(</span><span class="n">xx1</span><span class="p">,</span> <span class="n">xx2</span><span class="p">,</span> <span class="n">result</span><span class="p">,</span> <span class="n">colors</span> <span class="o">=</span> <span class="n">colors</span><span class="p">[</span><span class="mi">0</span><span class="p">:</span><span class="nb">len</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">unique</span><span class="p">(</span><span class="n">y</span><span class="p">))],</span> <span class="n">alpha</span> <span class="o">=</span> <span class="mf">0.5</span><span class="p">)</span>
    <span class="k">for</span> <span class="n">index</span><span class="p">,</span> <span class="n">value</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">unique</span><span class="p">(</span><span class="n">y</span><span class="p">)):</span> <span class="c1"># plot each point &amp; 'enumerate()' returns index and value of the given array
</span>        <span class="n">plt</span><span class="o">.</span><span class="n">scatter</span><span class="p">(</span><span class="n">x</span> <span class="o">=</span> <span class="n">X</span><span class="p">[</span><span class="n">y</span> <span class="o">==</span> <span class="n">value</span><span class="p">,</span> <span class="mi">0</span><span class="p">],</span> <span class="n">y</span> <span class="o">=</span> <span class="n">X</span><span class="p">[</span><span class="n">y</span> <span class="o">==</span> <span class="n">value</span><span class="p">,</span> <span class="mi">1</span><span class="p">],</span> <span class="c1"># select each X and y vectors by creating a mask
</span>                    <span class="n">color</span> <span class="o">=</span> <span class="n">colors</span><span class="p">[</span><span class="n">index</span><span class="p">],</span>
                    <span class="n">marker</span> <span class="o">=</span> <span class="n">markers</span><span class="p">[</span><span class="n">index</span><span class="p">],</span>
                    <span class="n">label</span> <span class="o">=</span> <span class="n">feature_names</span><span class="p">[</span><span class="n">index</span><span class="p">],</span>
                    <span class="n">edgecolor</span> <span class="o">=</span> <span class="s">'black'</span><span class="p">)</span>
</code></pre></div></div>

<p>Perceba que a fun√ß√£o foi levemente modificada para comportar dois novos par√¢metros: <code class="highlighter-rouge">transf1</code> e <code class="highlighter-rouge">transf2</code> (al√©m do <code class="highlighter-rouge">modified</code>, que √©, apenas, uma tecnicalidade). Esses vari√°veis recebem uma fun√ß√£o respons√°vel pela transforma√ß√£o de cada uma das <em>features</em> do nosso conjunto de dados (por exemplo, uma transforma√ß√£o como a definida por $\phi(\mathbf{x})$). Mas antes de utilizarmos esse novo artif√≠cio, vamos ver como ficam as regi√µes de decis√£o para os dados transformados:</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">feature_names</span> <span class="o">=</span> <span class="p">[</span><span class="s">"In"</span><span class="p">,</span> <span class="s">"Out"</span><span class="p">]</span>
<span class="n">plot_decision_regions</span><span class="p">(</span><span class="n">X_transformed</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">perceptron</span><span class="p">,</span> <span class="n">feature_names</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="s">"Fitted model using transformed $X$"</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s">"Transformed $x_1$"</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s">"Transformed $x_2$"</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">axis</span><span class="p">(</span><span class="s">"scaled"</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">xlim</span><span class="p">(</span><span class="o">-</span><span class="mf">0.25</span><span class="p">,</span> <span class="mf">4.25</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">ylim</span><span class="p">(</span><span class="o">-</span><span class="mf">0.25</span><span class="p">,</span> <span class="mf">4.25</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">legend</span><span class="p">(</span><span class="n">loc</span> <span class="o">=</span> <span class="mi">1</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</code></pre></div></div>

<p><img src="/assets/images/transformacoes-nao-lineares_files/transformacoes-nao-lineares_13_0.png" alt="png" /></p>

<p>Por enquanto, nada de novo; como era de se esperar, os dados foram corretamente classificados e separados.</p>

<p>Agora o que podemos fazer (que √©, de fato, a parte interessante) √© contruir as regi√µes de decis√£o para os dados <strong>originais</strong>; nesse caso, utilizaremos os par√¢metros <code class="highlighter-rouge">transf1</code> e <code class="highlighter-rouge">transf2</code> passando, como argumento, a fun√ß√£o <code class="highlighter-rouge">lambda: x: x ** 2</code> $-$ ou seja, do mesmo modo que definimos $\phi$. Veja:</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">feature_names</span> <span class="o">=</span> <span class="p">[</span><span class="s">"In"</span><span class="p">,</span> <span class="s">"Out"</span><span class="p">]</span>
<span class="n">plot_decision_regions</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">perceptron</span><span class="p">,</span> <span class="n">feature_names</span><span class="p">,</span> <span class="bp">True</span><span class="p">,</span> <span class="k">lambda</span> <span class="n">x</span><span class="p">:</span> <span class="n">np</span><span class="o">.</span><span class="n">power</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="mi">2</span><span class="p">))</span>
<span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="s">"Fitted model using original $X$"</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s">"Original $x_1$"</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s">"Original $x_2$"</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">axis</span><span class="p">(</span><span class="s">"scaled"</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">xlim</span><span class="p">(</span><span class="o">-</span><span class="mf">2.25</span><span class="p">,</span> <span class="mf">2.25</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">ylim</span><span class="p">(</span><span class="o">-</span><span class="mf">2.25</span><span class="p">,</span> <span class="mf">2.25</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">legend</span><span class="p">(</span><span class="n">loc</span> <span class="o">=</span> <span class="mi">1</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</code></pre></div></div>

<p><img src="/assets/images/transformacoes-nao-lineares_files/transformacoes-nao-lineares_15_0.png" alt="png" /></p>

<p>Tomando esse tipo de estrat√©gia, n√≥s conseguimos, como pode ser visto acima, classificar dois grupos de pontos que, √† princ√≠pio, n√£o eram linearmente separ√°veis.</p>

<h3 id="regress√£o">Regress√£o</h3>

<p>Agora, nesse segundo exemplo, vamos estudar um problema de regress√£o. Para isso, considere o seguinte cen√°rio: suponha que as informa√ß√µes ‚Äúsal√°rio‚Äù e ‚Äúfelicidade‚Äù (para alguma medida arbitr√°ria que captura esse sentimento) foram coletadas a partir de um grupo de $100$ indiv√≠duos; suponha, ainda, que o sal√°rio dessas pessoas segue distribui√ß√£o $\text{Gamma}(2, 5000)$ (para uma distribui√ß√£o desse tipo, temos m√©dia $10\times 10^3$ e assimetria √† direita) $-$ veja o histograma a seguir.</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">rn</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">RandomState</span><span class="p">(</span><span class="mi">1</span><span class="p">)</span>
<span class="n">X</span>  <span class="o">=</span> <span class="n">rn</span><span class="o">.</span><span class="n">gamma</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="mi">5000</span><span class="p">,</span> <span class="mi">100</span><span class="p">)</span>
<span class="n">X</span>  <span class="o">=</span> <span class="n">X</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="mi">100</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">hist</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">color</span> <span class="o">=</span> <span class="s">"red"</span><span class="p">,</span> <span class="n">alpha</span> <span class="o">=</span> <span class="mf">0.5</span><span class="p">,</span> <span class="n">bins</span> <span class="o">=</span> <span class="mi">10</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s">"Salary (</span><span class="err">\</span><span class="s">$)"</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s">"Frequency"</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">xticks</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mf">45e3</span><span class="p">,</span> <span class="mf">5e3</span><span class="p">))</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</code></pre></div></div>

<p><img src="/assets/images/transformacoes-nao-lineares_files/transformacoes-nao-lineares_19_0.png" alt="png" /></p>

<p>Assim, temos v√°rios indiv√≠duos que ganham sal√°rios em torno dos dez mil reais, e alguns outros poucos trabalhadores que ganham quantias muito maiores do que essa.</p>

<p>Agora, suponha que a ‚Äúfelicidade‚Äù depende do ‚Äúsal√°rio‚Äù, mas essa rela√ß√£o n√£o √© linear; ou seja, depois de uma determinada quantidade de dinheiro, receber mais n√£o se traduz em ser proporcionalmente mais feliz. Podemos representar essa depend√™ncia atrav√©s da fun√ß√£o $\log(\cdot)$.</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">y</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">log</span><span class="p">(</span><span class="n">X</span><span class="p">)</span> <span class="o">+</span> <span class="n">rn</span><span class="o">.</span><span class="n">normal</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mf">0.2</span><span class="p">,</span> <span class="mi">100</span><span class="p">)</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="mi">100</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">scatter</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">marker</span> <span class="o">=</span> <span class="s">"o"</span><span class="p">,</span> <span class="n">color</span> <span class="o">=</span> <span class="s">"red"</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="s">"Salary (</span><span class="err">\</span><span class="s">$) vs. Happiness"</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s">"Salary (</span><span class="err">\</span><span class="s">$)"</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s">"Happiness measure"</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">xticks</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mf">45e3</span><span class="p">,</span> <span class="mf">5e3</span><span class="p">))</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</code></pre></div></div>

<p><img src="/assets/images/transformacoes-nao-lineares_files/transformacoes-nao-lineares_22_0.png" alt="png" /></p>

<p>No c√≥digo acima, perceba perceba que a ‚Äúfelicidade‚Äù, como fun√ß√£o do ‚Äúsal√°rio‚Äù, foi somada a valores que v√™m de uma distrui√ß√£o $N(0, 0.04)$ $-$ esse termo ser√° denominado por ‚Äúru√≠do‚Äù ($\epsilon$), e refere-se √† diferen√ßa entre os valores observado e <strong>real</strong> (n√£o observ√°vel) da vari√°vel dependente. Lembre-se de que, quando falamos de regress√£o linear, estamos interessados em estudar um modelo do tipo: $y = w_0 + w_1 x_1 + \cdots + w_d x_d + \epsilon$.</p>

<p>Visualmente (e por constru√ß√£o, nesse caso), a rela√ß√£o descrita acima <strong>n√£o</strong> √© linear; nesse caso, faz sentido aplicarmos alguma transforma√ß√£o na vari√°vel independente.</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">X_transformed</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">log</span><span class="p">(</span><span class="n">X</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">scatter</span><span class="p">(</span><span class="n">X_transformed</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">marker</span> <span class="o">=</span> <span class="s">"s"</span><span class="p">,</span> <span class="n">color</span> <span class="o">=</span> <span class="s">"green"</span><span class="p">,</span> <span class="n">alpha</span> <span class="o">=</span> <span class="mf">0.75</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="s">"Transformed Salary ($</span><span class="err">\</span><span class="s">log$ of </span><span class="err">\</span><span class="s">$) vs. Happiness"</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s">"Transformed Salary ($</span><span class="err">\</span><span class="s">log$ of </span><span class="err">\</span><span class="s">$)"</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s">"Happiness measure"</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</code></pre></div></div>

<p><img src="/assets/images/transformacoes-nao-lineares_files/transformacoes-nao-lineares_25_0.png" alt="png" /></p>

<p>Note que, aplicando $\log(\cdot)$ em $x$, obtemos algo que se aproxima mais de uma rela√ß√£o linear. Nesse caso, podemos ajustar o modelo de regress√£o (utilizando o Sklearn $-$ caso queira ver a implementa√ß√£o completa do algoritmo, consulte a <a href="/modelo-de-regressao-linear/">parte 05</a>). Primeiro, ajustaremos o modelo considerando $x$ e, depois, considerando $\log(x)$.</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">from</span> <span class="nn">sklearn.linear_model</span> <span class="kn">import</span> <span class="n">LinearRegression</span>

<span class="n">regression_original</span> <span class="o">=</span> <span class="n">LinearRegression</span><span class="p">()</span>
<span class="n">regression_original</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span>

<span class="n">x_min</span> <span class="o">=</span> <span class="n">X</span><span class="p">[:,</span> <span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="nb">min</span><span class="p">()</span>
<span class="n">x_max</span> <span class="o">=</span> <span class="n">X</span><span class="p">[:,</span> <span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="nb">max</span><span class="p">()</span>
<span class="n">x_values</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="n">x_min</span><span class="p">,</span> <span class="n">x_max</span><span class="p">,</span> <span class="mi">100</span><span class="p">)</span>
<span class="n">y_values</span> <span class="o">=</span> <span class="n">regression_original</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">asarray</span><span class="p">(</span><span class="n">x_values</span><span class="p">)</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">x_values</span><span class="p">),</span> <span class="mi">1</span><span class="p">))</span>
<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">x_values</span><span class="p">,</span> <span class="n">y_values</span><span class="p">,</span> <span class="n">color</span> <span class="o">=</span> <span class="s">"darkred"</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">scatter</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">marker</span> <span class="o">=</span> <span class="s">"o"</span><span class="p">,</span> <span class="n">color</span> <span class="o">=</span> <span class="s">"red"</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="s">"Fitted Regression for Salary"</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s">"Salary (</span><span class="err">\</span><span class="s">$)"</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s">"Happiness measure"</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">xticks</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mf">45e3</span><span class="p">,</span> <span class="mf">5e3</span><span class="p">))</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</code></pre></div></div>

<p><img src="/assets/images/transformacoes-nao-lineares_files/transformacoes-nao-lineares_27_0.png" alt="png" /></p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">regression_transformed</span> <span class="o">=</span> <span class="n">LinearRegression</span><span class="p">()</span>
<span class="n">regression_transformed</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_transformed</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span>

<span class="n">x_min</span> <span class="o">=</span> <span class="n">X_transformed</span><span class="p">[:,</span> <span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="nb">min</span><span class="p">()</span>
<span class="n">x_max</span> <span class="o">=</span> <span class="n">X_transformed</span><span class="p">[:,</span> <span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="nb">max</span><span class="p">()</span>
<span class="n">x_values</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="n">x_min</span><span class="p">,</span> <span class="n">x_max</span><span class="p">,</span> <span class="mf">0.01</span><span class="p">)</span>
<span class="n">y_values</span> <span class="o">=</span> <span class="n">regression_transformed</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">asarray</span><span class="p">(</span><span class="n">x_values</span><span class="p">)</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">x_values</span><span class="p">),</span> <span class="mi">1</span><span class="p">))</span>
<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">x_values</span><span class="p">,</span> <span class="n">y_values</span><span class="p">,</span> <span class="n">color</span> <span class="o">=</span> <span class="s">"darkgreen"</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">scatter</span><span class="p">(</span><span class="n">X_transformed</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">marker</span> <span class="o">=</span> <span class="s">"s"</span><span class="p">,</span> <span class="n">color</span> <span class="o">=</span> <span class="s">"green"</span><span class="p">,</span> <span class="n">alpha</span> <span class="o">=</span> <span class="mf">0.75</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="s">"Fitted regression for $</span><span class="err">\</span><span class="s">log$ of Salary"</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s">"Transformed Salary ($</span><span class="err">\</span><span class="s">log$ of </span><span class="err">\</span><span class="s">$)"</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s">"Happiness measure"</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</code></pre></div></div>

<p><img src="/assets/images/transformacoes-nao-lineares_files/transformacoes-nao-lineares_28_0.png" alt="png" /></p>

<p>Perceba que o primeiro modelo ajustado, com a vari√°vel $x$ original (indicado pelo gr√°fico de t√≠tulo <code class="highlighter-rouge">Fitted Regression for Salary</code>) n√£o representa bem o conjunto de dados (no pr√≥ximo par√°grafo, vamos analisar isso quantitativamente). Ao passo que, quando transformamos $x$, aplicando, nesse caso, a fun√ß√£o $\log(\cdot)$, obtemos uma reta (visualmente) melhor ajustada.</p>

<p>Uma medida que podemos utilizar para quantificar a intui√ß√£o de ‚Äúqual modelo se ajusta melhor aos dados‚Äù √© a quantidade $R^2$ (R-squared); que, a grosso modo, diz o quanto da varia√ß√£o de $y$ √© explicada pela regress√£o. Vamos aproveitar a fun√ß√£o <code class="highlighter-rouge">score()</code> implementada na classe <code class="highlighter-rouge">LinearRegression</code> para obter essa medida.</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">r2_original</span> <span class="o">=</span> <span class="n">regression_original</span><span class="o">.</span><span class="n">score</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span>
<span class="k">print</span><span class="p">(</span><span class="s">"R-squared for the original model: {}."</span><span class="o">.</span><span class="nb">format</span><span class="p">(</span><span class="n">r2_original</span><span class="p">))</span>
<span class="k">print</span><span class="p">(</span><span class="s">"Intercept: {} &amp; Coefficients: {}."</span><span class="o">.</span><span class="nb">format</span><span class="p">(</span><span class="n">regression_original</span><span class="o">.</span><span class="n">intercept_</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">regression_original</span><span class="o">.</span><span class="n">coef_</span><span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">]))</span>
</code></pre></div></div>

<div class="highlighter-rouge"><div class="highlight"><pre class="highlight"><code>R-squared for the original model: 0.7538771643539155.
Intercept: 7.975309624979791 &amp; Coefficients: 9.828555226466561e-05.
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">r2_transformed</span> <span class="o">=</span> <span class="n">regression_transformed</span><span class="o">.</span><span class="n">score</span><span class="p">(</span><span class="n">X_transformed</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span>
<span class="k">print</span><span class="p">(</span><span class="s">"R-squared for the 'tranformed' model: {}."</span><span class="o">.</span><span class="nb">format</span><span class="p">(</span><span class="n">r2_transformed</span><span class="p">))</span>
<span class="k">print</span><span class="p">(</span><span class="s">"Intercept: {} &amp; Coefficients: {}."</span><span class="o">.</span><span class="nb">format</span><span class="p">(</span><span class="n">regression_transformed</span><span class="o">.</span><span class="n">intercept_</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">regression_transformed</span><span class="o">.</span><span class="n">coef_</span><span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">]))</span>
</code></pre></div></div>

<div class="highlighter-rouge"><div class="highlight"><pre class="highlight"><code>R-squared for the 'tranformed' model: 0.9431020022916391.
Intercept: 0.12929691342341698 &amp; Coefficients: 0.9867610189477893.
</code></pre></div></div>

<p>Mais uma vez, o primeiro resultado diz respeito ao modelo que considera $x$, enquanto que o segundo, ao modelo que considera $\log(x)$ como vari√°vel independente. Perceba que, quando aplicamos a tranforma√ß√£o no nosso preditor ‚Äúsal√°rio‚Äù, obtemos um $R^2$ maior $-$ que √©, <strong>quase</strong> sempre, melhor.</p>

<p>Um ponto importante √© como devemos interpretar, quando olhamos para o segundo modelo, o coeficiente que obtemos; aqui, $w_1 \approx 0.987$. Nesse caso, podemos dizer que $1\%$ de aumento do sal√°rio, resulta em aumento de, aproximadamente, $\frac{0.987}{100} = 0.00987$ ‚Äú<em>unidades</em> de felicidade‚Äù.</p>

<h2 id="conclus√£o">Conclus√£o</h2>

<p>No come√ßo do texto vimos que, para aplicar os modelos lineares que estudamos at√© agora (seja de classifica√ß√£o, seja de regress√£o), basta que, olhando para a express√£o $\sum_{i = 0}^{d} w_i x_i$, os $w_i$‚Äôs sejam lineares; ou seja, podemos aplicar transforma√ß√µes n√£o-lineares no conjunto de dados $X$. Nesse sentido, vimos dois exemplos (implementados em Python), nos quais transforma√ß√µes do tipo $(\cdot)^2$ e $\log(\cdot)$ foram aplicadas. No pr√≥ximo post vamos falar um pouco mais sobre medidas de erro.</p>

<p>Qualquer d√∫vida, sugest√£o ou <em>feedback</em>, por favor, deixe um coment√°rio abaixo.</p>

<blockquote>
  <p>Essa postagem faz parte de uma <a href="/categorias/#machine-learning-learning-from-data">s√©rie</a> de textos que tem o objetivo de estudar, principalmente, o curso ‚Äú<a href="http://www.work.caltech.edu/telecourse.html">Learning from Data</a>‚Äù, ministrado pelo Professor Yaser Abu-Mostafa. Outros materiais utilizados ser√£o sempre referenciados.</p>
</blockquote>
:ET