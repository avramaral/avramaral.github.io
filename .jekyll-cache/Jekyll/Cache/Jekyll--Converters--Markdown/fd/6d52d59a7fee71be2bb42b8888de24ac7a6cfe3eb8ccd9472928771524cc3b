I"≥<p>O que n√≥s fizemos at√© agora foi, dado um conjunto $\mathcal{D}$, treinar um modelo que ‚Äúexplicasse‚Äù (no caso do Perceptron, ‚Äúclassificasse‚Äù) os dados $(\mathbf{x}_1, y_1), \cdots, (\mathbf{x}_N, y_N)$. Por√©m, isso significa, de fato, aprender? Isto √©, a fun√ß√£o $g \in \mathcal{H}$ escolhida pelo algoritmo aproxima a fun√ß√£o alvo $f$ no sentido de ter bom desempenho em explicar $\mathbf{x} \not\in \mathcal{D}$?</p>
:ET