I"‡S<p>Ao longo desse post vamos, como temos feito para todos os modelos que discutimos at√© agora <a href="/categorias/#machine-learning-learning-from-data">nessa s√©rie de textos</a>, estudar o que s√£o, do ponto de vista mais te√≥rico, as redes neurais. A ideia √© que, na pr√≥xima postagem, a gente consiga implementar em Python o que vamos estudar a partir desse momento.</p>

<p>Para come√ßar, podemos tentar definir o que s√£o as <strong>redes neurais</strong>. Bem, h√° v√°rias analogias sobre como o modelo matem√°tico que recebe o nome de ‚Äúrede neural‚Äù se compara √† forma atrav√©s da qual o ser humano aprende, etc., etc. Mas, grosso modo, redes neurais s√£o modelos, compostos por pequenas ‚Äúpe√ßas‚Äù, que t√™m o objetivo de aprender (no sentido que temos estudado) fun√ß√µes mais complexas. Essas ‚Äúpe√ßas‚Äù podem, em ess√™ncia, ser constru√≠das a partir de qualquer transforma√ß√£o n√£o-linear. Por√©m, o caso mais comum √© trabalharmos com blocos que utilizam fun√ß√µes do tipo ‚Äú<em>s-shaped curves</em>‚Äù. A imagem abaixo ilustra uma combina√ß√£o desse tipo.</p>

<p><img src="/assets/images/redes-neurais/rede-neural.png" alt="Rede Neural" />
<em>Figura 1 [fonte: ‚Äú<a href="http://www.work.caltech.edu/textbook.html">Learning from Data</a>‚Äù] $-$ Rede Neural.</em></p>

<p>A partir da Fig 1., podemos identificar algumas componentes. Em primeiro lugar, cada coluna de ‚Äún√≥s‚Äù (ou ‚Äú<em>nodes</em>‚Äù) √© chamada de ‚Äú<em>layer</em>‚Äù (ou ‚Äúcamada‚Äù); √† primeira camada, vamos dar o nome de ‚Äú<em>input</em>‚Äù, e √† √∫ltima, ‚Äú<em>output</em>‚Äù $-$ as camadas intermedi√°rias v√£o ser chamadas de ‚Äú<em>hidden layers</em>‚Äù. A fun√ß√£o de ativa√ß√£o $\theta$ ser√° definida a partir da ‚Äútangente hiperb√≥lica‚Äù; i.e., $\theta(s) = \tanh(s) = \frac{e^s - e^{-s}}{e^s + e^{-s}}$. A imagem abaixo ilustra o comportamento de $\theta(s)$.</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="o">%</span><span class="n">matplotlib</span> <span class="n">inline</span>
<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="n">np</span>
<span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="k">as</span> <span class="n">plt</span>

<span class="k">def</span> <span class="nf">theta_func</span><span class="p">(</span><span class="n">s</span><span class="p">):</span>
    <span class="k">return</span> <span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">exp</span><span class="p">(</span><span class="n">s</span><span class="p">)</span> <span class="o">-</span> <span class="n">np</span><span class="o">.</span><span class="n">exp</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span> <span class="o">*</span> <span class="n">s</span><span class="p">))</span> <span class="o">/</span> <span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">exp</span><span class="p">(</span><span class="n">s</span><span class="p">)</span> <span class="o">+</span> <span class="n">np</span><span class="o">.</span><span class="n">exp</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span> <span class="o">*</span> <span class="n">s</span><span class="p">))</span>

<span class="n">x</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">linspace</span><span class="p">(</span><span class="o">-</span><span class="mi">6</span><span class="p">,</span> <span class="mi">6</span><span class="p">,</span> <span class="n">num</span> <span class="o">=</span> <span class="mi">120</span><span class="p">)</span>
<span class="n">y</span> <span class="o">=</span> <span class="n">theta_func</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">axvline</span><span class="p">(</span> <span class="mi">0</span><span class="p">,</span> <span class="n">linestyle</span> <span class="o">=</span> <span class="s">"--"</span><span class="p">,</span> <span class="n">color</span> <span class="o">=</span> <span class="s">"black"</span><span class="p">,</span> <span class="n">linewidth</span> <span class="o">=</span> <span class="mi">1</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">axhline</span><span class="p">(</span> <span class="mi">0</span><span class="p">,</span> <span class="n">linestyle</span> <span class="o">=</span> <span class="s">"--"</span><span class="p">,</span> <span class="n">color</span> <span class="o">=</span> <span class="s">"black"</span><span class="p">,</span> <span class="n">linewidth</span> <span class="o">=</span> <span class="mi">1</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">axhline</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="n">linestyle</span> <span class="o">=</span> <span class="s">"--"</span><span class="p">,</span> <span class="n">color</span> <span class="o">=</span> <span class="s">"black"</span><span class="p">,</span> <span class="n">linewidth</span> <span class="o">=</span> <span class="mi">1</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">axhline</span><span class="p">(</span> <span class="mi">1</span><span class="p">,</span> <span class="n">linestyle</span> <span class="o">=</span> <span class="s">"--"</span><span class="p">,</span> <span class="n">color</span> <span class="o">=</span> <span class="s">"black"</span><span class="p">,</span> <span class="n">linewidth</span> <span class="o">=</span> <span class="mi">1</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">xlim</span><span class="p">(</span><span class="o">-</span><span class="mi">6</span><span class="p">,</span> <span class="mi">6</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s">"s"</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s">"$</span><span class="err">\</span><span class="s">Theta$(s)"</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</code></pre></div></div>

<p><img src="/assets/images/redes-neurais/redes-neurais_4_0.png" alt="png" /></p>

<p>Como pode ser visto a partir do gr√°fico acima, a maneira atrav√©s da qual definimos a fun√ß√£o $\theta$ √© muito parecida com o que fizemos na <a href="/modelo-de-regressao-logistica/">parte 11</a>, quando estudamos o modelo de regress√£o log√≠stica. A raz√£o de termos escolhido uma fun√ß√£o com contradom√≠nio ligeiramente diferente $-$ nesse caso, $\tanh$ $-$ √© a facilidade que temos em lidar com sua derivada.</p>

<p>Agora, vamos estabelecer algumas nota√ß√µes que nos ser√£o √∫teis ao longo do texto. As camadas (ou <em>labels</em>) ser√£o denotadas por $l = 0, 1, 2, \cdots, L$; por exemplo, a camada $l = L$ √© aquela √† qual demos o nome de <em>output</em>. Para nos referirmos a uma determiada camada $l$, utilizaremos o sobrescrito ${}^{(l)}$. Cada <em>layer</em> tem dimens√£o $d^{(l)}$, o que significa que em $l$ existem $d^{(l)} + 1$ n√≥s (lembre-se de $x_0$, chamado tamb√©m de <em>bias</em>).</p>

<p>O conjunto de hip√≥teses para o modelo de rede neural ser√° denotado por $\mathcal{H}_{nn}$, e √© completamente especificado uma vez que √© determinada a <em>arquitetura</em> da rede; ou seja, a dimens√£o <script type="math/tex">\mathbf{d} = [d^{(0)}, \cdots, d^{(L)}]</script> para todas as <em>layers</em>. Similarmente, uma hip√≥tese <script type="math/tex">h \in \mathcal{H}_{nn}</script> √© caracterizada pelo peso <script type="math/tex">w^{(l)}_{i j}</script> atribu√≠do a cada ‚Äúflecha‚Äù da rede. Vamos olhar de mais perto um par de n√≥s da nossa rede.</p>

<p><img src="/assets/images/redes-neurais/uma-relacao.png" alt="Componentes entre um par de n√≥s" />
<em>Figura 2 [fonte: ‚Äú<a href="http://www.work.caltech.edu/textbook.html">Learning from Data</a>‚Äù] $-$ Componentes entre um par de n√≥s.</em></p>

<p>Da Fig. 2, um n√≥ tem um sinal de entrada $s$ e um de sa√≠da $x$. O peso que conecta o n√≥ $j$ (da camada $l$) ao n√≥ $i$ (da camada <strong>anterior</strong>) √© denotado por, como j√° hav√≠amos visto, $w^{(l)}_{i j}$. Dessa forma, teremos $1 \leq l \leq L$, $0 \leq i \leq d^{(l - 1)}$ e $1 \leq j \leq d^{(l)}$.</p>

<p>Al√©m disso, quando tivermos o interesse <em>macro</em> de analisar os termos da nossa rede; ou seja, olhar para as camadas como componentes √∫nicas, podemos utilizar a nota√ß√£o vetorial. Para a cole√ß√£o de sinais de entrada $1, \cdots, d^{(l)}$ na camada $l$, teremos $\mathbf{s}^{(l)}$. De forma parecida, para o conjunto de sa√≠das em $l$, iremos utilizar o vetor $\mathbf{x}^{(l)}$ $-$ composto por elementos de √≠ndices $0, 1, \cdots, d^{(l)}$. Para as ‚Äúflechas‚Äù que conectam $(l-1)$ √† camada $l$, existir√° uma matriz $(d^{(l-1)} + 1) \times d^{(l)}$ de pesos $W^{(l)}$, tal que a $(i, j)$-√©sima entrada de $W^{(l)}$ √© o termo $w^{(l)}_{ij}$. Por fim, todas as matrizes do tipo $W^{(l)}$ ser√£o guardadas em um vetor $\mathbf{w} = [W^{(1)}, \cdots, W^{(L)}]$.</p>

<h3 id="forward-propagation">Forward Propagation</h3>

<p>Para calcularmos o valor de $h(\mathbf{x})$ (e, por consequ√™ncia, o erro $e(h(\mathbf{x}), f(\mathbf{x})$), vamos utilizar o algoritmo ‚Äú<em>Forward Propagation</em>‚Äù (ou, em portugu√™s, algo como ‚ÄúPropaga√ß√£o para Frente‚Äù). Mas antes de qualquer outra coisa, observe que as entradas e sa√≠das em uma camada $l$ podem ser relacionadas por:</p>

<script type="math/tex; mode=display">\begin{align*}
\mathbf{x}^{(l)} = \left[ 1, \theta(\mathbf{s}^{(l)})\right]^{\text{T}},
\end{align*}</script>

<p>onde <script type="math/tex">\theta(\mathbf{s}^{(l)})</script> √© o vetor cujas componentes s√£o <script type="math/tex">\theta(s^{(l)}_j)</script>. Dessa forma, temos que <script type="math/tex">s^{(l)}_j = \sum_{i = 0}^{d^{(l-1)}} w^{(l)}_{ij} x^{(l-1)}_i</script>. Em nota√ß√£o vetorial:</p>

<script type="math/tex; mode=display">\begin{align*}
\mathbf{s}^{(l)} = \left( W^{(l)} \right)^{\text{T}} \mathbf{x}^{(l-1)}.
\end{align*}</script>

<p>Note que, agora, s√≥ falta atribu√≠rmos $\mathbf{x}$ a $\mathbf{x}_0$. Sendo assim, podemos utilizar o algoritmo abaixo para calcular $h(\mathbf{x})$.</p>

<p><img src="/assets/images/redes-neurais/algoritmo-forward.png" alt="Algoritmo Forward Propagation" />
<em>Figura 3 [fonte: ‚Äú<a href="http://www.work.caltech.edu/textbook.html">Learning from Data</a>‚Äù] $-$ Algoritmo Forward Propagation.</em></p>

<p>Calculado $x^{(L)} = h(\mathbf{x})$ podemos, finalmente, determinar $E_{in}$. Utilizando a medida de erro quadr√°tico; isto √©, $e(h(\mathbf{x}), f(\mathbf{x})) = (h(\mathbf{x}) - f(\mathbf{x}))^2$, temos:</p>

<script type="math/tex; mode=display">E_{in} = \frac{1}{N} \sum_{n = 1}^{N}(\mathbf{x}^{(L)}_n - f(\mathbf{x}_n))^2.</script>

<p>Agora, o que temos que fazer √©, como de costume, minimizar $E_{in}$. Discutiremos isso na pr√≥xima se√ß√£o.</p>

<h3 id="backpropagation-algorithm">Backpropagation Algorithm</h3>

<p>Na <a href="/modelo-de-regressao-logistica/">parte 11</a>, utilizamos o algoritmo <em>gradient descent</em> para encontrar $\mathbf{w}$ tal que $E_{in}(\mathbf{w})$ √© m√≠nimo (local). Bastou inicializar $\mathbf{w}(0)$ e, para $t = 1, 2, \cdots$, atualizar o vetor de pesos da seguinte maneira:</p>

<script type="math/tex; mode=display">\begin{align*}
\mathbf{w}(t+1) = \mathbf{w}(t) - \eta \nabla E_{in}(\mathbf{w}(t)).
\end{align*}</script>

<p>Por√©m, para implementar esse procedimento, precisamos encontrar o vetor gradiente. Poder√≠amos fazer isso ‚Äúna m√£o‚Äù; mas √© nesse ponto em que o <em>Backpropagation Algorithm</em> (ou ‚ÄúAlgoritmo de Propaga√ß√£o para Tr√°s‚Äù) entra em a√ß√£o.</p>

<p>Esse algoritmo se baseia em aplica√ß√µes sucessivas da ‚Äúregra da cadeia‚Äù a fim de escrever as derivadas parciais na <em>layer</em> $l$ utilizando, para isso, as derivadas parciais de $l + 1$.</p>

<p>Comece definindo o ‚Äúvetor sensitivo‚Äù ($\mathbf{\delta}^{(l)}$) para a camada $l$ da seguinte forma:</p>

<script type="math/tex; mode=display">\begin{align*}
\mathbf{\delta}^{(l)} = \frac{\partial e(\mathbf{w})}{\partial \mathbf{s}^{(l)}};
\end{align*}</script>

<p>ou seja, $\mathbf{\delta}^{(l)}$ √© a derivada parcial da medida de erro $e(\mathbf{w})$ com respeito ao sinal de entrada $\mathbf{s}^{(l)}$. Dessa forma, podemos escrever a derivada de interesse como:</p>

<script type="math/tex; mode=display">\begin{align*}
\frac{\partial e(\mathbf{w})}{\partial W^{(l)}} = \mathbf{x}^{(l-1)}(\mathbf{\delta}^{(l)})^{\text{T}}
\end{align*}.</script>

<p>Aqui, note que $\frac{\partial \mathbf{s}^{(l)}}{\partial W^{(l)}} = \mathbf{x}^{(l-1)}$. Assim, como o termo $\mathbf{x}^{(l)}$, para $l \geq 0$, pode ser obtido por <em>forward propagation</em>, √© suficiente que nos preocupemos apenas com $\mathbf{\delta}^{(l)}$. E √© aqui que as coisas ficam interessantes. Com uma pequena modifica√ß√£o na rede e ‚Äúrodando-a‚Äù <em>ao contr√°rio</em> (por isso o nome ‚Äú<em>backpropagation</em>‚Äù), conseguimos $\mathbf{\delta}^{(l)}$.</p>

<p>Ao inv√©s de cada <em>layer</em> ‚Äúcuspir‚Äù o vetor $\mathbf{x}^{(l)}$ (como acontece quando estamos no algoritmo <em>forward propagation</em>), fazendo o caminho inverso, cada camada ir√° devolver o vetor $\mathbf{\delta}^{(l)}$.</p>

<p>Em rela√ß√£o √† ‚Äúpequena modifica√ß√£o‚Äù que temos que fazer, agora cada n√≥ faz uma transforma√ß√£o do tipo ‚Äúmultiplica√ß√£o por $\theta^{\prime}(\mathbf{s}^{(l)})$‚Äù. Sendo assim, se $\theta(\cdot) = \tanh(\cdot)$, ent√£o $\tanh^{\prime}(\mathbf{s}^{(l)}) = 1-\tanh^2(\mathbf{s}^{(l)}) = 1 - \mathbf{x}^{(l)} \otimes\mathbf{x}^{(l)}$; onde $\otimes$ significa produto termo-a-termo. A imagem abaixo ilustra esse procedimento.</p>

<p><img src="/assets/images/redes-neurais/backpropagation.png" alt="Backpropagation" />
<em>Figura 4 [fonte: ‚Äú<a href="http://www.work.caltech.edu/textbook.html">Learning from Data</a>‚Äù] $-$ Esquema de ‚ÄúBackpropagation‚Äù.</em></p>

<p>Al√©m disso, a partir da Fig. 4, vemos que a camada $(l+1)$ ‚Äúcospe‚Äù (para tr√°s) o vetor $\mathbf{\delta}^{(l+1)}$, que √© multiplicado por $W^{(l+1)}$, somado, e entregue para os n√≥s da <em>layer</em> $l$. Essa opera√ß√£o pode ser escrita como:</p>

<script type="math/tex; mode=display">\begin{align*}
\mathbf{\delta}^{(l)} = \theta^{\prime}(\mathbf{s}^{(l)}) \otimes \left[ W^{(l + 1)} \mathbf{\delta}^{(l+1)} \right]^{d^{(l)}}_1,
\end{align*}</script>

<p>onde o vetor $\left[ W^{(l + 1)} \mathbf{\delta}^{(l+1)} \right]^{d^{(l)}}_1$ cont√©m as componentes de $W^{(l + 1)} \mathbf{\delta}^{(l+1)} $, exclu√≠ndo o valor de √≠ndice zero (excluindo o termo ‚Äú<em>bias</em>‚Äù). <strong>Observa√ß√£o 1:</strong> a igualdade acima n√£o √© trivial; para ver o passo-a-passo de como obt√™-la, consulte o cap√≠tulo e-7 de
<a href="">Learning from Data</a>.</p>

<p>Sendo assim, se temos $\mathbf{\delta}^{(l+1)}$, podemos encontrar $\mathbf{\delta}^{(l)}$. Para iniciar essa ‚Äúcadeia‚Äù, basta determinar $\mathbf{\delta}^{(L)}$:</p>

<script type="math/tex; mode=display">% <![CDATA[
\begin{align*}
\mathbf{\delta}^{(L)} & = \frac{\partial e(\mathbf{w})}{\partial \mathbf{s}^{(L)}} \\
& = \frac{\partial}{\partial \mathbf{s}^{(L)}} (\mathbf{x}^{L} - f(\mathbf{x}))^2 \\
& 2(\mathbf{x}^{(L)} - f(\mathbf{x})) \frac{\partial \mathbf{x}^{(L)}}{\partial \mathbf{s}^{(L)}} \\
& 2(\mathbf{x}^{(L)} - f(\mathbf{x})) \theta^{\prime}(\mathbf{s}^{(L)}).
\end{align*} %]]></script>

<p><strong>Observa√ß√£o 2:</strong> quando a transforma√ß√£o de sa√≠da √© $\theta(\cdot) = \tanh(\cdot)$, temos que $\theta^{\prime}(\mathbf{s}^{(L)}) = 1 - (\mathbf{x}^{(L)})^2$; por√©m, quando a transforma√ß√£o de sa√≠da √© a fun√ß√£o identidade, $\theta^{\prime}(\mathbf{s}^{(L)}) = 1$. <strong>Observa√ß√£o 3:</strong> se existir somente um n√≥ de sa√≠da, $\mathbf{s}^{(L)}$ √© escalar (e, por consequ√™ncia, $\mathbf{\delta}^{(L)}$ tamb√©m).</p>

<p>Por fim, utilizando a f√≥rmula de $\mathbf{\delta}^{(l)}$, podemos calcular todos os ‚Äúvetores sensitivos‚Äù. O algoritmo para esse tipo de dedu√ß√£o √© apresentado a seguir (assumindo transforma√ß√£o nas <em>hidden layers</em> igual a $\tanh(\cdot)$ $-$ se esse n√£o for o caso, adaptar o passo $3$).</p>

<p><img src="/assets/images/redes-neurais/calculate-sensitivity.png" alt="Algoritmo Backpropagation" />
<em>Figura 5 [fonte: ‚Äú<a href="http://www.work.caltech.edu/textbook.html">Learning from Data</a>‚Äù] $-$ Algoritmo ‚ÄúBackpropagation‚Äù.</em></p>

<p>Agora, para obter a derivada da medida de erro com respeito ao vetor de pesos, basta lembrar que $\frac{\partial e(\mathbf{w})}{\partial W^{(l)}} = \mathbf{x}^{(l-1)}(\mathbf{\delta}^{(l)})^{\text{T}}$.</p>

<p>Estamos quase l√°! O que vamos fazer a seguir √© calcular a derivada de $E_{in}(h)$, como gostar√≠amos que fosse feito (mas veremos na √∫ltima parte desse texto que existe, nesse sentido, uma abordagem melhor: o <em>stochastic gradient descent</em>):</p>

<script type="math/tex; mode=display">\begin{align*}
\frac{\partial E_{in}}{\partial W^{(l)}} = \frac{1}{N} \sum^{N}_{n = 1} \frac{\partial e(\mathbf{x}_n)}{\partial W^{(l)}}.
\end{align*}</script>

<p>O algorimo a seguir, onde $G^{(l)}(\mathbf{x}_n)$ √© o vetor gradiente no ponto $\mathbf{x}_n$, sumariza tudo que fizemos at√© agora.</p>

<p><img src="/assets/images/redes-neurais/algoritmo-gradiente.png" alt="Algoritmo Gradiente" />
<em>Figura 6 [fonte: ‚Äú<a href="http://www.work.caltech.edu/textbook.html">Learning from Data</a>‚Äù] $-$ Algoritmo para c√°lculo do vetor gradiente.</em></p>

<h3 id="stochastic-gradient-descent">Stochastic Gradient Descent</h3>

<p>Existe uma vers√£o do algoritmo de gradiente descendente, conhecida como <em>Stochastic Gradient Descent</em>, que reduz consideravelmente o tempo computacional gasto para minimizar $E_{in}$.</p>

<p>No algoritmo de <em>gradient descent</em> que hav√≠amos visto at√© ent√£o, o vetor gradiente era calculado para todo o conjunto de dados antes de sermos capazes de atualizar $\mathbf{w}$. Nessa nova vers√£o, ao inv√©s de considerar os $N$ pontos, escolha um $(\mathbf{x}_n, y_n)$ uniformemente em $\mathcal{D}$ e leve em conta apenas esse ‚Äòpar ordenado‚Äô para calcular a derivada ($e^{\prime}(\mathbf{w})$); ent√£o, esse vetor gradiente obtido √© utilizado para atualizar o vetor de pesos <strong>da mesma forma</strong> que faz√≠amos antes.</p>

<p>A ideia de o porqu√™ isso funciona vem do fato de que:</p>

<script type="math/tex; mode=display">% <![CDATA[
\begin{align*}
\mathbb{E}_{\mathbf{x}_n}\left[\nabla e(h(\mathbf{x}_n), f(\mathbf{x}_n))\right] & = \frac{1}{N}\sum_{n = 1}^{N} \nabla e(h(\mathbf{x}_n), f(\mathbf{x}_n)) \\
& = \nabla E_{in}(h);
\end{align*} %]]></script>

<p>ou seja, ‚Äúem m√©dia‚Äù, o vetor gradiente leva o processo de minimiza√ß√£o para a dire√ß√£o correta (exceto por pequenos desvios).</p>

<p>Al√©m de ser computacionalmente mais barato, o <em>Stochastic Gradient Descent</em> tamb√©m nos ajuda a contornar problemas de ‚Äúficar preso em m√≠nimos locais‚Äù $-$ j√° que a minimiza√ß√£o, como dito, n√£o √© ‚Äúdireta‚Äù.</p>

<p>Se utilizarmos essa t√©cnica para minimizar o termo $E_{in}$ na nossa rede neural, o algoritmo <strong>geral</strong> pode ser estabelecido como:</p>

<p><img src="/assets/images/redes-neurais/algoritmo-final.png" alt="Algoritmo Final" />
<em>Figura 7 [fonte: ‚Äú<a href="http://www.work.caltech.edu/textbook.html">Learning from Data</a>‚Äù] $-$ Algoritmo geral para rede neural.</em></p>

<h2 id="conclus√£o">Conclus√£o</h2>

<p>Ao longo do texto, vimos como resolver, peda√ßo por peda√ßo, os problemas que enfrentamos quando tentamos implementar um modelo do tipo ‚Äúrede neural‚Äù. Vimos que, depois de constru√≠da a arquitetura da rede, calcular as medidas de erro n√£o foi um problema $-$ bastou utilizar o algoritmo <em>Forward Propagation</em>. Por√©m, quando tentammos encontrar $\mathbf{w}$ que minimiza $E_{in}$, percebemos que definir o vetor gradiente $\nabla E_{in}(\mathbf{w})$ n√£o √© tarefa f√°cil. Aqui, o <em>Backpropagation Algorithm</em> nos foi muito √∫til e resolveu esse problema. Por fim, vimos a vantagem de implementar o algoritmo <em>Stochastic Grandient Descent</em> ao inv√©s do gradiente descendente ‚Äúnormal‚Äù que hav√≠amos visto no post passado. Na pr√≥xima postagem, vamos fazer a implementa√ß√£o em Python do que estudamos hoje.</p>

<p>Qualquer d√∫vida, sugest√£o ou <em>feedback</em>, por favor, deixe um coment√°rio abaixo.</p>

<blockquote>
  <p>Essa postagem faz parte de uma <a href="/categorias/#machine-learning-learning-from-data">s√©rie</a> de textos que tem o objetivo de estudar, principalmente, o curso ‚Äú<a href="http://www.work.caltech.edu/telecourse.html">Learning from Data</a>‚Äù, ministrado pelo Professor Yaser Abu-Mostafa. Outros materiais utilizados ser√£o sempre referenciados.</p>
</blockquote>
:ET