I"Rw<p>Como mencionado na <a href="/o-que-e-aprendizado/">parte 01</a> <a href="/categorias/#machine-learning-learning-from-data">dessa série de textos</a>, essa postagem será dedicada à implementação do <em>Perceptron Learning Algorithm</em> (PLA) em Python, utilizando, para isso, a biblioteca Numpy. Discutiremos um exemplo e, ao final, vamos ver como utilizar a implementação desse mesmo algoritmo pela biblioteca Sklearn.</p>

<p>O código a seguir é baseado (feitas algumas modificações) nos capítulos iniciais do que é apresentado no livro <a href="https://sebastianraschka.com/books.html">Python Machine Learning</a>.</p>

<p>Primeiro vamos à implementação do algoritmo, e depois discutiremos os trechos do que foi escrito. Considere a classe <code class="highlighter-rouge">Perceptron</code> a seguir:</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="n">np</span>

<span class="c1"># Raw implementation
</span><span class="k">class</span> <span class="nc">Perceptron</span><span class="p">():</span>
    <span class="s">"""
    Perceptron learning algorithm implementation
    """</span>
    
    <span class="k">def</span> <span class="nf">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">eta</span> <span class="o">=</span> <span class="mi">1</span><span class="p">,</span> <span class="n">random_seed</span> <span class="o">=</span> <span class="mi">1</span><span class="p">):</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">eta</span> <span class="o">=</span> <span class="n">eta</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">random_seed</span> <span class="o">=</span> <span class="n">random_seed</span>
        
    <span class="k">def</span> <span class="nf">fit</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">):</span>
        <span class="n">rn</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">RandomState</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">random_seed</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">w_</span> <span class="o">=</span> <span class="n">rn</span><span class="o">.</span><span class="n">normal</span><span class="p">(</span><span class="n">loc</span> <span class="o">=</span> <span class="mi">0</span><span class="p">,</span> <span class="n">scale</span> <span class="o">=</span> <span class="mf">0.01</span><span class="p">,</span> <span class="n">size</span> <span class="o">=</span> <span class="n">X</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span> <span class="o">+</span> <span class="mi">1</span><span class="p">)</span>
        <span class="n">errors</span> <span class="o">=</span> <span class="bp">True</span>
        
        <span class="k">while</span> <span class="n">errors</span><span class="p">:</span>
            <span class="n">errors</span> <span class="o">=</span> <span class="mi">0</span>
            <span class="k">for</span> <span class="n">X_i</span><span class="p">,</span> <span class="n">y_i</span> <span class="ow">in</span> <span class="nb">zip</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">):</span>
                <span class="k">if</span><span class="p">(</span><span class="n">y_i</span> <span class="o">!=</span> <span class="bp">self</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X_i</span><span class="p">)):</span>
                    <span class="c1"># update weights vector for misclassified points
</span>                    <span class="n">update</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">eta</span> <span class="o">*</span> <span class="n">y_i</span>
                    <span class="bp">self</span><span class="o">.</span><span class="n">w_</span><span class="p">[</span><span class="mi">1</span><span class="p">:]</span> <span class="o">+=</span> <span class="n">update</span> <span class="o">*</span> <span class="n">X_i</span>
                    <span class="bp">self</span><span class="o">.</span><span class="n">w_</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">+=</span> <span class="n">update</span> 
                    <span class="n">errors</span> <span class="o">+=</span> <span class="mi">1</span>
                    
        <span class="k">return</span> <span class="bp">self</span>
    
    <span class="k">def</span> <span class="nf">predict</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">X_i</span><span class="p">):</span>
        <span class="n">eval_func</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="n">X_i</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">w_</span><span class="p">[</span><span class="mi">1</span><span class="p">:])</span> <span class="o">+</span> <span class="bp">self</span><span class="o">.</span><span class="n">w_</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="c1"># ATTENTION: this implemented arguments order is more intuitive
</span>        <span class="k">return</span> <span class="n">np</span><span class="o">.</span><span class="n">where</span><span class="p">(</span><span class="n">eval_func</span> <span class="o">&gt;=</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">)</span>
</code></pre></div></div>

<p>Note que, para criar uma instância da classe, são necessários dois parâmetros: o primeiro deles, <code class="highlighter-rouge">eta</code>, diz respeito a uma pequena generalização feita na regra de atualização do vetor $\mathbf{w}$ (discutida no próximo parágrafo), enquanto que o parâmetro <code class="highlighter-rouge">random_seed</code> define uma semente para geração aleatória do vetor inicial de pesos.</p>

<p>Como acabei de dizer, podemos generalizar a regra de atualização de $\mathbf{w}$ apresentada na parte 01 dessa série introduzindo o parâmetro $\eta$. A regra, então, ficaria assim:</p>

<script type="math/tex; mode=display">\begin{align*}
    \mathbf{w}(t+1) = \mathbf{w}(t) + \eta \, y(t) \, \mathbf{x}(t)
\end{align*}</script>

<p>Perceba que para $\eta = 1$, a regra é exatamente a mesma que vimos antes. Dessa forma, a única coisa que $\eta$ faz é mexer no quanto a reta definida por $\mathbf{w}$ “se move” para classificar corretamente o ponto considerado. Nesse sentido, perceba que, para $\eta$ grande, a chance de eu “bagunçar” a classificação dos demais pontos também é grande; portanto, $\eta$ maior não é necessariamente melhor (normalmente, $0 &lt; \eta \leq 1$).</p>

<p>Continuando, o método <code class="highlighter-rouge">__init__()</code> apenas inicializa os atributos <code class="highlighter-rouge">eta</code> e <code class="highlighter-rouge">random_seed</code>. O método <code class="highlighter-rouge">fit()</code> é o que, de fato, ajusta o modelo; ou seja, ajusta os valores do vetor $\mathbf{w}$. Nesse caso, para os pontos que não estão classificados corretamente (<code class="highlighter-rouge">y_i != self.predict(X_i)</code>), o atributo <code class="highlighter-rouge">w_</code> é atualizado de acordo com a regra que acabamos de discutir $-$ esse processo é realizado quantas vezes forem necessárias. Uma tecnicalidade importante é a de que o vetor de pesos não deve ser inicializado com todas as entradas nulas; caso isso aconteça, o termo <code class="highlighter-rouge">update * X_i</code> afetará somente a escala de $\mathbf{w}$. Por fim, o método <code class="highlighter-rouge">predict()</code>, baseado na função $h(\mathbf{x})$ definida no post anterior, faz a classificação de cada ponto (ou conjunto de pontos) <code class="highlighter-rouge">X_i</code>.</p>

<p>Para verificar o funcionamento do algoritmo, vamos utilizar o conjunto de dados <a href="https://archive.ics.uci.edu/ml/datasets/iris">Iris</a>, que classifica três espécies de flores de acordo com o comprimento e largura de suas pétalas e sépalas. Veja as primeiras linhas do conjunto de dados:</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="o">%</span><span class="n">matplotlib</span> <span class="n">inline</span>
<span class="kn">import</span> <span class="nn">pandas</span> <span class="k">as</span> <span class="n">pd</span>
<span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="k">as</span> <span class="n">plt</span>

<span class="c1"># Iris Data Set
</span><span class="n">df</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">read_csv</span><span class="p">(</span><span class="s">"https://bit.ly/2Mg0qkZ"</span><span class="p">,</span> <span class="n">header</span> <span class="o">=</span> <span class="bp">None</span><span class="p">,</span> <span class="n">encoding</span> <span class="o">=</span> <span class="s">"UTF"</span><span class="p">)</span>

<span class="n">df</span><span class="o">.</span><span class="n">columns</span> <span class="o">=</span> <span class="p">[</span><span class="s">'sepal-length'</span><span class="p">,</span> <span class="s">'sepal-width'</span><span class="p">,</span> <span class="s">'petal-length'</span><span class="p">,</span> <span class="s">'petal-width'</span><span class="p">,</span> <span class="s">'category'</span><span class="p">]</span>
<span class="n">df</span><span class="o">.</span><span class="n">head</span><span class="p">()</span>
</code></pre></div></div>

<div>
<style scoped="">
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>sepal-length</th>
      <th>sepal-width</th>
      <th>petal-length</th>
      <th>petal-width</th>
      <th>category</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>5.1</td>
      <td>3.5</td>
      <td>1.4</td>
      <td>0.2</td>
      <td>Iris-setosa</td>
    </tr>
    <tr>
      <th>1</th>
      <td>4.9</td>
      <td>3.0</td>
      <td>1.4</td>
      <td>0.2</td>
      <td>Iris-setosa</td>
    </tr>
    <tr>
      <th>2</th>
      <td>4.7</td>
      <td>3.2</td>
      <td>1.3</td>
      <td>0.2</td>
      <td>Iris-setosa</td>
    </tr>
    <tr>
      <th>3</th>
      <td>4.6</td>
      <td>3.1</td>
      <td>1.5</td>
      <td>0.2</td>
      <td>Iris-setosa</td>
    </tr>
    <tr>
      <th>4</th>
      <td>5.0</td>
      <td>3.6</td>
      <td>1.4</td>
      <td>0.2</td>
      <td>Iris-setosa</td>
    </tr>
  </tbody>
</table>
</div>

<p>Entretanto, para que consigamos visualizar facilmente o resultado do algoritmo, vamos nos concentrar em duas <em>features</em>: “Sepal length” e “Petal length”. Além disso, vamos denotar a espécie “Iris Setosa” (50 primeiras linhas) por $-1$ e a espécie “Iris Versicolor” (linhas 50 a 100) por $+1$. Nesse caso, não utilizaremos as informações da terceira espécie; já que o Perceptron é um classificador <strong>binário</strong>. Veja como ficaram os dados:</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">df</span> <span class="o">=</span> <span class="n">df</span><span class="o">.</span><span class="n">loc</span><span class="p">[</span><span class="mi">0</span><span class="p">:</span><span class="mi">100</span><span class="p">,</span> <span class="p">[</span><span class="s">'sepal-length'</span><span class="p">,</span> <span class="s">'petal-length'</span><span class="p">,</span> <span class="s">'category'</span><span class="p">]]</span>

<span class="n">X</span> <span class="o">=</span> <span class="n">df</span><span class="o">.</span><span class="n">loc</span><span class="p">[</span><span class="mi">0</span><span class="p">:</span><span class="mi">100</span><span class="p">,</span> <span class="p">[</span><span class="s">'sepal-length'</span><span class="p">,</span> <span class="s">'petal-length'</span><span class="p">]]</span><span class="o">.</span><span class="n">values</span>
<span class="n">y</span> <span class="o">=</span> <span class="n">df</span><span class="o">.</span><span class="n">category</span><span class="o">.</span><span class="n">values</span>
<span class="n">y</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">where</span><span class="p">(</span><span class="n">y</span> <span class="o">==</span> <span class="s">'Iris-setosa'</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>

<span class="n">plt</span><span class="o">.</span><span class="n">scatter</span><span class="p">(</span><span class="n">X</span><span class="p">[</span><span class="mi">0</span><span class="p">:</span><span class="mi">50</span><span class="p">,</span> <span class="mi">0</span><span class="p">],</span> <span class="n">X</span><span class="p">[</span><span class="mi">0</span><span class="p">:</span><span class="mi">50</span><span class="p">,</span> <span class="mi">1</span><span class="p">],</span> <span class="n">color</span> <span class="o">=</span> <span class="s">"red"</span><span class="p">,</span> <span class="n">marker</span> <span class="o">=</span> <span class="s">"o"</span><span class="p">,</span> <span class="n">label</span> <span class="o">=</span> <span class="s">"Iris-ventosa"</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">scatter</span><span class="p">(</span><span class="n">X</span><span class="p">[</span><span class="mi">50</span><span class="p">:</span><span class="mi">100</span><span class="p">,</span> <span class="mi">0</span><span class="p">],</span> <span class="n">X</span><span class="p">[</span><span class="mi">50</span><span class="p">:</span><span class="mi">100</span><span class="p">,</span> <span class="mi">1</span><span class="p">],</span> <span class="n">color</span> <span class="o">=</span> <span class="s">"green"</span><span class="p">,</span> <span class="n">marker</span> <span class="o">=</span> <span class="s">"s"</span><span class="p">,</span> <span class="n">label</span> <span class="o">=</span> <span class="s">"Iris-versicolor"</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s">'Sepal length [cm]'</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s">'Petal length [cm]'</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">legend</span><span class="p">(</span><span class="n">loc</span> <span class="o">=</span> <span class="mi">2</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</code></pre></div></div>

<p><img src="/assets/images/implementacao_perceptron_files/perceptron_10_0.png" alt="png" /></p>

<p>Agora podemos ajustar o modelo:</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">my_perceptron</span> <span class="o">=</span> <span class="n">Perceptron</span><span class="p">()</span>
<span class="n">my_perceptron</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span>

<span class="k">print</span><span class="p">(</span><span class="s">"Weights vector: {}."</span><span class="o">.</span><span class="nb">format</span><span class="p">(</span><span class="n">my_perceptron</span><span class="o">.</span><span class="n">w_</span><span class="p">))</span>
</code></pre></div></div>

<div class="highlighter-rouge"><div class="highlight"><pre class="highlight"><code>Weights vector: [-1.98375655 -3.50611756  9.19471828].
</code></pre></div></div>

<p>Nesse caso, instanciamos um objeto da classe <code class="highlighter-rouge">Perceptron</code> e depois ajustamos o modelo baseado no conjunto de dados que acabamos de filtrar. Note, então, que o vetor <code class="highlighter-rouge">w_</code> foi completamente determinado. Assim, o que podemos fazer é visualizar os resultados de forma gráfica. Para isso, utiizaremos a função a seguir, <code class="highlighter-rouge">plot_decision_regions()</code>:</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">def</span> <span class="nf">plot_decision_regions</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">classifier</span><span class="p">,</span> <span class="n">feature_names</span><span class="p">,</span> <span class="n">resolution</span> <span class="o">=</span> <span class="mf">0.01</span><span class="p">):</span>
    <span class="c1"># general settings
</span>    <span class="n">markers</span> <span class="o">=</span> <span class="p">[</span><span class="s">"o"</span><span class="p">,</span> <span class="s">"s"</span><span class="p">,</span> <span class="s">"*"</span><span class="p">,</span> <span class="s">"x"</span><span class="p">,</span> <span class="s">"v"</span><span class="p">]</span>
    <span class="n">colors</span>  <span class="o">=</span> <span class="p">(</span><span class="s">"red"</span><span class="p">,</span> <span class="s">"green"</span><span class="p">,</span> <span class="s">"blue"</span><span class="p">,</span> <span class="s">"gray"</span><span class="p">,</span> <span class="s">"cyan"</span><span class="p">)</span>
    <span class="n">x1_min</span><span class="p">,</span> <span class="n">x1_max</span> <span class="o">=</span> <span class="n">X</span><span class="p">[:,</span> <span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="nb">min</span><span class="p">()</span> <span class="o">-</span> <span class="mf">0.5</span><span class="p">,</span> <span class="n">X</span><span class="p">[:,</span> <span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="nb">max</span><span class="p">()</span> <span class="o">+</span> <span class="mf">0.5</span>
    <span class="n">x2_min</span><span class="p">,</span> <span class="n">x2_max</span> <span class="o">=</span> <span class="n">X</span><span class="p">[:,</span> <span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="nb">min</span><span class="p">()</span> <span class="o">-</span> <span class="mf">0.5</span><span class="p">,</span> <span class="n">X</span><span class="p">[:,</span> <span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="nb">max</span><span class="p">()</span> <span class="o">+</span> <span class="mf">0.5</span>
    <span class="c1"># define a grid
</span>    <span class="n">xx1</span><span class="p">,</span> <span class="n">xx2</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">meshgrid</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="n">x1_min</span><span class="p">,</span> <span class="n">x1_max</span><span class="p">,</span> <span class="n">resolution</span><span class="p">),</span>
                           <span class="n">np</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="n">x2_min</span><span class="p">,</span> <span class="n">x2_max</span><span class="p">,</span> <span class="n">resolution</span><span class="p">))</span>
    <span class="c1"># classify each grid point
</span>    <span class="n">result</span> <span class="o">=</span> <span class="n">classifier</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="n">xx1</span><span class="o">.</span><span class="n">ravel</span><span class="p">(),</span> <span class="n">xx2</span><span class="o">.</span><span class="n">ravel</span><span class="p">()])</span><span class="o">.</span><span class="n">T</span><span class="p">)</span>
    <span class="n">result</span> <span class="o">=</span> <span class="n">result</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="n">xx1</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>
    <span class="c1"># make a plot
</span>    <span class="n">plt</span><span class="o">.</span><span class="n">contourf</span><span class="p">(</span><span class="n">xx1</span><span class="p">,</span> <span class="n">xx2</span><span class="p">,</span> <span class="n">result</span><span class="p">,</span> <span class="n">colors</span> <span class="o">=</span> <span class="n">colors</span><span class="p">[</span><span class="mi">0</span><span class="p">:</span><span class="nb">len</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">unique</span><span class="p">(</span><span class="n">y</span><span class="p">))],</span> <span class="n">alpha</span> <span class="o">=</span> <span class="mf">0.5</span><span class="p">)</span>
    <span class="k">for</span> <span class="n">index</span><span class="p">,</span> <span class="n">value</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">unique</span><span class="p">(</span><span class="n">y</span><span class="p">)):</span> <span class="c1"># plot each point &amp; 'enumerate()' returns index and value of the given array
</span>        <span class="n">plt</span><span class="o">.</span><span class="n">scatter</span><span class="p">(</span><span class="n">x</span> <span class="o">=</span> <span class="n">X</span><span class="p">[</span><span class="n">y</span> <span class="o">==</span> <span class="n">value</span><span class="p">,</span> <span class="mi">0</span><span class="p">],</span> <span class="n">y</span> <span class="o">=</span> <span class="n">X</span><span class="p">[</span><span class="n">y</span> <span class="o">==</span> <span class="n">value</span><span class="p">,</span> <span class="mi">1</span><span class="p">],</span> <span class="c1"># select each X and y vectors by creating a mask
</span>                    <span class="n">color</span> <span class="o">=</span> <span class="n">colors</span><span class="p">[</span><span class="n">index</span><span class="p">],</span>
                    <span class="n">marker</span> <span class="o">=</span> <span class="n">markers</span><span class="p">[</span><span class="n">index</span><span class="p">],</span>
                    <span class="n">label</span> <span class="o">=</span> <span class="n">feature_names</span><span class="p">[</span><span class="n">index</span><span class="p">],</span>
                    <span class="n">edgecolor</span> <span class="o">=</span> <span class="s">'black'</span><span class="p">)</span>
</code></pre></div></div>

<p>Agora podemos plotar o gráfico de interesse:</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">feature_names</span> <span class="o">=</span> <span class="p">[</span><span class="s">'Iris ventosa'</span><span class="p">,</span> <span class="s">'Iris versicolor'</span><span class="p">]</span>
<span class="n">plot_decision_regions</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">my_perceptron</span><span class="p">,</span> <span class="n">feature_names</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="s">'Fitted model with raw implementation'</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s">'Sepal length [cm]'</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s">'Petal length [cm]'</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">legend</span><span class="p">(</span><span class="n">loc</span> <span class="o">=</span> <span class="mi">2</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</code></pre></div></div>

<p><img src="/assets/images/implementacao_perceptron_files/perceptron_16_0.png" alt="png" /></p>

<p>Como podemos ver, o algoritmo classificou corretamente todas as flores. Entretanto, um ponto muito importante sobre o qual ainda não disctutimos, é a eficiência (ou acurácia) desse modelo para classificar novas observações. Esse tipo de medida será discutida (e implementada) ao longo dos próximos textos.</p>

<p>Antes de finalizar, vamos ver como ajustar esse mesmo modelo utilizando a implementação do Sklearn:</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># Sklearn usage
</span><span class="kn">from</span> <span class="nn">sklearn.linear_model</span> <span class="kn">import</span> <span class="n">Perceptron</span>

<span class="n">sklearn_perceptron</span> <span class="o">=</span> <span class="n">Perceptron</span><span class="p">()</span>
<span class="n">sklearn_perceptron</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span>

<span class="k">print</span><span class="p">(</span><span class="s">"Weight vector (without w_0): {}."</span><span class="o">.</span><span class="nb">format</span><span class="p">(</span><span class="n">sklearn_perceptron</span><span class="o">.</span><span class="n">coef_</span><span class="p">))</span>
</code></pre></div></div>

<div class="highlighter-rouge"><div class="highlight"><pre class="highlight"><code>Weight vector (without w_0): [[-2.4  5. ]].
</code></pre></div></div>

<p>Como a classe Perceptron já está implementada na biblioteca, ajustar o modelo é super simples; basta, mais uma vez, utilizar o método <code class="highlighter-rouge">fit()</code>. O vetor de pesos é ligeiramente diferente, mas também é uma solução para o nosso problema $-$ veja o gráfico abaixo:</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">feature_names</span> <span class="o">=</span> <span class="p">[</span><span class="s">'Iris ventosa'</span><span class="p">,</span> <span class="s">'Iris versicolor'</span><span class="p">]</span>
<span class="n">plot_decision_regions</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">sklearn_perceptron</span><span class="p">,</span> <span class="n">feature_names</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="s">'Fiited model with Sklearn usage'</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s">'Sepal length [cm]'</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s">'Petal length [cm]'</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">legend</span><span class="p">(</span><span class="n">loc</span> <span class="o">=</span> <span class="mi">2</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</code></pre></div></div>

<p><img src="/assets/images/implementacao_perceptron_files/perceptron_21_0.png" alt="png" /></p>

<h2 id="conclusão">Conclusão</h2>

<p>Nessa postagem vimos a implementação em Python do <em>Perceptron Learning Algorithm</em> (PLA) que havíamos discutido antes. Entretanto, a maior parte desses resultados em <em>machine learning</em> já estão disponíveis através da biblioteca Sklearn (veja a <a href="https://scikit-learn.org/stable/">documentação</a>) $-$ o que não nos impede, como forma de estudo, de escrever as nossas próprias versões dos algoritmos. Por fim, como foi brevemente mencionado, é importante que consigamos avaliar a efeciência dos nossos modelos; esse tópico começará a ser abordado no próximo post.</p>

<p>Qualquer dúvida, sugestão ou <em>feedback</em>, por favor, deixe um comentário abaixo.</p>

<blockquote>
  <p>Essa postagem faz parte de uma <a href="/categorias/#machine-learning-learning-from-data">série</a> de textos que tem o objetivo de estudar, principalmente, o curso “<a href="http://www.work.caltech.edu/telecourse.html">Learning from Data</a>”, ministrado pelo Professor Yaser Abu-Mostafa. Outros materiais utilizados serão sempre referenciados.</p>
</blockquote>
:ET