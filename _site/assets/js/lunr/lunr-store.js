var store = [{
        "title": "Uma Introdução ao NumPy e Pandas para Análise de Dados",
        "excerpt":"Python oferece muitas bibliotecas que extendem suas funcionalidades padrão. Por esse motivo, quando vamos trabalhar com processamento de dados, existem dois pacotes muito úteis que podemos utilizar: Numpy e Pandas.   Numpy cria um novo objeto array multidimensional que nos permite estruturar e operar nosso conjunto de dados de maneira fácil (e muito mais rápido que as tradicionais listas do Python). Além disso, nós também temos o Pandas, uma biblioteca de alto-nível construída sobre o código do Numpy que oferece dois novos tipos de estrutura de dados: Series e DataFrame.   A primeira coisa que temos que fazer antes de usar essas bibliotecas é importá-las. Para isso, veja as duas linhas de código a seguir:   import numpy  as np import pandas as pd   Agora, nós podemos conferir se os pacotes foram importadas de maneira correta imprimindo suas versões:   print(\"Numpy  -\", np.__version__) print(\"Pandas -\", pd.__version__)   Numpy  - 1.17.4 Pandas - 0.25.3   Como dito anteriormente, NumPy é uma biblioteca de baixo-nível, se comparada ao Pandas. Por esse motivo, nós vamos começar com ela, criando algumas arrays.   A fim de criar uma array de 1 dimensão (1D), digite:   my_array = np.array([0, 1, 2], dtype = \"int16\") my_array   array([0, 1, 2], dtype=int16)   Note que nós criamos uma variável chamada my_array e atribuímos a ela uma array de três elementos: $\\lbrace0, 1, 2\\rbrace$. Em adição, nós também determinamos o parâmetro dtype $-$ isso é importante porque, diferente do que acontece com as variáveis padrão no Python, a biblioteca NumPy nos permite dizer quanto de espaço será alocado na memória para salvar um determinado objeto; nesse sentido, NumPy é mais parecido com a linguagem C, na qual você deve que determinar a quantidade de bits que será utilizada para armazenar algo.   Continuando com a mesma sintaxe, nós podemos criar arrays $n$ dimensionais.   # 2D array (2, 2) my2D_array = np.array([[11, 12], [21, 22]]) print(\"2D array, with dtype = {}: \\n{}\\n\".format(my2D_array.dtype, my2D_array))  # 3D array (2, 2, 2) my3D_array = np.array([[[111, 112], [121, 122]], [[211, 212], [221, 222]]]) print(\"3D array, with dtype = {}: \\n{}\\n\".format(my3D_array.dtype, my3D_array))   2D array, with dtype = int64:  [[11 12]  [21 22]]  3D array, with dtype = int64:  [[[111 112]   [121 122]]   [[211 212]   [221 222]]]   Note que, para o caso my2D_array, nós criamos uma array de 2 dimensões com 2 linhas e 2 colunas; i.e., $(2 \\times 2)$. Por outro lado, considerando a variável my3D_array, uma array de 3 dimensões, com 2 linhas, 2 colunas e 2 camadas de produnfidade $-$ ou seja, $(2 \\times 2 \\times 2)$ $-$, foi criada. Por fim, perceba que, como não determinamos manualmente o atributo dtype, a biblioteca Numpy o definiu como int64, justificado pelos valores que cada umas das arrays assumiu.   Dessa forma, se quisermos fatiar alguns desses elementos, podemos tratar essas arrays de maneira similar às listas do Python:   # on the 2D array, we want to slice the first row: (11, 12) print(\"My 2D sliced array:\", my2D_array[0, :])  # on the 3D array, we want to slice the elements of the second row and second column for both layers of depth: (221, 222) print(\"My 3D sliced array:\", my3D_array[1, 1, :])    My 2D sliced array: [11 12] My 3D sliced array: [221 222]   Nesse exemplo, é importante notar que os índices começam de 0 (como de costume).   Além desses comandos simples, Numpy também disponibiliza uma grande quantidade de métodos e atributos que podem ser utilizados para realizar tarefas específicas. Vou demonstrar alguns deles, mas para uma lista completa, acesse a documentação oficial (Numpy Doc).   Em relação às operações matemáticas, esses são os métodos mais utilizados:   # create two arrays that will be used on the math operations a = np.array([[1, 2], [3, 4]]) # array([[1, 2],                                #        [3, 4]])  b = np.array([[4, 3], [2, 1]]) # array([[4, 3],                                #        [2, 1]])  # Element by element addition print(\"Addition (element by element): \\n{}\\n\".format(np.add(a, b)))  # Element by element subtraction print(\"Subraction (element by element): \\n{}\\n\".format(np.subtract(a, b)))  # Element by element multiplication print(\"Multiplication (element by element): \\n{}\\n\".format(np.multiply(a, b)))  # Matrix multiplication print(\"Matrix multiplication: \\n{}\\n\".format(np.dot(a, b)))  # Element by element division print(\"Division (element by element): \\n{}\\n\".format(np.divide(a, b)))   Addition (element by element):  [[5 5]  [5 5]]  Subraction (element by element):  [[-3 -1]  [ 1  3]]  Multiplication (element by element):  [[4 6]  [6 4]]  Matrix multiplication:  [[ 8  5]  [20 13]]  Division (element by element):  [[0.25       0.66666667]  [1.5        4.        ]]   O método mais importante aqui é o np.dot(array_1, array_2), que faz a multiplicação “adequada” de duas matrizes; em contraponto ao método np.multiply(array_1, array_2), que realiza o produto termo a termo das duas arrays.   Por fim, antes de começarmos a trabalhar com a biblioteca Pandas, tem mais um exemplo que gostaria de apresentar. Veja a seguir:   # create a 1D array with elements [0, 25[; then reshape it to a 2D array with 5 rows and 5 cols an_array = np.array(np.arange(0, 25)).reshape(5, 5) an_array   array([[ 0,  1,  2,  3,  4],        [ 5,  6,  7,  8,  9],        [10, 11, 12, 13, 14],        [15, 16, 17, 18, 19],        [20, 21, 22, 23, 24]])   print(\"Shape of the array:\", an_array.shape) print(\"Number of dimensions:\", an_array.ndim)   Shape of the array: (5, 5) Number of dimensions: 2   Com esses dois pedaços de código acima, nós conseguimos aprender um pouco mais sobre algumas funcionalidades do Numpy. Primeiro, nós criarmos uma array unidimensioal com 25 elementos $\\lbrace 0, 1, \\cdots, 23, 24 \\rbrace$; então, na mesma linha de código, nós utilizamos o método reshape() e transformamos esse objeto em uma array $(5 \\times 5)$. Finalmente, o “formato” e o número de dimensões da array foram impressos utilizando os atributos shape e ndim, respectivamente.   Exitem dezenas de outros métodos e atributos diferentes para se explorar com o Numpy, mas isso foi suficiente para uma introdução. Vamos agora trabalhar com o Pandas.   A biblioteca Pandas, como dito no começo do tutorial, fornece duas novas estruturas que serão extremamente importantes para o processamento de dados. Enquanto a estrutura Series equivale a uma array com rótulos de 1 dimensão, um DataFrame é uma array de duas dimensões que pode ter colunas heterogêneas (o que significa que podemos ter cada coluna de um Data Frame armazenando um tipo de dado diferente). Sendo assim, como é possível de se imaginar, um conjunto de Series forma um  DataFrame.   Agora, podemos começar a escrever algum código utilizando Pandas. Vamos ver como criar e utilizar essas novas ferramentas:   # create a pair of new Series s1 = pd.Series(['A', 'B', 'C']) s2 = pd.Series([1.2, 0.7, 3.0])  print(\"Series 1: \\n{}\".format(s1)) print() print(\"Series 2: \\n{}\".format(s2))   Series 1:  0    A 1    B 2    C dtype: object  Series 2:  0    1.2 1    0.7 2    3.0 dtype: float64   Note que a sintaxe é bem intuitiva; entretanto, o aspecto mais importantes vem do fato de que agora temos duas sequências explicitamente rotuladas e que podem ser combinadas para criar um DataFrame.   Um DataFrame pode ser encarado como um dicinário de Series; assim, a fim de criar um objeto desse tipo, podemos utilizar o seguinte código:   # create a dictionary with the previous Series (s1 and s2) data = {'1st col': s1, '2nd col': s2}  # create a DataFrame with this dictionary my_df = pd.DataFrame(data) my_df                           1st col       2nd col                       0       A       1.2                 1       B       0.7                 2       C       3.0            Note que nós começamos com dois objetos do tipo Series, e então os combinamos para criar um DataFrame. Temos, agora, um conjunto tabulado com informações heterogêneas.   Nesse segundo exemplo, vamos criar um DataFrame preenchendo-o com os elementos de uma array criada utilizando Numpy.   my_dataFrame = pd.DataFrame(np.arange(0, 50).reshape(10, 5), columns = ['1st', '2nd', '3rd', '4th', '5th']) my_dataFrame                           1st       2nd       3rd       4th       5th                       0       0       1       2       3       4                 1       5       6       7       8       9                 2       10       11       12       13       14                 3       15       16       17       18       19                 4       20       21       22       23       24                 5       25       26       27       28       29                 6       30       31       32       33       34                 7       35       36       37       38       39                 8       40       41       42       43       44                 9       45       46       47       48       49            Como é possível ver, nós criamos DataFrame a partir uma array de duas dimensões gerada utilizando Numpy.   Uma das operações mais úteis que podemos fazer com essa nova estrutura é, mais uma vez, fatiá-la. Para fazer isso, podemos utilizar o atributo iloc[] a fim de selecionar uma porção do DataFrame original.   # using the same \"my_dataFrame\" DataFrame # select the 3rd and 4th columns and the rows with indexes from 4 to 8 my_dataFrame[['3rd', '4th']].iloc[4:9]                           3rd       4th                       4       22       23                 5       27       28                 6       32       33                 7       37       38                 8       42       43            Perceba que, se você quiser selecionar mais de uma coluna, terá que utilizar um lista para agrupá-las.   A próxima alternativa para fatiar um DataFrame é criando uma máscara que utiliza algum tipo de condicional; por exemplo, se nós quisermos recuperar, na terceira coluna (3rd), os valores que são maiores que 20, nós podemos fazer o seguinte:   # create a mask mask = my_dataFrame['3rd'] &gt; 30  # apply the mask to the \"3rd\" column in order to slice the DataFrame considering the given condition my_dataFrame['3rd'][mask]   6    32 7    37 8    42 9    47 Name: 3rd, dtype: int64   Note que nós primeiro criamos a máscara, e então a aplicamos sobre o DataFrame, escolhendo tanto as colunas (3rd) quanto as linhas (aquelas que tem valor maior que 30) desejadas.   Finalmente, nós vamos ver alguns métodos da biblioteca Pandas; porém, como já dito anteriormente, eu recomendo fortemente que você leia a documentação oficial do Pandas.   A seguir, vamos criar um conjunto de dados para os nossos próximos exemplos.   # let's create a DataFrame for the next demonstrations  col_labels = ['Name', 'Age', 'Nationality']  name        = pd.Series(['André', 'James', 'Agata', 'María', 'Pedro', 'Juan', 'Paul']) age         = pd.Series([23, 27, 21, None, 27, 22, 25]) nationality = pd.Series(['Brazilian', 'American', 'Greek', 'Mexican', 'Brazilian', 'Mexican', 'British'])  people = {col_labels[0]: name,           col_labels[1]: age,           col_labels[2]: nationality}  df_people = pd.DataFrame(people) df_people.head()                           Name       Age       Nationality                       0       André       23.0       Brazilian                 1       James       27.0       American                 2       Agata       21.0       Greek                 3       María       NaN       Mexican                 4       Pedro       27.0       Brazilian            A primeira coisa a observar, é a ulização do médoto head(), que retorna, por padrão, apenas as 5 primeiras linhas do nosso banco de dados. É mais conveniente visualizar apenas as primeiras linhas do DataFrame quando o conjunto de dados com o qual se está trabalhando é grande demais. Além disso, uma das idades (Age) está “em branco” (isso é muito comum em aplicações do mundo real, e nós vamos ver como tratar esse tipo de problema).   Nós podemos começar lidando com o valor None. Existem algumas estratégias diferentes que podemos tomar; entretanto, a fim de manter esse tutorial o mais simples possível, vamos apenas eliminar a linha que contém esse problema. Para fazer isso, podemos utilizar o método dropna():   df_people.dropna(inplace = True) df_people                           Name       Age       Nationality                       0       André       23.0       Brazilian                 1       James       27.0       American                 2       Agata       21.0       Greek                 4       Pedro       27.0       Brazilian                 5       Juan       22.0       Mexican                 6       Paul       25.0       British            Como é possível de ser visto, nós removemos a linha com índice 3. Para fazer isso de forma permanente, foi necessário atribuir o valor True ao parâmetro inplace.   Agora, nós podemos ter uma visão geral do conjunto de dados utilizando o método info().   df_people.info()   &lt;class 'pandas.core.frame.DataFrame'&gt; Int64Index: 6 entries, 0 to 6 Data columns (total 3 columns): Name           6 non-null object Age            6 non-null float64 Nationality    6 non-null object dtypes: float64(1), object(2) memory usage: 192.0+ bytes   Veja que o método utlizado nós mostrou que temos 6 entradas não nulas para cada uma das 3 colunas.   A seguir, vamos assumir que queremos saber a média de idade das pessoas com nacionalidade brasileira (Brazilian). Para essa situação hipotética, a primeira coisa que temos que fazer é criar uma máscara para selecionar os invíduos que nasceram no Brasil.   # create a mask n_mask = df_people['Nationality'] == 'Brazilian'  # apply the mask df_people[n_mask]                           Name       Age       Nationality                       0       André       23.0       Brazilian                 4       Pedro       27.0       Brazilian            Com essas linhas de código, nós filtramos o DataFrame para mostrar apenas as pessoas com nacionalidade brasileira. Falta, então, calcular a média de suas idades:   average_age = df_people[n_mask].mean() average_age   Age    25.0 dtype: float64   Note que o resultado é uma estrutura do tipo Series. Dessa forma, se quisermos formatá-lo, podemos utilizar o atributo values, que retorna os valores do objeto em questão como uma array Numpy.   print(\"The average age of the Brazilian citizens is {:.0f} years.\".format(average_age.values[0]))   The average age of the Brazilian citizens is 25 years.   Conclusão   Numpy e Pandas são duas bibliotecas essenciais para se trabalhar com análise de dados. Numpy introduz objetos do tipo ndarray (arrays $n$ dimensionais) e o Pandas implementa duas novas estruturas de dados: Series e DataFrame. Dessa forma, se você quiser utilizar os conceitos de ciência de dados, aprendizagem de máquina, etc. nos seus projetos com Python, você deve aprender a utilizar essas excelentes ferramentas.   Qualquer dúvida, sugestão ou feedback, por favor, deixe um comentário abaixo.      Eu havia escrito esse texto, originalmente em inglês, em uma antiga versão do blog que já não existe mais. Pequenas correções e atualizações, além da própria tradução, foram feitas para que o conteúdo continuasse relevante.   ","categories": ["Tutorial"],
        "tags": ["python","ciencia-de-dados"],
        "url": "http://localhost:4000/introducao-numpy-pandas/",
        "teaser":null},{
        "title": "Visualização de Dados com Matplotlib",
        "excerpt":"Uma parte essencial do processo de análise de dados é a visualização parcial e final dos resultados que foram alcançados. Na maior parte das vezes, é muito mais fácil interpretar esse tipo de informação graficamente do que através de, apenas, tabelas ou números.   Entretanto, mais do que apenas ser capaz de plotar gráficos, é importante que o pesquisador (ou estudante, ou cientista de dados, etc.) represente esse conjunto de dados de uma forma que sua audiência consiga entender. Você precisa ter gráficos acessíveis, confiáveis e elegantes (Kirk, A. citado em Curso edX).   Em Python, o pacote mais básico para visualização de dados é o Matplotlib. Ele nos permite plotar diferentes tipos de gráficos com dezenas de opções de customização. Por esse motivo, nós o escolhemos para esse tutorial.      Toda a imagem mostrada acima é uma Figure criada pelo módulo matplotlib.pyplot; dentro dela, na área branca, estão compreendidos os eixos x e y, chamadas de Axes ou Subplot (existe uma pequena diferença entre esses dois termos, mas para a maioria dos casos, eles podem ser tratados como sinônimos). Além disso, no canto superior esquerdo, existe um pequeno menu que nos permite realizar algumas ações $-$ incluindo exportar o gráfico como imagem.   Observação: A partir desse ponto, eu não vou mais apresentar toda a janela mostrada na figura acima; ao invés disso, apenas os gráficos serão gerados.   Agora que sabemos o básico, vamos importar a biblioteca e verificar se ela está funcionando.   %matplotlib inline import matplotlib.pyplot as plt   Perceba que, na maior parte das situações, nós só temos que importar o módulo pyplot. Assim, se nenhuma mensagem de erro apareceu, o Matplotlib foi corretamente importado.   Observação 2: se você está utilizando o Jupyter Notebook para realizar seus testes, é necessário que o comando %matplotlib inline seja incluído antes de importar a biblioteca.   Como você deve imaginar, a primeira coisa que temos que fazer é criar uma Figure:   fig = plt.figure(figsize = (3, 6))   &lt;Figure size 216x432 with 0 Axes&gt;   Além de criar um objeto Figure e atribuí-lo à variável fig, nós defimos os valores para o parâmetro figsize, que, como o nome sugere, determina o tamanho da janela: $3 \\times 6$ polegadas.   Agora nós criamos, dentro do “container” fig, um objeto Axes. Para isso, basta utilizar o método add_subplot():   ax1 = fig.add_subplot(111)   Note que, mais uma vez, nós tivemos que passar o valor de um parâmetro para a função. Nesse caso, o 111 representa o número de objetos Axes que serão criados dentro de fig: uma array com 1 linha, 1 coluna e índice 1.   O próximo passo é definir os dados que serão utilizados para plotar o gráfico. Para esse primeiro exemplo, eu vou criar duas listas que ilustram o comportamento da função $f(x) = 2x$ com domínio em $\\lbrace 0, 1, \\cdots, 10 \\rbrace$:   x = [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10] y = [0, 2, 4, 6, 8, 10, 12, 14, 16, 18, 20]   Feito isso, agora só precisamos plotar esses valores em um sistema de coordenadas utilizando o comando plot(); e, por fim, chamar o método show() para mostrá-lo na tela:   # all the code togheter fig = plt.figure(figsize = (3, 6)) ax1 = fig.add_subplot(111) ax1.scatter(x, y) plt.show()      Observação 3: mais uma vez, se você está utilizando Jupyter Notebook, talvez seja necessário que todos os comandos estejam em uma única célula.   Em adição ao que acabamos de fazer, é possível modificar algumas característica do gráfico, veja a seguir:   # all the code togheter fig = plt.figure(figsize = (2, 4)) # intentionally smaller than the previous one ax1 = fig.add_subplot(111) ax1.scatter(x, y, label = 'f(x)', color = 'red')  # ax1 properties ax1.set_title('My Title') ax1.set_xlabel('X') ax1.set_ylabel('Y')  plt.legend(loc = 4) plt.show()      Nós incluímos informações importantes com essas últimas linhas de código. No método scatter(), nós adicionamos dois parâmetros: labele color. O primeiro deles é usado para identificar a curva que está sendo plotada (através do método legend()), enquanto que o segundo define a cor dos pontos.   Além disso, definimos algumas novas propriedades para o objeto ax1: o método set_title() define o título do gráfico, e os métodos set_xlabel e set_ylabel definem os rótulos que serão utilizados nos eixos $x$ e $y$, respectivamente.   A biblioteca Matplotlib, como mencionado no começo desse texto, é muito flexível; por isso, a fim de extrair todo o seu potencial, é importante que você leia a documentação oficial.   Finalmente, um outro exemplo, um pouco mais complexo, será apresentado. Primeiro, veja o seguinte código:   import numpy as np  # create a new figure fig = plt.figure(figsize = (10, 5))  # create two new Axes objects in the format of a '1 row x 2 columns' array ax1 = fig.add_subplot(121) ax2 = fig.add_subplot(122)  # create the data set that will be plotted x = np.linspace(0, np.pi * 2) y = np.sin(x) # y = f(x) = sin(x) z = np.cos(x) # z = g(x) = cos(x)  # plot f(x) and g(x) ax1.plot(x, y, label = 'sin', color = 'b') # 'b' stands for 'blue' ax2.plot(x, z, label = 'cos', color = 'r') # 'r' stands for 'red'  # set 'ax1' properties ax1.set_title('Trigonometric Functions - SINE') ax1.set_xlabel('Angle (in radian)') ax1.set_ylabel('Magnitude') ax1.axis([0, np.pi * 2, -1.25, 1.25]) # define the range of both axes # define ticks for each axis (3 auxiliary variables) xticks = [0, np.pi / 2, np.pi, np.pi * 1.5, np.pi * 2]                         # define the ticks values - 'X' axis xlabel = ['0', '$\\\\frac{\\\\pi}{2}$', '$\\\\pi$', '$\\\\frac{3\\\\pi}{2}$', '$2\\\\pi$'] # define the label values - 'X' axis yticks = [-1, -0.5, 0, 0.5, 1]                                                 # define the ticks values - 'Y' axis ax1.xaxis.set(ticks = xticks, ticklabels = xlabel) ax1.yaxis.set(ticks = yticks) ax1.legend(loc = 1)  # set 'ax1' properties ax2.set_title('Trigonometric Functions - COSINE') ax2.set_xlabel('Angle (in radian)') ax2.set_ylabel('Magnitude') ax2.axis([0, np.pi * 2, -1.25, 1.25]) # define the range of both axes # define ticks for each axis (3 auxiliary variables) xticks = [0, np.pi / 2, np.pi, np.pi * 1.5, np.pi * 2]                         # define the ticks values - 'X' axis xlabel = ['0', '$\\\\frac{\\\\pi}{2}$', '$\\\\pi$', '$\\\\frac{3\\\\pi}{2}$', '$2\\\\pi$'] # define the label values - 'X' axis yticks = [-1, -0.5, 0, 0.5, 1]                                                 # define the ticks values - 'Y' axis ax2.xaxis.set(ticks = xticks, ticklabels = xlabel) ax2.yaxis.set(ticks = yticks) ax2.legend(loc = 1)  plt.tight_layout() # fix the spaces between the two Axes plt.show()      Nós acabamos de criar uma Figure com dois Subplot’s dentro dela. As imagens da esquerda e da direita são definidas pelas funções seno e cosseno, respectivametne. Além disso, há algumas coisas novas aqui; por isso, os próximos parágrafos serão dedicados a esses detalhes.   Depois de importar, além do Matplotlib, o Numpy (veja aqui um pequeno tutorial sobre Numpy e Pandas), nós criamos uma Figure com um tamanho específico. Agora, utilizando esse objeto, que foi armazenado na variável fig, foram criados dois Subplot’s $-$ Importante: note que para o primeiro objeto, o valor do parâmetro foi 121(que significa 1 linha, 2 colunas e o índice 1), enquanto que para o segundo, esse número teve que ser definido como 122.   Nas linhas seguintes, a única coisa que fizemos foi criar os nossos vetores de dados x, y e z. Com o Numpy, nós geramos uma lista, atribuída a x, de valores igualmente espaçados entre $0$ e $2\\pi$; então, nas variáveis y e z, nós calculamos e salvamos os valores de seno e cosseno de x, respectivamente.   Depois disso tudo, diferentemente do primeiro exemplo, utilizamos o método plot() (ao invés de scatter()). Essa modificação faz com que o gráfico de pontos seja, agora, exibido como gráfico de linha.   Por fim, sobre as propriedades de ax1 e ax2, descreverei apenas os atributos e métodos que ainda não foram discutidos. A primeira novidade é o método axis(), que define os valores mínimo e máximo que serão mostrados em cada eixo do gráfico $-$ perceba que é necessário passar uma lista de números. Além disso, nós também criamos algumas variáveis que foram utilizadas para definir os parametros ticks e ticklabes dos métodos xaxis.set() e yaxis.set(). Esses métodos definem em quais pontos ao longo dos eixos você terá um indicador de valor.   Um pequeno detalhe é o de que foi necessário, antes de chamar o método show(), utilizar a função tight_layout() a fim de ajustar o tamanho e espaçamento dos gráficos.   Conclusão   Matplotlib é uma biblioteca muito flexível e poderosa que nos permite criar diferentes tipos de gráficos. Além disso, como mencionado anteriormente, existe uma galeria oficial cheia de exemplos reais criados a partir dessa ferramenta $-$ confira, e veja todas as possibilidades.   Qualquer dúvida, sugestão ou feedback, por favor, deixe um comentário abaixo.      Eu havia escrito esse texto, originalmente em inglês, em uma antiga versão do blog que já não existe mais. Pequenas correções e atualizações, além da própria tradução, foram feitas para que o conteúdo continuasse relevante.   ","categories": ["Tutorial"],
        "tags": ["python","ciencia-de-dados"],
        "url": "http://localhost:4000/visualizacao-de-dados-com-matplotlib/",
        "teaser":null},{
        "title": "[Parte 01] O que é Aprendizado (de Máquina) & PLA",
        "excerpt":"Quando se fala de Aprendizado de Máquina, há pelo menos duas interpretações para o que isso significa: a primeira delas diz respeito a um conjunto de técnicas e modelos estatísticos que são usados, primariamente, para se fazer inferência (estimação pontual dos parâmetros de interesse, contrução de intervalo de confiança, teste de hipótese, etc.); enquanto que a segunda abordagem, que será a utilizada daqui para frente, se preocupa em, principalmente, fazer predição sobre novas observações $-$ nesse caso, o(s) modelo(s) utilizado(s) pode(m), inclusive, não ter forma explícita (Izbicki, R.; dos Santos, T. M. Machine Learning sob a ótica estatística). Dito isso, podemos começar.   Componentes do aprendizado   A fim de dar contexto ao que vem a seguir, tome o seguinte exemplo: imagine que um banco contratou uma empresa de consultoria para ajudá-lo a determinar se, para cada cliente que pede um empréstimo, o banco deve ou não conceder esse crédito (aqui, um cliente é bom se, de alguma forma, faz com que o banco ganhe dinheiro; e é ruim, caso contrário). Para construir um modelo que resolve esse tipo de problema, o banco tem um conjunto de dados de clientes antigos, com várias de suas características (salário, estado civil, bens materiais, etc.), além de, se no passado, esses clientes fizeram a instituição ganhar ou perder dinheiro. De posse dessas informações, a empresa de consultoria pode escrever um modelo que ajuda o banco a predizer se clientes futuros darão (ou não) algum tipo de lucro.   Considerando esse exemplo, podemos dar nomes às componentes (do aprendizado) de interesse. Seja $\\mathbf{x}$ o vetor de entrada (informação que o banco tem de um cliente), então $f: \\mathcal{X} \\longrightarrow \\mathcal{Y}$ é a função alvo (que é desconhecida) $-$ onde $\\mathcal{X}$ é o espaço de entrada (para o caso onde existem $d$ características sobre um cliente, $\\mathcal{X}$ é o Espaço Euclidiano $d$-dimensional) e $\\mathcal{Y}$ é o espaço de saída (no exemplo, $\\mathcal{Y} = \\lbrace +1, -1 \\rbrace$; ou seja, o banco concede ou não o empréstimo). Além disso, temos o conjunto de dados com entradas e saídas, definido por $\\mathcal{D} = (\\mathbf{x}_1, y_1), \\cdots, (\\mathbf{x}_N, y_N)$ $-$ onde $y_n = f(\\mathbf{x}_n)$, tal que $n = 1, \\cdots, N$ $-$, e um algoritmo de aprendizagem $\\mathcal{A}$ que usa $\\mathcal{D}$ para determinar uma função $g: \\mathcal{X} \\longrightarrow \\mathcal{Y}$ que aproxima $f$. Nesse caso, o algoritmo “escolhe” uma função $g$ a partir de uma classe de funções que são relevantes para o problema (esse conjunto que contempla $g$ será denotado por $\\mathcal{H}$, e receberá o nome de Hypothesis Set).   Voltando ao exemplo, o banco irá, baseado em $g$, decidir para quais clientes realizará o empréstimo (lembre-se que $f$ é desconhecida). Nesse caso, o algoritmo $\\mathcal{A}$ selecionou $g \\in \\mathcal{H}$ a partir da análise do conjunto de dados $\\mathcal{D}$; na esperança que o comportamento de clientes futuros ainda possa ser modelado por essa função escolhida. A figura a seguir ilustra a relação entre todas essas componentes.    Figura 1 [fonte: “Learning from Data”] $-$ Componentes do aprendizado.   A Fig. 1 será utilizada como framework para tratarmos o “problema do aprendizado”. Mais tarde, esse esquema vai passar por alguns refinamentos, mas a base será a mesma:           Existe uma $f$ para ser aprendida (que é, e continuará sendo desconhecida para nós).            Temos um conjunto de dados $\\mathcal{D}$ gerados por essa função alvo.            O algoritmo de aprendizagem $\\mathcal{A}$ utiliza $\\mathcal{D}$ para encontrar uma função $g \\in \\mathcal{H}$ que aproxima bem $f$.       Um modelo de aprendizado simples   Sobre as componentes do aprendizado que acabamos de discutir, a função alvo $f$ e o conjunto de dados $\\mathcal{D}$ vêm do problema com o qual estamos lidando. Entretanto, o conjunto de possíveis soluções $\\mathcal{H}$ e o algoritmo de aprendizagem $\\mathcal{A}$ são ferramentas nós temos que escolher para determinar $g$; nesse sentido, eles ($\\mathcal{H}$ e $\\mathcal{A}$) são chamados de modelo de aprendizado.   Vejamos, então, um modelo de aprendizado simples: seja $\\mathcal{X} = \\mathbb{R}^d$ e $\\mathcal{Y} = \\lbrace +1, -1 \\rbrace$; onde $+1$ e $-1$, denotam “sim” e “não”, respectivamente. No exemplo do banco, diferentes coordenadas de $\\mathbf{x} \\in \\mathcal{X}$ representam cada uma das características do cliente (salário, estado civil, bens materiais, etc.); enquanto que o espaço de saída $\\mathcal{Y}$ faz referência ao fato de o banco conceder ou não o empréstimo. Em adição, vamos dizer que $\\mathcal{H}$ é composto por todas as funções $h \\in \\mathcal{H}$ que têm forma ditada por:     onde $\\mathbf{w}$ é um vetor de “pesos” e $\\mathbf{x} \\in \\mathcal{X}$, com $\\mathcal{X} = \\lbrace 1 \\rbrace \\times \\mathbb{R}^d$. O que está sendo feito aqui é simples: a família de funções $h(\\cdot)$ $-$ perceba que $h$ não está completamente definida, já $\\textbf{w}$ não é parâmetro da função $-$, atribui pesos $w_i$ para cada uma das $d$ características dos indivíduos. Dessa forma, podemos determinar a regra de que, se $\\sum_{i = 1}^{d} w_i x_i &gt; \\text{threshold}$, então o banco aprova o empréstimo; caso contrário, não. $h(\\mathbf{x})$ traduz essa ideia; além de assumir os valores $+1$ ou $-1$, como gostaríamos que fosse.   O modelo que acabamos de descrever é chamado de perceptron. O algoritmo de aprendizagem $\\mathcal{A}$ vai procurar por valores de $\\mathbf{w}$ ($w_0$ incluído) que se adaptam bem as dados. A escolha ótima será a nossa função $g$.   Observação: se o conjunto de dados for linearmente separável, então existirá um $\\mathbf{w}$ que classifica todas as observações corretamente.   Por fim, vamos ver então qual é esse algoritmo $\\mathcal{A}$. O algoritmo de aprendizagem nesse caso é chamado de perceptron learning algorithm (PLA), e funciona como descrito abaixo.   Para encontrar $\\mathbf{w}$ tal que todos os pontos estão corretamente classificados, vamos considerar um processo de iteração em $t$ $-$ tal que $t = 0, 1, 2, \\cdots$. Nesse caso, o vetor de “pesos” no $t$-ésimo instante será denotado por $\\mathbf{w}(t)$; aqui, $\\mathbf{w}(0)$ é escolhido arbitrariamente. Para cada etapa do processo, o algoritmo seleciona uma das obervações que não está classificada corretamente $-$ vamos chamá-la de $(\\mathbf{x}(t), y(t))$ $-$, e aplica a seguinte regra:     O que a regra que acabamos de definir faz é “mover” a reta $w_0 + w_1 x_1 + w_2 x_2 = 0$ (para o caso com $2$ dimensões) que divide os pontos do conjunto de dados; a fim de classificar corretamente a observação $(\\mathbf{x}(t), y(t))$.   Como dito anteriormente, se os dados são linearmente separáveis, o PLA converge, classificando corretamente todas as observações; o que implica em duas coisas interessantes:           Repare que, para cada etapa do processo de iteração, apesar de corrigir a observação que está sendo considerada, o algoritmo pode “bagunçar” a classificação (em um primeiro momento, correta) dos outros pontos; mas mesmo assim, sob a hipótese de que os dados são linearmente separáveis, o algoritmo converge (a demonstração pode ser vista aqui).            Para esse tipo de classificador que acabamos de detalhar, $\\mathcal{H}$ é uma classe infinita de funções; assim, dizer que, nesse caso, o algorimo converge, é o mesmo que dizer que, mesmo em um conjunto de cardinalidade infinita, foi necessário uma quantidade finita de iterações para encontrarmos uma solução ótima (no sentido de classificar corretamente todos os pontos) para o problema $-$ o que é, no mínimo, interessante.       Conclusão   Na primeira parte dessa série de textos, vimos o framework básico com o qual vamos trabalhar quando queremos modelar o processo de aprendizado (de máquina). Essas ideias serão revisitadas à exaustão e, por isso, são tão importantes. Por fim, vimos também como essas componentes do aprendizado podem nos guiar na construção de um modelo de classificação simples. Tal modelo, o “perceptron”, é de fato limitado; mas é um excelente primeiro passo que podemos dar. A próxima postagem será dedicada à implementação desse classificador em Python, bem como à discussão de um exemplo.   Qualquer dúvida, sugestão ou feedback, por favor, deixe um comentário abaixo.      Essa postagem faz parte de uma série de textos que tem o objetivo de estudar, principalmente, o curso “Learning from Data”, ministrado pelo Professor Yaser Abu-Mostafa. Outros materiais utilizados serão sempre referenciados.   ","categories": ["Machine Learning - Learning from Data"],
        "tags": [],
        "url": "http://localhost:4000/o-que-e-aprendizado/",
        "teaser":null},{
        "title": "[Parte 02] Implementação em Python: Perceptron",
        "excerpt":"Como mencionado na parte 01 dessa série de textos, essa postagem será dedicada à implementação do Perceptron Learning Algorithm (PLA) em Python, utilizando, para isso, a biblioteca Numpy. Discutiremos um exemplo e, ao final, vamos ver como utilizar a implementação desse mesmo algoritmo pela biblioteca Sklearn.   O código a seguir é baseado (feitas algumas modificações) nos capítulos iniciais do que é apresentado no livro Python Machine Learning.   Primeiro vamos à implementação do algoritmo, e depois discutiremos os trechos do que foi escrito. Considere a classe Perceptron a seguir:   import numpy as np  # Raw implementation class Perceptron():     \"\"\"     Perceptron learning algorithm implementation     \"\"\"          def __init__(self, eta = 1, random_seed = 1):         self.eta = eta         self.random_seed = random_seed              def fit(self, X, y):         rn = np.random.RandomState(self.random_seed)         self.w_ = rn.normal(loc = 0, scale = 0.01, size = X.shape[1] + 1)         errors = True                  while errors:             errors = 0             for X_i, y_i in zip(X, y):                 if(y_i != self.predict(X_i)):                     # update weights vector for misclassified points                     update = self.eta * y_i                     self.w_[1:] += update * X_i                     self.w_[0] += update                      errors += 1                              return self          def predict(self, X_i):         eval_func = np.dot(X_i, self.w_[1:]) + self.w_[0] # ATTENTION: this implemented arguments order is more intuitive         return np.where(eval_func &gt;= 0, 1, -1)   Note que, para criar uma instância da classe, são necessários dois parâmetros: o primeiro deles, eta, diz respeito a uma pequena generalização feita na regra de atualização do vetor $\\mathbf{w}$ (discutida no próximo parágrafo), enquanto que o parâmetro random_seed define uma semente para geração aleatória do vetor inicial de pesos.   Como acabei de dizer, podemos generalizar a regra de atualização de $\\mathbf{w}$ apresentada na parte 01 dessa série introduzindo o parâmetro $\\eta$. A regra, então, ficaria assim:     Perceba que para $\\eta = 1$, a regra é exatamente a mesma que vimos antes. Dessa forma, a única coisa que $\\eta$ faz é mexer no quanto a reta definida por $\\mathbf{w}$ “se move” para classificar corretamente o ponto considerado. Nesse sentido, perceba que, para $\\eta$ grande, a chance de eu “bagunçar” a classificação dos demais pontos também é grande; portanto, $\\eta$ maior não é necessariamente melhor (normalmente, $0 &lt; \\eta \\leq 1$).   Continuando, o método __init__() apenas inicializa os atributos eta e random_seed. O método fit() é o que, de fato, ajusta o modelo; ou seja, ajusta os valores do vetor $\\mathbf{w}$. Nesse caso, para os pontos que não estão classificados corretamente (y_i != self.predict(X_i)), o atributo w_ é atualizado de acordo com a regra que acabamos de discutir $-$ esse processo é realizado quantas vezes forem necessárias. Uma tecnicalidade importante é a de que o vetor de pesos não deve ser inicializado com todas as entradas nulas; caso isso aconteça, o termo update * X_i afetará somente a escala de $\\mathbf{w}$. Por fim, o método predict(), baseado na função $h(\\mathbf{x})$ definida no post anterior, faz a classificação de cada ponto (ou conjunto de pontos) X_i.   Para verificar o funcionamento do algoritmo, vamos utilizar o conjunto de dados Iris, que classifica três espécies de flores de acordo com o comprimento e largura de suas pétalas e sépalas. Veja as primeiras linhas do conjunto de dados:   %matplotlib inline import pandas as pd import matplotlib.pyplot as plt  # Iris Data Set df = pd.read_csv(\"https://bit.ly/2Mg0qkZ\", header = None, encoding = \"UTF\")  df.columns = ['sepal-length', 'sepal-width', 'petal-length', 'petal-width', 'category'] df.head()                           sepal-length       sepal-width       petal-length       petal-width       category                       0       5.1       3.5       1.4       0.2       Iris-setosa                 1       4.9       3.0       1.4       0.2       Iris-setosa                 2       4.7       3.2       1.3       0.2       Iris-setosa                 3       4.6       3.1       1.5       0.2       Iris-setosa                 4       5.0       3.6       1.4       0.2       Iris-setosa            Entretanto, para que consigamos visualizar facilmente o resultado do algoritmo, vamos nos concentrar em duas features: “Sepal length” e “Petal length”. Além disso, vamos denotar a espécie “Iris Setosa” (50 primeiras linhas) por $-1$ e a espécie “Iris Versicolor” (linhas 50 a 100) por $+1$. Nesse caso, não utilizaremos as informações da terceira espécie; já que o Perceptron é um classificador binário. Veja como ficaram os dados:   df = df.loc[0:100, ['sepal-length', 'petal-length', 'category']]  X = df.loc[0:100, ['sepal-length', 'petal-length']].values y = df.category.values y = np.where(y == 'Iris-setosa', -1, 1)  plt.scatter(X[0:50, 0], X[0:50, 1], color = \"red\", marker = \"o\", label = \"Iris-ventosa\") plt.scatter(X[50:100, 0], X[50:100, 1], color = \"green\", marker = \"s\", label = \"Iris-versicolor\") plt.xlabel('Sepal length [cm]') plt.ylabel('Petal length [cm]') plt.legend(loc = 2) plt.show()      Agora podemos ajustar o modelo:   my_perceptron = Perceptron() my_perceptron.fit(X, y)  print(\"Weights vector: {}.\".format(my_perceptron.w_))   Weights vector: [-1.98375655 -3.50611756  9.19471828].   Nesse caso, instanciamos um objeto da classe Perceptron e depois ajustamos o modelo baseado no conjunto de dados que acabamos de filtrar. Note, então, que o vetor w_ foi completamente determinado. Assim, o que podemos fazer é visualizar os resultados de forma gráfica. Para isso, utiizaremos a função a seguir, plot_decision_regions():   def plot_decision_regions(X, y, classifier, feature_names, resolution = 0.01):     # general settings     markers = [\"o\", \"s\", \"*\", \"x\", \"v\"]     colors  = (\"red\", \"green\", \"blue\", \"gray\", \"cyan\")     x1_min, x1_max = X[:, 0].min() - 0.5, X[:, 0].max() + 0.5     x2_min, x2_max = X[:, 1].min() - 0.5, X[:, 1].max() + 0.5     # define a grid     xx1, xx2 = np.meshgrid(np.arange(x1_min, x1_max, resolution),                            np.arange(x2_min, x2_max, resolution))     # classify each grid point     result = classifier.predict(np.array([xx1.ravel(), xx2.ravel()]).T)     result = result.reshape(xx1.shape)     # make a plot     plt.contourf(xx1, xx2, result, colors = colors[0:len(np.unique(y))], alpha = 0.5)     for index, value in enumerate(np.unique(y)): # plot each point &amp; 'enumerate()' returns index and value of the given array         plt.scatter(x = X[y == value, 0], y = X[y == value, 1], # select each X and y vectors by creating a mask                     color = colors[index],                     marker = markers[index],                     label = feature_names[index],                     edgecolor = 'black')   Agora podemos plotar o gráfico de interesse:   feature_names = ['Iris ventosa', 'Iris versicolor'] plot_decision_regions(X, y, my_perceptron, feature_names) plt.title('Fitted model with raw implementation') plt.xlabel('Sepal length [cm]') plt.ylabel('Petal length [cm]') plt.legend(loc = 2) plt.show()      Como podemos ver, o algoritmo classificou corretamente todas as flores. Entretanto, um ponto muito importante sobre o qual ainda não disctutimos, é a eficiência (ou acurácia) desse modelo para classificar novas observações. Esse tipo de medida será discutida (e implementada) ao longo dos próximos textos.   Antes de finalizar, vamos ver como ajustar esse mesmo modelo utilizando a implementação do Sklearn:   # Sklearn usage from sklearn.linear_model import Perceptron  sklearn_perceptron = Perceptron() sklearn_perceptron.fit(X, y)  print(\"Weight vector (without w_0): {}.\".format(sklearn_perceptron.coef_))   Weight vector (without w_0): [[-2.4  5. ]].   Como a classe Perceptron já está implementada na biblioteca, ajustar o modelo é super simples; basta, mais uma vez, utilizar o método fit(). O vetor de pesos é ligeiramente diferente, mas também é uma solução para o nosso problema $-$ veja o gráfico abaixo:   feature_names = ['Iris ventosa', 'Iris versicolor'] plot_decision_regions(X, y, sklearn_perceptron, feature_names) plt.title('Fiited model with Sklearn usage') plt.xlabel('Sepal length [cm]') plt.ylabel('Petal length [cm]') plt.legend(loc = 2) plt.show()      Conclusão   Nessa postagem vimos a implementação em Python do Perceptron Learning Algorithm (PLA) que havíamos discutido antes. Entretanto, a maior parte desses resultados em machine learning já estão disponíveis através da biblioteca Sklearn (veja a documentação) $-$ o que não nos impede, como forma de estudo, de escrever as nossas próprias versões dos algoritmos. Por fim, como foi brevemente mencionado, é importante que consigamos avaliar a efeciência dos nossos modelos; esse tópico começará a ser abordado no próximo post.   Qualquer dúvida, sugestão ou feedback, por favor, deixe um comentário abaixo.      Essa postagem faz parte de uma série de textos que tem o objetivo de estudar, principalmente, o curso “Learning from Data”, ministrado pelo Professor Yaser Abu-Mostafa. Outros materiais utilizados serão sempre referenciados.   ","categories": ["Machine Learning - Learning from Data"],
        "tags": [],
        "url": "http://localhost:4000/implementacao-perceptron/",
        "teaser":null},{
        "title": "[Parte 03] Memorizar não é Aprender",
        "excerpt":"O que nós fizemos até agora foi, dado um conjunto $\\mathcal{D}$, treinar um modelo que “explicasse” (no caso do Perceptron, “classificasse”) os dados $(\\mathbf{x}_1, y_1), \\cdots, (\\mathbf{x}_N, y_N)$. Porém, isso significa, de fato, aprender? Isto é, a função $g \\in \\mathcal{H}$ escolhida pelo algoritmo aproxima a função alvo $f$ no sentido de ter bom desempenho em explicar $\\mathbf{x} \\not\\in \\mathcal{D}$?   O que nós vamos fazer agora é introduzir uma componente aleatória no framework de aprendizado que começamos a discutir na parte 01 dessa série de textos $-$ que vai nos permitir responder “sim” às perguntas do parágrafo anterior.   Para , seja , com ; i.e., a probabilidade de que o valor de uma função fixa   avaliada em   com  escolhida antes de  ser gerado  seja diferente da função alvo $f$ avaliada no mesmo ponto. Por consequência, . Além disso, defina ; ou seja,  é a proporção de vezes que  é diferente de  para uma amostra . A ideia é que, desde que a  seja gerada aleatoriamente seguindo uma distribuição  (não necessariamente conhecida), então  aproxima bem . A relação a seguir, conhecida como Desigualdade de Hoeffding, quantifica essa aproximação:     O que a inequação acima diz é que a probabilidade de $\\nu$ estar arbitrariamente próximo de $\\mu$ é algo como “$1$ menos alguma coisa que decai exponencialmente com $N$”. O que é o mesmo que dizer que, para $N$ “grande”, $\\nu$ aproxima bem o comportamento de $\\mu$. Assim, a quantidade de vezes que $h$ erra na amostra $\\mathcal{D}$ é proporcional à quantidade de erros que $h$ cometeria fora de $\\mathcal{D}$. Veja abaixo um esquema atualizado das nossas componentes do aprendizado.    Figura 1 [fonte: “Learning from Data”] $-$ Framework de aprendizado atualizado com componente estocástica.   Dito tudo isso, se houvesse apenas uma função em $\\mathcal{H}$, seria fácil de verificar se $h$ tem bom desempenho em avaliar pontos fora de $\\mathcal{D}$; só que esse não é o caso $-$ na maior parte das vezes, $\\mathcal{H}$ tem cardinalidade infinita, inclusive. Isso nos motiva a introduzir uma nova notação:   Defina  e ; ou seja,  e  são, respectivamente, as quantidades  e  como função de . Então é óbvio que, para todo , , . O ganho em definir essa nova notação aparece no próximo parágrafo. Observação: o subscrito “” faz referência ao termo in-sample; da mesma forma, “” quer dizer out-of-sample.   A cota que temos até agora diz respeito a uma única função $h \\in \\mathcal{H}$ ; porém, se $\\mathcal{H}$ tem cardinalidade maior que $1$ (o que, na prática, é sempre verdade), podemos escrever uma relação parecida para uma função $g \\in \\mathcal{H}$ escolhida por $\\mathcal{A}$. Seja $\\mathcal{H}$ conjunto finito de tamanho $M$, então vale:     Nas equivalências acima, a primeira desigualdade é justificada por inclusão de eventos, a segunda por union bound, e a terceira, como já vimos, vem da Desigualdade de Hoeffding.   A princípio, essa cota que conseguimos para $g$ só faz sentido se $M$ for finito; já que o lado direito da desigualdade cresce com $M$. Entretanto, esse resultado pode ser generalizado para $\\mathcal{H}$ conjunto infinito.   Em resumo, é possível interpretar o resultado de que $\\mathbb{P}\\left[\\lvert E_{in}(g) - E_{out}(g)\\rvert &gt; \\epsilon\\right] \\leq 2 M e^{-2 \\epsilon^2 N}$ da seguinte forma: a depender de $M$ e $\\epsilon$, o nosso modelo consegue, de fato, aprender, pois a função $g \\in \\mathcal{H}$ escolhida por $\\mathcal{A}$ se aproxima de $f$ quando $N$ cresce $-$ no sentido de, se $E_{in}(g) \\approx 0$, ter probabilidade de erro arbitrariamente pequena para avaliar $\\mathbf{x} \\not\\in \\mathcal{D}$.   Conclusão   Vimos que, com a introdução de uma componente estocástica no nosso framework de aprendizado, é possível que nosso modelo aprenda (e não apenas memorize). Nesse caso, quando $N$ cresce, $E_{in}(g) \\approx E_{out}(g)$. Assim, se conseguirmos fazer com que $E_{in}(g) \\approx 0$, então teremos que $E_{out}(g) \\approx 0$; o que é o mesmo que dizer que se o algoritmo $\\mathcal{A}$ conseguir escolher uma função $g \\in \\mathcal{H}$ que tem bom desempenho em avaliar $\\mathbf{x} \\in \\mathcal{D}$, então $g$ também terá bons resultados para observações fora de $\\mathcal{D}$.   Qualquer dúvida, sugestão ou feedback, por favor, deixe um comentário abaixo.      Essa postagem faz parte de uma série de textos que tem o objetivo de estudar, principalmente, o curso “Learning from Data”, ministrado pelo Professor Yaser Abu-Mostafa. Outros materiais utilizados serão sempre referenciados.   ","categories": ["Machine Learning - Learning from Data"],
        "tags": [],
        "url": "http://localhost:4000/memorizar-nao-e-aprender/",
        "teaser":null},{
        "title": "[Parte 04] Modelos Lineares de Classificação & Implementação em Python do Pocket",
        "excerpt":"Na parte 03 dessa série de textos, discutimos se é possível que nossos algoritmos, de fato, aprendam; ou seja, se conseguimos determinar uma função $g \\in \\mathcal{H}$ que aproxima bem $f$ para pontos $\\mathbf{x} \\not\\in \\mathcal{D}$. Esse assunto ainda não foi esgotado, mas por hora vamos nos concentrar em estudar mais alguns algoritmos $-$ em especial, alguns modelos lineares.   Esse post vai ser um pouco diferente, no sentido de mesclar a apresentação teórica com a implementação prática (em Python) de um dos algoritmos de interesse: o Pocket Learning Algorithm (ou só Pocket) $-$ uma variação do Perceptron.   Fazendo referência ao PLA (Perceptron Learning Algorithm), que estudamos nas partes 01 e 02, uma de suas limitações era a de que os dados precisavam ser linearmente separáveis; caso contrário, o algoritmo não era capaz de classificar corretamente todos os pontos $\\mathbf{x} \\in \\mathcal{D}$, e, por consequência, não convergia. Perceba que essa é uma suposição bem forte, já que, na prática, os dados quase nunca tem essa característica. Uma solução para contornar esse problema seria a de limitar o número de iterações que o algoritmo poderia realizar antes de ser interrompido. Porém, dessa solução, surge um problema.   Lembre-se de que o Perceptron, na tentativa de ajustar o hiperplano definido por  que classifica corretamente um ponto , poderia “bagunçar” a classificação associada aos demais pontos. Em outras palavras, mais iterações não se traduzem em uma reta (para o caso de  dimensões) “melhor” (no sentido de ter  menor). Dito isso, uma ideia para tratar esse problema seria a de, a cada etapa do processo, verificar o erro in-sample e, nas situações nas quais ele for o menor, tomar o vetor  associado como o “escolhido”. Isso é exatamente o que o Pocket Learning Algorithm faz, veja o código a seguir:   # Raw implementation class Pocket:     \"\"\"     Pocket learning algorithm implementation     \"\"\"          def __init__(self, eta = 1, random_seed = 1, n_iterations = 100):         self.eta = eta         self.random_seed = random_seed         self.n_iterations = n_iterations           def fit(self, X, y):         rn = np.random.RandomState(self.random_seed)         self.w_ = rn.normal(loc = 0, scale = 0.01, size = X.shape[1] + 1)         counter = 0         errors = True                  partial_w = self.w_.copy()         partial_error_in_sample = 0         self.error_in_sample_ = 0                   while errors and (counter &lt; self.n_iterations):             errors = 0             error_freq = 0             for X_i, y_i in zip(X, y):                 if y_i != self.predict(X_i):                     # update weights for misclassified points                     update = self.eta * y_i                     self.w_[1:] += update * X_i                     self.w_[0] += update                     errors += 1                 for X_i, y_i in zip(X, y):                 if y_i != self.predict(X_i):                     # count misclassified points AFTER analyze all of them                      error_freq += 1                 partial_error_in_sample = (1 / X.shape[0]) * error_freq             if (counter == 0) or (partial_error_in_sample &lt; self.error_in_sample_):                 # update smallest error and best weights vector                 self.error_in_sample_ = partial_error_in_sample                   partial_w = self.w_.copy()             counter += 1                      self.w_ = partial_w.copy()         return self          def predict(self, X_i):         eval_func = np.dot(X_i, self.w_[1:]) + self.w_[0]         return np.where(eval_func &gt;= 0, 1, -1)   A classe Pocket é muito similar à classe Perceptron que havíamos criado anteriormente; o que faz sentido, já que o Pocket é uma modificação do Perceptron. A principal diferença está no método fit(). Perceba que agora o número de iterações não é definido apenas pela quantidade de vezes que o vetor $\\mathbf{w}$ tem que ser atualizado para que todos os pontos sejam corretamente classificados $-$ na verdade isso pode nem acontecer, já que, como dito, a suposição de que os dados são linearmente separáveis não é mais necessária. O atributo n_iterations cuida desse limite máximo.   Note também que, ao final de cada ciclo em que o algoritmo percorre todos os pontos $\\mathbf{x} \\in \\mathcal{D}$, o erro $E_{in}(h)$ (erro in-sample) é calculado e armazenado na variável partial_error_in_sample. Depois disso, no caso de ele ser o menor erro encontrado até o momento, essa quantidade é salva no atributo error_in_sample $-$ bem como o vetor $\\mathbf{w}$, que é armazenado em partial_w. Ao final, o vetor de pesos escolhido é aquele que teve o menor erro associado; ou seja, o vetor salvo em partial_w, que é então tranferido para o atributo w_.   Vamos ver agora como isso funciona em um conjunto de dados que não é linearmente separável. Considere o seguinte cenário: suponha que você quer classificar corretamente digitos númericos escritos a mão, como os mostrados na figura abaixo. Cada uma das imagens é composta por uma grade de $16 \\times 16$ pixels que assume valores entre $0$ e $255$; ou seja, teríamos um espaço Euclidiano $256$-dimensional de funções (possivelmente) real-avaliadas.    Figura 1 [fonte: “Learning from Data”] $-$ Dígitos numéricos escritos a mão.   A fim de diminuir essa quantidade de features (ou características, ou variáveis independentes, etc.), podemos considerar, apenas, alguma medida de intensidade e alguma medida de simetria dos pixels. Obviamente não estamos utilizando todas as informações, mas isso já deve ser o suficiente para termos bons resultados. No código a seguir, ajustaremos um modelo para classificar os dígitos $1$ e $5$ (lembre-se que o Pocket ainda é um classificador binário); veja:   %matplotlib inline import numpy as np import pandas as pd import matplotlib.pyplot as plt  df = pd.read_csv(\"http://www.amlbook.com/data/zip/features.train\", header = None, delimiter = r\"\\s+\") df.columns = ['number', 'intensity', 'symmetry'] df['number'] = df['number'].astype(int)  df.head(3)                           number       intensity       symmetry                       0       6       0.341092       -4.528937                 1       5       0.444131       -5.496812                 2       4       0.231002       -2.886750            mask = ((df.number == 1) | (df.number == 5)) # select only numbers '1' and '5' df = df[mask] df = df.reset_index(drop = True) df.head(3)                           number       intensity       symmetry                       0       5       0.444131       -5.496812                 1       1       0.123043       -0.707875                 2       1       0.113859       -0.931375            df.info()   &lt;class 'pandas.core.frame.DataFrame'&gt; RangeIndex: 1561 entries, 0 to 1560 Data columns (total 3 columns): number       1561 non-null int64 intensity    1561 non-null float64 symmetry     1561 non-null float64 dtypes: float64(2), int64(1) memory usage: 36.7 KB   Perceba que, depois de filtrar adequadamente o conjunto de dados, temos uma base com 1561 entradas que apresentam características (de intensidade e simetria dos pixels) dos números $1$ e $5$. Vamos, agora, plotar esses dados.   X = df.loc[:, ['intensity', 'symmetry']].values y = df.loc[:, 'number'].values y = np.where(y == 1, -1, 1) # maps 1 to -1, and 5 to 1  plt.scatter(X[y == -1, 0], X[y == -1, 1], color = \"red\", marker = \"o\", label = \"Number 1\") plt.scatter(X[y ==  1, 0], X[y ==  1, 1], color = \"green\", marker = \"s\", label = \"Number 5\") plt.xlabel(\"Intensity measure\") plt.ylabel(\"Symmetry measure\") plt.legend(loc = 1) plt.show()      A primeira coisa a se notar é que os dados não são linearmente separáveis. Dito isso, vamos, finalmente, ajustar o modelo:   my_pocket = Pocket(n_iterations = 100) my_pocket.fit(X, y)  print(\"Weights vector: {}.\".format(my_pocket.w_)) print(\"Smallest error in-sample: {}.\".format(my_pocket.error_in_sample_))   Weights vector: [-9.98375655 -1.494057   -4.21659422]. Smallest error in-sample: 0.0038436899423446506.   Nesse caso, estamos considerando o vetor $\\mathbf{w}$ associado ao menor erro $E_{in}(h)$ encontrado: 0.0038436899. Podemos, então, plotar o gráfico com as regiões de decisão; utilizando, para isso, a função plot_decision_regions já discutida na parte 02.   def plot_decision_regions(X, y, classifier, feature_names, resolution = 0.01, plot_lim = 0.25):     # general settings     markers = [\"o\", \"s\", \"*\", \"x\", \"v\"]     colors  = (\"red\", \"green\", \"blue\", \"gray\", \"cyan\")     x1_min, x1_max = X[:, 0].min() - plot_lim, X[:, 0].max() + plot_lim     x2_min, x2_max = X[:, 1].min() - plot_lim, X[:, 1].max() + plot_lim     # define a grid     xx1, xx2 = np.meshgrid(np.arange(x1_min, x1_max, resolution),                            np.arange(x2_min, x2_max, resolution))     # classify each grid point     result = classifier.predict(np.array([xx1.ravel(), xx2.ravel()]).T)     result = result.reshape(xx1.shape)     # make a plot     plt.contourf(xx1, xx2, result, colors = colors[0:len(np.unique(y))], alpha = 0.5)     for index, value in enumerate(np.unique(y)):          plt.scatter(x = X[y == value, 0], y = X[y == value, 1],                      color = colors[index],                     marker = markers[index],                     label = feature_names[index],                     edgecolor = 'black')   feature_names = ['Number 1', 'Number 5'] plot_decision_regions(X, y, my_pocket, feature_names, plot_lim = 0.15) plt.title(\"Fitted model with Pocket Learning Algorithm\") plt.xlabel(\"Intensity measure\") plt.ylabel(\"Symmetry measure\") plt.legend(loc = 1) plt.show()      Como podemos observar, o Pocket encontrou uma reta que minimiza (considerando as cem primeiras iterações) o erro amostral $-$ o que, como discutido na parte 03, é um dos passos necessários para dizermos que o nosso algoritmo aprendeu.   Conclusão   Vimos ao longo do texto um generalização para o Perceptron, chamada Pocket. Esses dois algoritmos fazem parte de uma classe maior de modelos lineares, e são, portanto, classificadores lineares. No próximo post vamos estudar o modelo de regressão $-$ nesse caso, a função alvo $f: \\mathcal{X} \\rightarrow \\mathcal{Y}$ terá contradominio nos números reais.   Qualquer dúvida, sugestão ou feedback, por favor, deixe um comentário abaixo.      Essa postagem faz parte de uma série de textos que tem o objetivo de estudar, principalmente, o curso “Learning from Data”, ministrado pelo Professor Yaser Abu-Mostafa. Outros materiais utilizados serão sempre referenciados.   ","categories": ["Machine Learning - Learning from Data"],
        "tags": [],
        "url": "http://localhost:4000/modelos-lineares-de-classificacao-e-pocket/",
        "teaser":null},{
        "title": "[Parte 05] Modelo de Regressão Linear & Implementação em Python",
        "excerpt":"Continuando a discussão sobre modelos lineares, assunto que começamos a estudar na parte 04 dessa série de textos, vamos, nesse post, falar do modelo de regressão. A principal diferença entre esse tipo de modelo e os classificadores que estudamos anteriormente é que agora a função alvo $f$ é real-avaliada $-$ que é o mesmo que dizer que $\\mathcal{Y} \\subset \\mathbb{R}$.   Para dar contexto ao problema, considere o seguinte exemplo: você é professor de uma turma de Ensino Médio e, ao longo do ano, aplica três provas de 20 pontos cada. Depois de os alunos realizarem os dois primeiros testes, você deseja construir um modelo que lhe permita predizer a nota dos alunos na terceira prova. Perceba que, nesse caso, não estamos tentando “classificar” a terceira nota $-$ aqui, $y \\in [0, 20]$. Para resolver esse tipo de tarefa, faremos uso de um modelo (linear) de regressão. Observação 1: inúmeras outras características dos alunos poderiam ser utilizadas como preditores (exemplo: horas de estudo, número de faltas ao longo do ano, etc.), mas para simplicidade do modelo, vamos nos atentar, somente, às notas nas duas primeiras avaliações.   Nesse caso, a classe de funções $h \\in \\mathcal{H}$ será defina por:     Perceba que $h$, como acabamos de definir, é muito parececido com a classe funções que utilizamos quando dicutimos o Perceptron; porém, ao invés do sinal $-$ $\\text{sign}(\\cdot)$ $-$, estamos interessado no valor de $\\mathbf{w}^{\\text{T}}\\mathbf{x}$.   Continuando, da mesma forma que fizemos quando estudamos o modelo Pocket, o que queremos nesse caso é minimizar o erro amostral $-$ $E_{in}(h)$ $-$, associado ao modelo. Nesse sentido, utilizaremos uma medida de erro clássica para análise de regressão: o erro quadrático. Defina $E_{out}(h) = \\mathbb{E}\\left[(h(\\mathbf{x}) - y)^2\\right]$ $-$ nesse caso, o valor esperado é calculado com respeito à distruição $P(\\mathbf{x}, y)$. Porém, como não temos acesso à medida de erro $E_{out}(h)$, como discutimos na parte 03, uma alternativa é minimar o erro in-sample.   Assim, podemos escrever que . Nesse sentido, nossa missão é encontrar  tal que  é mínimo. Veja:     Derivando $E_{in}(\\mathbf{w})$; ou seja, calculando o vetor gradiente $\\nabla E_{in}(\\mathbf{w})$, obtemos:     Igualando $\\nabla E_{in}(\\mathbf{w})$ ao vetor $\\mathbf{0}$, temos que:     Assim, se $X^{\\text{T}}X$ for invertível, então $\\mathbf{w} = (X^{\\text{T}} X)^{-1} X^{\\text{T}} \\mathbf{y}$; onde $X^{\\dagger} = (X^{\\text{T}} X)^{-1} X^{\\text{T}}$ é conhecida como pseudo-inversa de $X$. Aqui, $(X^{\\text{T}} X)^{-1}$ existirá sempre que nenhuma coluna de $X$ for combinação linear das outras; na prática, se $N$ for muito maior que $d + 1$, então isso quase sempre será satisfeito.   Aqui, dois pontos são importantes. Obervação 2: note que obtemos uma solução analítica para minimizar $E_{in}(\\mathbf{w})$ $-$ para o caso do Pocket, por exemplo, esse não era o caso. Observação 3: perceba que $E_{in}(\\mathbf{w})$ é função de $\\mathbf{w}$, e não de $X$ (que, nessa situação, é constante).   Agora que temos um solução para o problema de minimazação do erro, podemos implementar o algoritmo. A classe LinearRegression cuida disso.   # Raw implementation class LinearRegression:     \"\"\"     Linear Regression Algorithm     \"\"\"     def __ini__(self):         pass          def fit(self, X, y):         Z = np.array([1 for x in np.arange(X.shape[0])])         X = np.c_[Z, X] # create an array by including each component as a column         X_dagger = np.linalg.pinv(X) # find the pseudo-inverse matrix         self.w_  = np.dot(X_dagger, y)          return self          def predict(self, X):         return np.dot(X, self.w_[1:]) + self.w_[0]   Perceba que no método fit() calculamos a pseudo-inversa de $X$ através da função pinv() (implementada pelo o módulo de álgebra linear do Numpy). Depois disso, bastou calcularmos o vetor de pesos w_ definido por $\\mathbf{w} =  X^{\\dagger} \\mathbf{y}$. O método predict() apenas implementa a função $h(\\mathbf{x})$.   Agora, para ajustarmos o modelo, considere o exemplo das notas de três provas feitas por alunos do Ensino Médio discutido no começo do texto. Veja os dados:   %matplotlib inline import numpy as np import pandas as pd import matplotlib.pyplot as plt  df = pd.read_csv(\"student-mat.csv\", sep = \";\") df = df.loc[:, ['G1', 'G2', 'G3']] df.head(3)                           G1       G2       G3                       0       5       6       6                 1       5       5       6                 2       7       8       10            df.info()   &lt;class 'pandas.core.frame.DataFrame'&gt; RangeIndex: 395 entries, 0 to 394 Data columns (total 3 columns): G1    395 non-null int64 G2    395 non-null int64 G3    395 non-null int64 dtypes: int64(3) memory usage: 9.4 KB   Perceba que temos $395$ entradas não nulas para cada uma das três provas. Nesse caso, G1 e G2 serão nossos preditores, e G3 será fará o papel da variável dependente. Vamos, então, visualizar como os dados se comportam:   X = df.loc[:, ['G1', 'G2']].values y = df.loc[:, 'G3'].values  from mpl_toolkits.mplot3d import Axes3D  fig = plt.figure(figsize = (6, 6)) ax  = fig.add_subplot(111, projection = '3d') ax.scatter(X[:, 0], X[:, 1], y, color = \"red\", marker = \"o\")  ax.set_xlim3d(0, 20) ax.set_ylim3d(0, 20) ax.set_zlim3d(0, 20)  ticks = np.arange(0, 24, 4) ax.xaxis.set(ticks = ticks) ax.yaxis.set(ticks = ticks) ax.zaxis.set(ticks = ticks)  ax.set_xlabel(\"G1\") ax.set_ylabel(\"G2\") ax.set_zlabel(\"G3\")  ax.view_init(30, 150)  plt.tight_layout() plt.show()      Note que, ao menos a primeira vista, os dados da amostra aparentam ter comportamento linear; o que nos permite prosseguir com o ajuste do modelo:   my_regression = LinearRegression() my_regression.fit(X, y) print(\"Weights vector: {}.\".format(my_regression.w_))   Weights vector: [-1.83001214  0.15326859  0.98686684].   Veja que o vetor de pesos, nesse caso com $3$ coordenadas ($w_0$, $w_1$ e $w_2$, respectivamente) foi facilmente determinado. Para conseguirmos visualizar o plano definido por esse vetor, podemos plotar o seguinte gráfico:   g1 = np.arange(0, 20, 0.1) g2 = np.arange(0, 20, 0.1) g1, g2 = np.meshgrid(g1, g2) g3 = my_regression.predict(np.c_[np.ravel(g1), np.ravel(g2)]) g3 = g3.reshape(g1.shape)  fig = plt.figure(figsize = (6, 6)) ax  = fig.add_subplot(111, projection = '3d') ax.plot_surface(g1, g2, g3, color = \"red\", alpha = 0.5) ax.scatter(X[:, 0], X[:, 1], y, color = \"red\", marker = \"o\", edgecolor = \"black\")  ax.set_xlim3d(0, 20) ax.set_ylim3d(0, 20) ax.set_zlim3d(0, 20)  ticks = np.arange(0, 24, 4) ax.xaxis.set(ticks = ticks) ax.yaxis.set(ticks = ticks) ax.zaxis.set(ticks = ticks)  ax.set_title(\"Fitted model with raw implementation\", pad = 15) ax.set_xlabel(\"G1\") ax.set_ylabel(\"G2\") ax.set_zlabel(\"G3\")  ax.view_init(30, 150) # ax.invert_xaxis()  plt.tight_layout() plt.show()      Nesse caso, o plano parece representar bem o conjunto de pontos. Entretanto, ainda não temos uma análise quantitativa desse tipo de medida $-$ como dito em posts anteriores, ainda vamos chegar lá: na discussão da acurácia dos modelos que escrevemos.   Um pequeno teste que podemos fazer é o de predizer, de acordo com o modelo ajustado, qual nota dois alunos arbitrários tirariam na prova G3 (com base em suas notas G1 e G2).   print(\"O aluno A teve notas G1 = 6.5 e G2 = 17. Assim, espera-se que ele tire {:.2f} pontos na última prova.\".format(my_regression.predict(np.array([6.5, 17])))) print(\"\\n\") print(\"O aluno B teve notas G1 = 17 e G2 = 6.5. Assim, espera-se que ele tire {:.2f} pontos na última prova.\".format(my_regression.predict(np.array([17, 6.5]))))   O aluno A teve notas G1 = 6.5 e G2 = 17. Assim, espera-se que ele tire 15.94 pontos na última prova.   O aluno B teve notas G1 = 17 e G2 = 6.5. Assim, espera-se que ele tire 7.19 pontos na última prova.   Uma observação interessante nesse caso é a de que a nota G3 é mais afetada pela nota G2 do que por G1 $-$ o que faz total sentido, já que, como vimos, $w_2 &gt; w_1$.   Por fim, vamos utilizar a implementação do Sklearn para o modelo de regressão linear. Confira o código a seguir:   # Sklearn usage from sklearn.linear_model import LinearRegression  sklearn_regression = LinearRegression() sklearn_regression.fit(X, y)  print(\"Weights vector - intercept: {} &amp; coefficients: {}.\".format(sklearn_regression.intercept_, sklearn_regression.coef_))   Weights vector - intercept: -1.8300121405807381 &amp; coefficients: [0.15326859 0.98686684].   Nesse caso, como obtivemos uma solução analítica para $\\mathbf{w}$, os resultados são exatamente iguais aos que encontramos.   Conclusão   Nesse texto discutimos o importante modelo de regressão linear, que nos permite então, trabalhar com uma função alvo $f: \\mathcal{X} \\rightarrow \\mathcal{Y}$, com $\\mathcal{Y} \\subset \\mathbb{R}$. Como vimos, nesse caso há uma solução analítica para $\\mathbf{w}$, o que nem sempre é o caso. Além disso, fizemos a implementação do algoritmo em Python $-$ em contraponto à utilização direta do Sklearn (que também foi feita no final do texto). Na próxima postagem, discutiremos como trabalhar com transformações não lineares.   Qualquer dúvida, sugestão ou feedback, por favor, deixe um comentário abaixo.      Essa postagem faz parte de uma série de textos que tem o objetivo de estudar, principalmente, o curso “Learning from Data”, ministrado pelo Professor Yaser Abu-Mostafa. Outros materiais utilizados serão sempre referenciados.   ","categories": ["Machine Learning - Learning from Data"],
        "tags": [],
        "url": "http://localhost:4000/modelo-de-regressao-linear/",
        "teaser":null},{
        "title": "[Parte 06] Transformações NÃO-lineares & Implementação em Python",
        "excerpt":"Como vimos até agora nessa série de textos, modelos lineares (tanto de classificação quanto de regressão) utilizam a quantidade $\\sum_{i = 0}^{d} w_i x_i$ para calcular a função $h \\in \\mathcal{H}$. Note que essa expressão é linear para os $x_i$’s e $w_i$’s; porém, como discutimos na parte 05, os $x_i$’s podem, do ponto de vista do algoritmo, ser encaradados como constantes (pense que o conjunto de dados $\\mathcal{D}$, no momento que vamos ajustar o modelo, já está definido). Dessa forma, basta que a expressão que estamos considerando seja linear para o vetor de pesos $-$ o que, em outras palavras, significa dizer que podemos aplicar tranformações não-lineares em $\\mathbf{x} \\in \\mathcal{D}$.   Nessa postagem vamos discutir (e implementar) dois exemplos: um de classificação $-$ utilizando o algoritmo Perceptron $-$, e outro de regressão; ambos com transformações não lineares aplicadas no conjunto de dados.   Classificação   Para o primeiro caso, vamos gerar um conjunto de dados que será classificado de acordo com a posição de um ponto dentro (ou fora) de um circunferência com centro na origem.   Veja como o conjunto de dados foi gerado, bem como uma representação gráfica dos pontos.   %matplotlib inline import numpy as np import pandas as pd import matplotlib.pyplot as plt  rn = np.random.RandomState(999) x1 = rn.normal(0, 1.00, 100) x2 = rn.normal(0, 1.00, 100)  mask_in  = ((x1 ** 2) + (x2 ** 2) - 1.00 &lt; 0) mask_out = ((x1 ** 2) + (x2 ** 2) - 1.44 &gt; 0) &amp; ((x1 ** 2) + (x2 ** 2) - 4.00 &lt; 0)   x1_in  = x1[mask_in] x2_in  = x2[mask_in] x1_out = x1[mask_out] x2_out = x2[mask_out]  X = np.array(np.c_[x1_in.tolist() + x1_out.tolist(), x2_in.tolist() + x2_out.tolist()]) y = np.asarray([np.where(y &lt; x1_in.shape[0], -1, 1) for y in np.arange(x1_in.shape[0] + x1_out.shape[0])])  plt.scatter(X[:x1_in.shape[0], 0], X[:x1_in.shape[0], 1], color = \"red\", marker = \"o\", label = \"In\") plt.scatter(X[x1_in.shape[0]:, 0], X[x1_in.shape[0]:, 1], color = \"green\", marker = \"s\", label = \"Out\") plt.axis(\"scaled\") plt.xlim(-2.25, 2.25) plt.ylim(-2.25, 2.25) plt.xlabel(\"original $x_1$\") plt.ylabel(\"original $x_2$\") plt.legend(loc = 1) plt.show()      Nesse exemplo, pontos sorteados segundo uma distribuição $N(0, 1)$ para cada uma das coordenadas foram definidos como In $-$ caso o ponto esteja dentro da circunferência de raio $1$ $-$ ou Out $-$ caso o ponto esteja fora da circunferência de raio $1.2$ e dentro da circunferência de raio $2$. Obviamente, essas duas classes não são linearmente separáveis.   Assim, vamos aplicar uma transformação nos pontos de $\\mathbf{x}$ tal que $\\phi: (x_1, x_2) \\rightarrow ({x_1}^2, {x_2}^2)$, para todo $\\mathbf{x} \\in \\mathcal{D}$. Veja, agora, como os dados transformados podem ser representados:   X_transformed = np.power(X, 2)  plt.scatter(X_transformed[:x1_in.shape[0], 0], X_transformed[:x1_in.shape[0], 1], color = \"red\", marker = \"o\", label = \"In\") plt.scatter(X_transformed[x1_in.shape[0]:, 0], X_transformed[x1_in.shape[0]:, 1], color = \"green\", marker = \"s\", label = \"Out\") plt.axis(\"scaled\") plt.xlim(-0.25, 4.25) plt.ylim(-0.25, 4.25) plt.xlabel(\"transformed $x_1$\") plt.ylabel(\"transformed $x_2$\") plt.legend(loc = 1) plt.show()      Feita as transformação nos dados de acordo com a nossa função $\\phi$, para todo $\\mathcal{x} \\in \\mathcal{D}$ (nesse caso, por construção), o meu conjunto de pontos é linearmente separável. Sendo assim, posso aplicar, por exemplo, o Perceptron (utilizando o Sklearn $-$ caso queira ver a implementação completa do algoritmo, consulte a parte 02):   from sklearn.linear_model import Perceptron  perceptron = Perceptron() perceptron.fit(X_transformed, y)  print(\"Intercept weight: {}.\".format(perceptron.intercept_)) print(\"Weights vector: {}.\".format(perceptron.coef_))   Intercept weight: [-2.]. Weights vector: [[2.36966542 1.48327095]].   De posse do modelo ajustado; i.e., do vetor $\\mathbf{w}$ completamente definido, podemos plotar as regiões de decisão, utilizando a função plot_decision_regions() introduzida, pela primeira vez, na parte 02.   # modified function to admit data transformation def plot_decision_regions(X, y, classifier, feature_names, modified = False, transf1 = lambda x: x, transf2 = None, resolution = 0.01, axis_lim = 1):     # general settings     markers = [\"o\", \"s\", \"*\", \"x\", \"v\"]     colors  = (\"red\", \"green\", \"blue\", \"gray\", \"cyan\")     x1_min, x1_max = X[:, 0].min() - axis_lim, X[:, 0].max() + axis_lim     x2_min, x2_max = X[:, 1].min() - axis_lim, X[:, 1].max() + axis_lim     # define a grid     xx1, xx2 = np.meshgrid(np.arange(x1_min, x1_max, resolution),                            np.arange(x2_min, x2_max, resolution))     # tranform the point that will be predicted, but NOT the one which will be plotted     if modified:         if transf2 == None:             transf2 = transf1         xx1_mod = transf1(xx1)         xx2_mod = transf2(xx2)     else:         xx1_mod = xx1         xx2_mod = xx2           # classify each grid point     result = classifier.predict(np.array([xx1_mod.ravel(), xx2_mod.ravel()]).T)     result = result.reshape(xx1_mod.shape)     # make a plot     plt.contourf(xx1, xx2, result, colors = colors[0:len(np.unique(y))], alpha = 0.5)     for index, value in enumerate(np.unique(y)): # plot each point &amp; 'enumerate()' returns index and value of the given array         plt.scatter(x = X[y == value, 0], y = X[y == value, 1], # select each X and y vectors by creating a mask                     color = colors[index],                     marker = markers[index],                     label = feature_names[index],                     edgecolor = 'black')   Perceba que a função foi levemente modificada para comportar dois novos parâmetros: transf1 e transf2 (além do modified, que é, apenas, uma tecnicalidade). Esses variáveis recebem uma função responsável pela transformação de cada uma das features do nosso conjunto de dados (por exemplo, uma transformação como a definida por $\\phi(\\mathbf{x})$). Mas antes de utilizarmos esse novo artifício, vamos ver como ficam as regiões de decisão para os dados transformados:   feature_names = [\"In\", \"Out\"] plot_decision_regions(X_transformed, y, perceptron, feature_names) plt.title(\"Fitted model using transformed $X$\") plt.xlabel(\"Transformed $x_1$\") plt.ylabel(\"Transformed $x_2$\") plt.axis(\"scaled\") plt.xlim(-0.25, 4.25) plt.ylim(-0.25, 4.25) plt.legend(loc = 1) plt.show()      Por enquanto, nada de novo; como era de se esperar, os dados foram corretamente classificados e separados.   Agora o que podemos fazer (que é, de fato, a parte interessante) é contruir as regiões de decisão para os dados originais; nesse caso, utilizaremos os parâmetros transf1 e transf2 passando, como argumento, a função lambda: x: x ** 2 $-$ ou seja, do mesmo modo que definimos $\\phi$. Veja:   feature_names = [\"In\", \"Out\"] plot_decision_regions(X, y, perceptron, feature_names, True, lambda x: np.power(x, 2)) plt.title(\"Fitted model using original $X$\") plt.xlabel(\"Original $x_1$\") plt.ylabel(\"Original $x_2$\") plt.axis(\"scaled\") plt.xlim(-2.25, 2.25) plt.ylim(-2.25, 2.25) plt.legend(loc = 1) plt.show()      Tomando esse tipo de estratégia, nós conseguimos, como pode ser visto acima, classificar dois grupos de pontos que, à princípio, não eram linearmente separáveis.   Regressão   Agora, nesse segundo exemplo, vamos estudar um problema de regressão. Para isso, considere o seguinte cenário: suponha que as informações “salário” e “felicidade” (para alguma medida arbitrária que captura esse sentimento) foram coletadas a partir de um grupo de $100$ indivíduos; suponha, ainda, que o salário dessas pessoas segue distribuição $\\text{Gamma}(2, 5000)$ (para uma distribuição desse tipo, temos média $10\\times 10^3$ e assimetria à direita) $-$ veja o histograma a seguir.   rn = np.random.RandomState(1) X  = rn.gamma(2, 5000, 100) X  = X.reshape(100, 1) plt.hist(X, color = \"red\", alpha = 0.5, bins = 10) plt.xlabel(\"Salary (\\$)\") plt.ylabel(\"Frequency\") plt.xticks(np.arange(0, 45e3, 5e3)) plt.show()      Assim, temos vários indivíduos que ganham salários em torno dos dez mil reais, e alguns outros poucos trabalhadores que ganham quantias muito maiores do que essa.   Agora, suponha que a “felicidade” depende do “salário”, mas essa relação não é linear; ou seja, depois de uma determinada quantidade de dinheiro, receber mais não se traduz em ser proporcionalmente mais feliz. Podemos representar essa dependência através da função $\\log(\\cdot)$.   y = np.log(X) + rn.normal(0, 0.2, 100).reshape(100, 1) plt.scatter(X, y, marker = \"o\", color = \"red\") plt.title(\"Salary (\\$) vs. Happiness\") plt.xlabel(\"Salary (\\$)\") plt.ylabel(\"Happiness measure\") plt.xticks(np.arange(0, 45e3, 5e3)) plt.show()      No código acima, perceba perceba que a “felicidade”, como função do “salário”, foi somada a valores que vêm de uma distruição $N(0, 0.04)$ $-$ esse termo será denominado por “ruído” ($\\epsilon$), e refere-se à diferença entre os valores observado e real (não observável) da variável dependente. Lembre-se de que, quando falamos de regressão linear, estamos interessados em estudar um modelo do tipo: $y = w_0 + w_1 x_1 + \\cdots + w_d x_d + \\epsilon$.   Visualmente (e por construção, nesse caso), a relação descrita acima não é linear; nesse caso, faz sentido aplicarmos alguma transformação na variável independente.   X_transformed = np.log(X) plt.scatter(X_transformed, y, marker = \"s\", color = \"green\", alpha = 0.75) plt.title(\"Transformed Salary ($\\log$ of \\$) vs. Happiness\") plt.xlabel(\"Transformed Salary ($\\log$ of \\$)\") plt.ylabel(\"Happiness measure\") plt.show()      Note que, aplicando $\\log(\\cdot)$ em $x$, obtemos algo que se aproxima mais de uma relação linear. Nesse caso, podemos ajustar o modelo de regressão (utilizando o Sklearn $-$ caso queira ver a implementação completa do algoritmo, consulte a parte 05). Primeiro, ajustaremos o modelo considerando $x$ e, depois, considerando $\\log(x)$.   from sklearn.linear_model import LinearRegression  regression_original = LinearRegression() regression_original.fit(X, y)  x_min = X[:, 0].min() x_max = X[:, 0].max() x_values = np.arange(x_min, x_max, 100) y_values = regression_original.predict(np.asarray(x_values).reshape(len(x_values), 1)) plt.plot(x_values, y_values, color = \"darkred\") plt.scatter(X, y, marker = \"o\", color = \"red\") plt.title(\"Fitted Regression for Salary\") plt.xlabel(\"Salary (\\$)\") plt.ylabel(\"Happiness measure\") plt.xticks(np.arange(0, 45e3, 5e3)) plt.show()      regression_transformed = LinearRegression() regression_transformed.fit(X_transformed, y)  x_min = X_transformed[:, 0].min() x_max = X_transformed[:, 0].max() x_values = np.arange(x_min, x_max, 0.01) y_values = regression_transformed.predict(np.asarray(x_values).reshape(len(x_values), 1)) plt.plot(x_values, y_values, color = \"darkgreen\") plt.scatter(X_transformed, y, marker = \"s\", color = \"green\", alpha = 0.75) plt.title(\"Fitted regression for $\\log$ of Salary\") plt.xlabel(\"Transformed Salary ($\\log$ of \\$)\") plt.ylabel(\"Happiness measure\") plt.show()      Perceba que o primeiro modelo ajustado, com a variável $x$ original (indicado pelo gráfico de título Fitted Regression for Salary) não representa bem o conjunto de dados (no próximo parágrafo, vamos analisar isso quantitativamente). Ao passo que, quando transformamos $x$, aplicando, nesse caso, a função $\\log(\\cdot)$, obtemos uma reta (visualmente) melhor ajustada.   Uma medida que podemos utilizar para quantificar a intuição de “qual modelo se ajusta melhor aos dados” é a quantidade $R^2$ (R-squared); que, a grosso modo, diz o quanto da variação de $y$ é explicada pela regressão. Vamos aproveitar a função score() implementada na classe LinearRegression para obter essa medida.   r2_original = regression_original.score(X, y) print(\"R-squared for the original model: {}.\".format(r2_original)) print(\"Intercept: {} &amp; Coefficients: {}.\".format(regression_original.intercept_[0], regression_original.coef_[0, 0]))   R-squared for the original model: 0.7538771643539155. Intercept: 7.975309624979791 &amp; Coefficients: 9.828555226466561e-05.   r2_transformed = regression_transformed.score(X_transformed, y) print(\"R-squared for the 'tranformed' model: {}.\".format(r2_transformed)) print(\"Intercept: {} &amp; Coefficients: {}.\".format(regression_transformed.intercept_[0], regression_transformed.coef_[0, 0]))   R-squared for the 'tranformed' model: 0.9431020022916391. Intercept: 0.12929691342341698 &amp; Coefficients: 0.9867610189477893.   Mais uma vez, o primeiro resultado diz respeito ao modelo que considera $x$, enquanto que o segundo, ao modelo que considera $\\log(x)$ como variável independente. Perceba que, quando aplicamos a tranformação no nosso preditor “salário”, obtemos um $R^2$ maior $-$ que é, quase sempre, melhor.   Um ponto importante é como devemos interpretar, quando olhamos para o segundo modelo, o coeficiente que obtemos; aqui, $w_1 \\approx 0.987$. Nesse caso, podemos dizer que $1\\%$ de aumento do salário, resulta em aumento de, aproximadamente, $\\frac{0.987}{100} = 0.00987$ “unidades de felicidade”.   Conclusão   No começo do texto vimos que, para aplicar os modelos lineares que estudamos até agora (seja de classificação, seja de regressão), basta que, olhando para a expressão $\\sum_{i = 0}^{d} w_i x_i$, os $w_i$’s sejam lineares; ou seja, podemos aplicar transformações não-lineares no conjunto de dados $X$. Nesse sentido, vimos dois exemplos (implementados em Python), nos quais transformações do tipo $(\\cdot)^2$ e $\\log(\\cdot)$ foram aplicadas. No próximo post vamos falar um pouco mais sobre medidas de erro.   Qualquer dúvida, sugestão ou feedback, por favor, deixe um comentário abaixo.      Essa postagem faz parte de uma série de textos que tem o objetivo de estudar, principalmente, o curso “Learning from Data”, ministrado pelo Professor Yaser Abu-Mostafa. Outros materiais utilizados serão sempre referenciados.   ","categories": ["Machine Learning - Learning from Data"],
        "tags": [],
        "url": "http://localhost:4000/transformacoes-nao-lineares/",
        "teaser":null},{
        "title": "[Parte 07] Erro e Ruído",
        "excerpt":"Formalizando alguns conceitos sobre os quais já falamos ao longo dessa série de textos, essa postagem será dedicada à discussão de: 1) Como quantificar o quão bem a hipótese final $g \\in \\mathcal{H}$ se aproxima da função alvo $f$? 2) Como lidar com o “ruído” associado à $f$?   Medidas de Erro   Dando sequência às ideias sobre as quais começamos a discutir na parte 03, e relembrando que $g$ é apenas uma aproximação de $f$, é importante que sejamos capazes de definir uma medida de erro para essa diferença. Vamos, então, começar por definir “erro” da seguinte forma:     Aqui, note que o erro é uma função de cada uma das possíveis $h \\in \\mathcal{H}$ e de $f$. Mais explicitamente, dado um ponto $\\mathbf{x}$, podemos definir $e(h(\\mathbf{x}), f(\\mathbf{x}))$ como uma medida pontual de erro. Assim, $E$ será determinado pela média dos erros pontuais $e$’s, para todo $\\mathbf{x} \\in \\mathcal{D}$.   Nesse sentido, temos como exemplo: ${}^{*)}$ $e(h(\\mathbf{x}), f(\\mathbf{x})) = \\mathbb{I}_{\\lbrace h(\\mathbf{x}) \\neq f(\\mathbf{x}) \\rbrace}$, quando falamos de classificadores; ou ${}^{**)}$ $e(h(\\mathbf{x}), f(\\mathbf{x})) = (h(\\mathbf{x}) - f(\\mathbf{x}))^2$, quando estudamos o modelo de regressão.   Um ponto importante a se discutir é que, em uma situação ideal, a medida de erro ($E$) deve ser escolhida de acordo com o problema com o qual se está trabalhando. Entretanto, isso nem sempre é praticável $-$ pode acontecer de a função erro (ou “função custo”, ou “função perda”) especificada ser de difícil otimização (no sentido matemático da palavra; i.e., pode não ser possível determinar o vetor de pesos $\\mathbf{w}$ que minimiza essa medida).   Ruído   Em situações reais, é possível que não sejamos capazes de obter toda a informação que determina unicamente, através da função $f$, o valor do ponto $\\mathbf{x} \\in \\mathcal{X}$; ou seja, existem características que não são observáveis, e, portanto, não podem ser explicitamante incluídas no modelo que escrevemos. Assim, temos que acomodar no nosso framework essa diferença, denomimanda por ruído, entre os valores observado e real (não observável) de $y$.   Assim, ao invés de definirmos $y = f(\\mathbf{x})$, podemos enxergar $y$ como variável aleatória. Formalmente, ao invés de uma função alvo $f$, teremos uma distribuição alvo $P(y \\mid \\mathbf{x})$. Dessa forma, um ponto ($\\mathbf{x}$, y) é gerado a partir da distribuição conjunta $P(\\mathbf{x}, y) = P(\\mathbf{x}) P(y \\mid \\mathbf{x})$. Seguindo esse raciocínio, teremos que $y = f(\\mathbf{x}) + \\epsilon$; onde, para o modelo de regressão, $f(\\mathbf{x}) = \\mathbb{E}(y \\mid \\mathbf{x})$. Aqui, chamaremos de $\\epsilon$ de “ruído”, mas existem outros nomes que podem ser encontrados na literatura (“erro”, por exemplo).   O esquema abaixo introduz essa nova compomente $-$ distribuição alvo $-$, bem como a medida de erro (discutida no começo do texto) no diagrama de aprendizado que estamos construindo.    Figura 1 [fonte: “Learning from Data”] $-$ Framework completo de aprendizado.   Observações importantes   Note que existe uma diferença no papel das distribuição $P(y \\mid \\mathbf{x})$ e $P(\\mathbf{x})$ em relação ao problema do aprendizado que temos discutido até agora. A primeira distruição é a que estamos tentanto aprender, ao passo que a segunda diz respeito à quantificação do quão bem estamos aprendendo (como explicado em detalhes na parte 03).   Por fim, podemos nos perguntar se aprender a distribuição alvo é tão fácil quanto aprender a função alvo. E a resposta é: “não necessariamente”. Perceba que a aproximação de $E_{out}$ por $E_{in}$ ainda pode ser igual para os dois cenário (a construção que fizemos na parte 03 continua válida); entretanto, o erro amostral ($E_{in}$) pode ser potencialmente maior $-$ pela dificuldade de incorporar o ruído no modelo ajustado.   Conclusão   Nesse post, discutimos com um pouco mais de profundidade a quantificação que podemos fazer sobre o quão bem uma função $g \\in \\mathcal{H}$ pode aproximar $f$; além de como medidas de erro podem ser definidas nesse contexto. Em adição, incorporamos o conceito de ruído ao nosso framework de aprendizado, nos permitindo incluir no nosso modelo a diferença entre os valores observado e real (não observável) da variável dependente. Nos próximos textos, vamos generalizar vários dos conceitos que estudamos até agora.   Qualquer dúvida, sugestão ou feedback, por favor, deixe um comentário abaixo.      Essa postagem faz parte de uma série de textos que tem o objetivo de estudar, principalmente, o curso “Learning from Data”, ministrado pelo Professor Yaser Abu-Mostafa. Outros materiais utilizados serão sempre referenciados.   ","categories": ["Machine Learning - Learning from Data"],
        "tags": [],
        "url": "http://localhost:4000/erro-e-ruido/",
        "teaser":null},{
        "title": "[Parte 08] Teoria da Generalização",
        "excerpt":"Ao longo dessa e da próxima postagem da nossa série de textos, vamos estabelecer e estudar a distinção que tem que existir entre o conjunto de dados utilizados para treinar o nosso modelo, e o conjunto de dados utilizado para testá-lo.   Nesse sentido, e considerando medidas de erro, o termo  nos diz o quão bem o nosso modelo ajustado, baseado em , generalizou o comportamento da função alvo (ou distribuição alvo) fora desse conjunto de dados   ou seja, a medida  é definida por pontos . Em contrapartida, o erro  baseia-se nos dados de treinamento (conjunto ). Além disso, como começamos a discutir na parte 03, a relação entre  e   dado um conjunto de hipóteses  de tamanho  , é definida por:     Veja que a inequação acima torna-se pouco útil quando consideramos um conjunto $\\mathcal{H}$ de tamanho infinito (que é o que acontece na maior parte dos casos). Lembre-se também de que essa cota foi obtida pela propriedade de union bound para a união dos eventos $\\left[ \\lvert E_{in}(h_m) - E_{out}(h_m) \\rvert &gt; \\epsilon \\right]$, com $m = 1, \\cdots, M$. Entretanto, se existir grande interseção entre esses eventos (que é o que acontece), essa cota não é boa $-$ vamos, dessa forma, tentar melhorá-la.   Para alcançar um objetivo como esse, vamos, primeiro, definir uma nova quantidade: a função de crescimento. Essa função é o que substituirá $M$ na nossa cota. A sequência de observações e definições a seguir nos levará onde queremos chegar.   Agora, ao invés de tomarmos $h: \\mathcal{X} \\longrightarrow \\lbrace -1, +1 \\rbrace$ (para simplificar os argumentos, iremos considerar funções avaliadas no conjunto $\\lbrace -1, +1 \\rbrace$, ao invés de $\\mathbb{R}$), vamos restringir o domínio da função aos pontos de $\\mathcal{D}$; i.e., $h: \\lbrace \\mathbf{x}_1, \\cdots, \\mathbf{x}_N \\rbrace \\longrightarrow \\lbrace -1, +1 \\rbrace$. Assim, se $h$ for avaliada em uma amostra finita $\\lbrace \\mathbf{x}_1, \\cdots, \\mathbf{x}_N \\rbrace \\subset \\mathcal{X}$, iremos obter um $N$-upla $(h(\\mathbf{x}_1), \\cdots, h(\\mathbf{x}_N))$ de $\\pm 1 $’s.Essa “nova” função $h$ será chamada de dicotomia.   Definição 1: Tome $\\lbrace \\mathbf{x}_1, \\cdots, \\mathbf{x}_N \\rbrace \\subset \\mathcal{X}$. As dicotomias geradas por $\\mathcal{H}$ sobre esse conjunto de pontos serão definida por:     Definição 2: A função de crescimento é definida, para um conjunto $\\mathcal{H}$, como:     onde $\\lvert \\cdot \\rvert$ é a cardinalidade do conjunto.   Em palavras,  é número máximo de dicotomias que podem ser geradas por  a partir de um conjunto de  pontos. Aqui, note que, como os elementos de  são subconjuntos de , então . Além disso, se  for capaz de gerar todas as possíveis dicotomias sobre , então  e nós dizemos que  pode quebrar .   Para entendermos melhor os conceitos que acabamos de definir, considere $\\mathcal{H}$ como sendo o conjunto de hipóteses associado ao algoritmo Perceptron avaliado em duas dimensões. A partir da figura abaixo, podemos dizer que:    Figura 1 [adaptado de: “Learning from Data”] $-$ Análise da função de crescimento para o Perceptron.   Olhando para , onde os pontos  e  foram dispostos de maneira colinear, observe que não conseguimos, utilizando o Perceptron, obter todas as oito -uplas; entretanto, considerando , isso é possível, logo . Por outro lado, para , somente catorze das possíveis dezesseis -uplas podem ser geradas pelo Perceptron  assim, .   Veja, nesse caso, que não é fácil calcular, como função de $N$, a quantidade $m_{\\mathcal{H}}(N)$. Observe ainda que, se considerarmos diferentes conjuntos $\\mathcal{H}$, associados a diferentes algorimos, essa diculdade pode ser ainda maior. Felizmente, para conseguirmos o que estamos querendo, basta que sejamos capazes de determinar uma cota superior “boa” (veremos a seguir, o que quero dizer por “boa”) para $m_{\\mathcal{H}}(N)$. Mas antes disso, mais uma definição:   Definição 3: se nenhum conjunto de pontos de tamanho $k$ puder ser quebrado (de acordo com a definição que demos ao termo “quebrar”) por $\\mathcal{H}$, então $k$ é chamado de break point para $\\mathcal{H}$.   A partir da Def. 3, é fácil notar que se $\\mathcal{H}$ é a classe de funções associada ao algoritmo Perceptron em duas dimensões, então $k = 4$ é break point para $\\mathcal{H}$.   A Def.3 também é fundamental para conseguirmos a cota “boa” que gostaríamos de ter para $m_{\\mathcal{H}}(N)$. Veja o teorema a seguir:   Teorema 1: Se $m_{\\mathcal{H}}(N) &lt; 2^k$ para algum valor de $k$; isto é, se existe break point  $k$ para $\\mathcal{H}$, então     para todo $N$. Observação: aqui, o lado direito da inequação é um polinômio em $N$ de grau $k - 1$.   A demonstração do Teorema 1 pode ser encontrada no Capítulo 2 de Learning from Data.   Observe que um cota como a estabelecida pelo Teor. 1 é boa, pois, se pudermos substituir $M$ por $m_{\\mathcal{H}}(N)$ em $\\mathbb{P}(\\lvert E_{in}(g) - E_{out}(g) \\rvert &gt; \\epsilon) \\leq 2 M e^{-2 \\epsilon^2 N}$, então:      $m_{\\mathcal{H}}(N)$ será dominada por alguma coisa que cresce polinomiamente rápido com $N$.   $e^{-2 \\epsilon^2 N}$ decresce exponecialmente rápido com $N$.   Logo $\\mathbb{P}(\\lvert E_{in}(g) - E_{out}(g) \\rvert &gt; \\epsilon)$  será menor ou igual que alguma quantidade arbitrariamente próxima de zero, como gostaríamos que fosse.   Desigualdade de Vapnik-Chervonenkis   Finalmente, o último passo que queremos conseguir justificar é o da troca de $M$ por $m_{\\mathcal{H}}(N)$. Se isso for possível, resolvemos nosso problema. Esse resultado (a menos de troca de constantes) é conhecido como Desigualdade de Vapnik-Chervonenkis e é enunciado a seguir.   Teorema 2 (Desigualdade de Vapnik-Chervonenkis): Para qualquer $N \\in \\mathbb{N}$, vale:     A demonstração do Teorema 2 pode ser encontrada no Apêndice A de Learning from Data.   No Teor. 2, perceba que as constantes que foram alteradas, em comparação à Desigualdade de Hoeffding, não “jogam ao nosso favor”. Porém, para $N$ suficientemente grande, o lado direito da desigualdade ainda é arbitrariamente pequeno.   Conclusão   Como já foi estabelecido desde a parte 03, nosso interesse é argumentar que o erro $E_{out}$ (construído a partir de $\\mathcal{X} - \\mathcal{D}$) é bem aproximado por $E_{in}$ (construído a partir de $\\mathcal{D}$). Havíamos resolvido essa questão quando o tamanho de $\\mathcal{H}$ é finito; porém, do ponto de vista prático, esse quase nunca é o caso. Assim, se pudermos construir uma cota (como na Desigualdade de Hoeffding) que depende de $m_{\\mathcal{H}}(N)$ ao invés de $M$, conseguimos generalizar adequamente a ideia de que é possível que o nosso modelo, a partir de um conjunto de hipóteses $\\mathcal{H}$ com cardinalidade (potencialmente) infinita, aprenda. Felizmente, a desigualdade de Vapnik-Chervonenkis estabelece essa relação e resolve esse problema.   Qualquer dúvida, sugestão ou feedback, por favor, deixe um comentário abaixo.      Essa postagem faz parte de uma série de textos que tem o objetivo de estudar, principalmente, o curso “Learning from Data”, ministrado pelo Professor Yaser Abu-Mostafa. Outros materiais utilizados serão sempre referenciados.   ","categories": ["Machine Learning - Learning from Data"],
        "tags": [],
        "url": "http://localhost:4000/teoria-da-generalizacao/",
        "teaser":null},{
        "title": "[Parte 09] Dimensão de Vapnik-Chervonenkis",
        "excerpt":"Continuando a discussão que começamos na última parte da nossa série de textos, vamos estudar mais propriedades associadas ao que demos o nome de “Teoria da Generalização”; ou, em outras palavras, ao estudo de como os nossos modelos podem ser generalizados para conjuntos de dados fora de $\\mathcal{D}$.   Nesse sentido, a primeira definição que vamos introduzir $-$ e a mais importante do ponto de vista prático, é a de Dimensão Vapnik-Chervonenkis (VC).   Definição 1: a dimensão VC de um conjunto $\\mathcal{H}$, denotada por $d_{\\text{VC}}(\\mathcal{H})$ (ou somente $d_{\\text{VC}}$), é o maior valor de $N$ para o qual $m_{\\mathcal{H}}(N) = 2^N$.   De forma simples, a dimensão VC corresponde ao máximo de pontos $N$ (para algum conjunto de pontos) que $\\mathcal{H}$ pode quebrar (lembre-se do significado que demos à essa expressão). Além disso, como é fácil perceber, se $d_{\\text{VC}}$ é dimensão VC para $\\mathcal{H}$, então $k = d_{\\text{VC}} + 1$ é break point. Assim, o Teor. 1 da parte 08 pode ser reescrito da seguinte forma:     onde o termo do lado direito da inequação é um polinômio de grau $d_{\\text{VC}}$; i.e., a dimensão VC também determina o grau do polinômio que limita a função de crescimento.   Uma outra consequência direta dessa nova definição é que conseguimos, sem surpresa, caracterizar o fenômeno $f \\approx g$; ou seja, se $d_{\\text{VC}}$ é finito, então $g \\in \\mathcal{H}$ irá generalizar o comportamento de $f$. Em adição, perceba que a dimensão VC é independente de:      $\\mathcal{A}$, o algoritmo de aprendizagem $-$ note que, sob a hipótese de que $d_{\\text{VC}}$ é finito, $f$ é generalizada (bem ou mal) por qualquer $h \\in \\mathcal{H}$.   $P$, a distribuição de entrada $-$ nesse caso, perceba que, para a função de crescimento, escolhemos um conjunto de pontos que maximiza o números de dicotomias geradas por $\\mathcal{H}$; assim, a escolha da distribuição que determina os pontos de $\\mathcal{D}$ não exerce papel fundamental na ideia de “generalização”.   $f$, a função alvo $-$ veja que, satisfeita determinadas condições, a Desigualdade de Vapnik-Chervonenkis é válida independente de que função $f$ estamos tentando generalizar.   Agora, utilizando o conceito que acabamos de definir, podemos tentar determinar a dimensão VC para algum conjunto conhecido de hipóteses $\\mathcal{H}$. Por exemplo, para o Perceptron $d$-dimensional, temos que $d_{\\text{VC}} = d + 1$. A demonstração desse fato não é complicada, e o argumento principal recai sobre o fato de que é possível mostrar que: ${}^{(a)}$ $d_{\\text{VC}} \\leq d + 1$ e ${}^{(b)}$ $d_{\\text{VC}} \\geq d + 1$. Entretanto, mais importante do que o resultado em si, é sua interpretação: qual o significado da quantidade $d + 1$ em um modelo Perceptron de $d$ dimensões?   Para o algoritmo Perceptron $d$-dimensional, a quantidade $d + 1$ diz respeito à quantidade de parâmetros necessários para se determinar a hipótese $h \\in \\mathcal{H}$. Nesse sentido, podemos dizer que, de alguma forma, a dimensão VC é tão maior (ou menor) quanto for o número de parâmetros efetivos (aqui, talvez o termo “graus de liberdade” seja mais adequado) do modelo com o qual estamos trabalhando.   Além disso, uma outra interpretação da quantidade “dimensão VC” pode ser introduzida $-$ nesse caso, uma interpretação prática. Mas antes, vamos relembrar o que a Desigualdade Vapnik-Chervonenkis diz:     onde $\\delta = 4 \\cdot m_{\\mathcal{H}}(2N) \\cdot e^{-\\frac{1}{8} \\epsilon^2 N}$.   Da equação anterior, podemos nos perguntar: fixados $\\delta$ e $\\epsilon$, como se relacionam $N$ e $d_{\\text{VC}}$? Para tentar responder à essa pergunta, ao invés de olharmos para $\\delta$ como definido acima, vamos nos concentrar em analisar $\\delta = N^{d_{\\text{VC}}} \\cdot e^{-N}$ (que é uma simplificação “honesta” do problema que estamos tentando estudar). O gráfico de $\\delta(N)$ para diferentes valores de $d_{\\text{VC}}$ é apresentado a seguir.   # plot of (N^d * exp{-N}) for different values of \"d\"  %matplotlib inline import numpy as np import matplotlib.pyplot as plt  def my_func(N, d):     return ((N ** d) * np.exp(-1 * N))  d_values = [5, 10, 15, 20, 25, 30]  x = np.linspace(0, 200, num = 100) for d in d_values:     y = my_func(x, d)     plt.plot(x, y, label = \"d = \" + str(d))  plt.axhline(1, color = \"black\") plt.xlabel(\"N\") plt.ylabel(\"Upper bound for the desired probab. (log scale)\") plt.xlim(0, 200) plt.ylim(10e-3, 10e9) plt.yscale(\"log\") plt.legend() plt.show()      Perceba que a cota superior para a probabilidade deseja também cresce à medida que $d_{\\text{VC}}$ cresce. Observação 1: apesar de estarmos olhando para uma cota superior de $\\mathbb{P}\\left[ \\lvert E_{in}(g) - E_{out}(g) \\rvert &gt; \\epsilon \\right]$, o comportamento apresentado no gráfico traduz, empiricamente, o comportamento da probabilidade desejada. Assim, se estamos trabalhando com modelos de alta dimensão VC, precisaremos de uma amostra de tamanho proporcionalmente maior $-$ como regra prática, utilizaremos $N = 10 \\cdot d_{\\text{VC}}$.   Cota para Teoria da Generalização   Por fim, antes de terminar esse texto, vamos trabalhar um pouco com a Desigualdade de Vapnik-Chervonenkis, reescrevendo-a em um formato que nos será mais útil. Dessa forma, se $\\delta = 4 \\cdot m_{\\mathcal{H}}(2N) \\cdot e^{-\\frac{1}{8} \\epsilon^2 N}$, então:     Assim, com probabilidade $\\geq 1 - \\delta$,     Porém, como o termo $E_{in}$ é (quase sempre) forçadamente menor que $E_{out}$ (lembre-se que, quando ajustamos um modelo, estamos tentando minimiar $E_{in}$), podemos simplificar um pouco mais a nossa notação e escrever que, com probabilidade $\\geq 1 - \\delta$,     A inequeção que acabamos de escrever é conhecida como uma cota para o “erro generalizado”.   Finalmente, com probabilidade $\\geq 1 - \\delta$,     Essa forma de reescrever a Desigualdade de Vapnik-Chervonenkis é interessante porque, apesar do termo da esquerda permanecer desconhecido, nós temos algum controle sobre $E_{in}$ e $\\Omega$ (o primeiro é o que tentamos minimizar, enquanto que o segundo relaciona-se à escolha de $\\mathcal{H}$). Observação 2: aqui, note que um conjunto de hipóteses $\\mathcal{H}$ “grande” ajuda a minimar $E_{in}$, mas faz com que $\\Omega$ cresça (já que, se $\\mathcal{H}$ cresce, então $d_{\\text{VC}}$ também é potencialmente maior), o que é ruim. Dessa forma, deve existir um balanço sobre o tamanho de $\\mathcal{H}$ para minimizar o termo $E_{out}$.   Conclusão   Dando continuidade à parte 08, definimos e estudamos uma nova quantidade: dimensão VC ou $d_{\\text{VC}}(\\mathcal{H})$. Vimos, nesse caso, como o valor de $d_{\\text{VC}}$ afeta, do ponto de vista prático, o tamanho de amostra $N$ que temos que ter para minimar a diferença entre $E_{out}$ e $E_{in}$. Por último, rearranjando os termos da Desigualdade de Vapnik-Chervonenkis, fomos capazes de escrever uma cota, como função de $E_{in}$ e de $\\Omega(N, \\mathcal{H}, \\delta)$, para o termo $E_{out}$. No próximo post vamos discutir, principalmente, a questão do tradeoff entre viés e variância.   Qualquer dúvida, sugestão ou feedback, por favor, deixe um comentário abaixo.      Essa postagem faz parte de uma série de textos que tem o objetivo de estudar, principalmente, o curso “Learning from Data”, ministrado pelo Professor Yaser Abu-Mostafa. Outros materiais utilizados serão sempre referenciados.   ","categories": ["Machine Learning - Learning from Data"],
        "tags": [],
        "url": "http://localhost:4000/dimensao-vc/",
        "teaser":null}]
