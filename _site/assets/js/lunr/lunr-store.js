var store = [{
        "title": "Uma Introdução ao NumPy e Pandas para Análise de Dados",
        "excerpt":"Python oferece muitas bibliotecas que extendem suas funcionalidades padrão. Por esse motivo, quando vamos trabalhar com processamento de dados, existem dois pacotes muito úteis que podemos utilizar: Numpy e Pandas.   Numpy cria um novo objeto array multidimensional que nos permite estruturar e operar nosso conjunto de dados de maneira fácil (e muito mais rápido que as tradicionais listas do Python). Além disso, nós também temos o Pandas, uma biblioteca de alto-nível construída sobre o código do Numpy que oferece dois novos tipos de estrutura de dados: Series e DataFrame.   A primeira coisa que temos que fazer antes de usar essas bibliotecas é importá-las. Para isso, veja as duas linhas de código a seguir:   import numpy  as np import pandas as pd   Agora, nós podemos conferir se os pacotes foram importadas de maneira correta imprimindo suas versões:   print(\"Numpy  -\", np.__version__) print(\"Pandas -\", pd.__version__)   Numpy  - 1.17.4 Pandas - 0.25.3   Como dito anteriormente, NumPy é uma biblioteca de baixo-nível, se comparada ao Pandas. Por esse motivo, nós vamos começar com ela, criando algumas arrays.   A fim de criar uma array de 1 dimensão (1D), digite:   my_array = np.array([0, 1, 2], dtype = \"int16\") my_array   array([0, 1, 2], dtype=int16)   Note que nós criamos uma variável chamada my_array e atribuímos a ela uma array de três elementos: $\\lbrace0, 1, 2\\rbrace$. Em adição, nós também determinamos o parâmetro dtype $-$ isso é importante porque, diferente do que acontece com as variáveis padrão no Python, a biblioteca NumPy nos permite dizer quanto de espaço será alocado na memória para salvar um determinado objeto; nesse sentido, NumPy é mais parecido com a linguagem C, na qual você deve que determinar a quantidade de bits que será utilizada para armazenar algo.   Continuando com a mesma sintaxe, nós podemos criar arrays $n$ dimensionais.   # 2D array (2, 2) my2D_array = np.array([[11, 12], [21, 22]]) print(\"2D array, with dtype = {}: \\n{}\\n\".format(my2D_array.dtype, my2D_array))  # 3D array (2, 2, 2) my3D_array = np.array([[[111, 112], [121, 122]], [[211, 212], [221, 222]]]) print(\"3D array, with dtype = {}: \\n{}\\n\".format(my3D_array.dtype, my3D_array))   2D array, with dtype = int64:  [[11 12]  [21 22]]  3D array, with dtype = int64:  [[[111 112]   [121 122]]   [[211 212]   [221 222]]]   Note que, para o caso my2D_array, nós criamos uma array de 2 dimensões com 2 linhas e 2 colunas; i.e., $(2 \\times 2)$. Por outro lado, considerando a variável my3D_array, uma array de 3 dimensões, com 2 linhas, 2 colunas e 2 camadas de produnfidade $-$ ou seja, $(2 \\times 2 \\times 2)$ $-$, foi criada. Por fim, perceba que, como não determinamos manualmente o atributo dtype, a biblioteca Numpy o definiu como int64, justificado pelos valores que cada umas das arrays assumiu.   Dessa forma, se quisermos fatiar alguns desses elementos, podemos tratar essas arrays de maneira similar às listas do Python:   # on the 2D array, we want to slice the first row: (11, 12) print(\"My 2D sliced array:\", my2D_array[0, :])  # on the 3D array, we want to slice the elements of the second row and second column for both layers of depth: (221, 222) print(\"My 3D sliced array:\", my3D_array[1, 1, :])    My 2D sliced array: [11 12] My 3D sliced array: [221 222]   Nesse exemplo, é importante notar que os índices começam de 0 (como de costume).   Além desses comandos simples, Numpy também disponibiliza uma grande quantidade de métodos e atributos que podem ser utilizados para realizar tarefas específicas. Vou demonstrar alguns deles, mas para uma lista completa, acesse a documentação oficial (Numpy Doc).   Em relação às operações matemáticas, esses são os métodos mais utilizados:   # create two arrays that will be used on the math operations a = np.array([[1, 2], [3, 4]]) # array([[1, 2],                                #        [3, 4]])  b = np.array([[4, 3], [2, 1]]) # array([[4, 3],                                #        [2, 1]])  # Element by element addition print(\"Addition (element by element): \\n{}\\n\".format(np.add(a, b)))  # Element by element subtraction print(\"Subraction (element by element): \\n{}\\n\".format(np.subtract(a, b)))  # Element by element multiplication print(\"Multiplication (element by element): \\n{}\\n\".format(np.multiply(a, b)))  # Matrix multiplication print(\"Matrix multiplication: \\n{}\\n\".format(np.dot(a, b)))  # Element by element division print(\"Division (element by element): \\n{}\\n\".format(np.divide(a, b)))   Addition (element by element):  [[5 5]  [5 5]]  Subraction (element by element):  [[-3 -1]  [ 1  3]]  Multiplication (element by element):  [[4 6]  [6 4]]  Matrix multiplication:  [[ 8  5]  [20 13]]  Division (element by element):  [[0.25       0.66666667]  [1.5        4.        ]]   O método mais importante aqui é o np.dot(array_1, array_2), que faz a multiplicação “adequada” de duas matrizes; em contraponto ao método np.multiply(array_1, array_2), que realiza o produto termo a termo das duas arrays.   Por fim, antes de começarmos a trabalhar com a biblioteca Pandas, tem mais um exemplo que gostaria de apresentar. Veja a seguir:   # create a 1D array with elements [0, 25[; then reshape it to a 2D array with 5 rows and 5 cols an_array = np.array(np.arange(0, 25)).reshape(5, 5) an_array   array([[ 0,  1,  2,  3,  4],        [ 5,  6,  7,  8,  9],        [10, 11, 12, 13, 14],        [15, 16, 17, 18, 19],        [20, 21, 22, 23, 24]])   print(\"Shape of the array:\", an_array.shape) print(\"Number of dimensions:\", an_array.ndim)   Shape of the array: (5, 5) Number of dimensions: 2   Com esses dois pedaços de código acima, nós conseguimos aprender um pouco mais sobre algumas funcionalidades do Numpy. Primeiro, nós criarmos uma array unidimensioal com 25 elementos $\\lbrace 0, 1, \\cdots, 23, 24 \\rbrace$; então, na mesma linha de código, nós utilizamos o método reshape() e transformamos esse objeto em uma array $(5 \\times 5)$. Finalmente, o “formato” e o número de dimensões da array foram impressos utilizando os atributos shape e ndim, respectivamente.   Exitem dezenas de outros métodos e atributos diferentes para se explorar com o Numpy, mas isso foi suficiente para uma introdução. Vamos agora trabalhar com o Pandas.   A biblioteca Pandas, como dito no começo do tutorial, fornece duas novas estruturas que serão extremamente importantes para o processamento de dados. Enquanto a estrutura Series equivale a uma array com rótulos de 1 dimensão, um DataFrame é uma array de duas dimensões que pode ter colunas heterogêneas (o que significa que podemos ter cada coluna de um Data Frame armazenando um tipo de dado diferente). Sendo assim, como é possível de se imaginar, um conjunto de Series forma um  DataFrame.   Agora, podemos começar a escrever algum código utilizando Pandas. Vamos ver como criar e utilizar essas novas ferramentas:   # create a pair of new Series s1 = pd.Series(['A', 'B', 'C']) s2 = pd.Series([1.2, 0.7, 3.0])  print(\"Series 1: \\n{}\".format(s1)) print() print(\"Series 2: \\n{}\".format(s2))   Series 1:  0    A 1    B 2    C dtype: object  Series 2:  0    1.2 1    0.7 2    3.0 dtype: float64   Note que a sintaxe é bem intuitiva; entretanto, o aspecto mais importantes vem do fato de que agora temos duas sequências explicitamente rotuladas e que podem ser combinadas para criar um DataFrame.   Um DataFrame pode ser encarado como um dicinário de Series; assim, a fim de criar um objeto desse tipo, podemos utilizar o seguinte código:   # create a dictionary with the previous Series (s1 and s2) data = {'1st col': s1, '2nd col': s2}  # create a DataFrame with this dictionary my_df = pd.DataFrame(data) my_df                           1st col       2nd col                       0       A       1.2                 1       B       0.7                 2       C       3.0            Note que nós começamos com dois objetos do tipo Series, e então os combinamos para criar um DataFrame. Temos, agora, um conjunto tabulado com informações heterogêneas.   Nesse segundo exemplo, vamos criar um DataFrame preenchendo-o com os elementos de uma array criada utilizando Numpy.   my_dataFrame = pd.DataFrame(np.arange(0, 50).reshape(10, 5), columns = ['1st', '2nd', '3rd', '4th', '5th']) my_dataFrame                           1st       2nd       3rd       4th       5th                       0       0       1       2       3       4                 1       5       6       7       8       9                 2       10       11       12       13       14                 3       15       16       17       18       19                 4       20       21       22       23       24                 5       25       26       27       28       29                 6       30       31       32       33       34                 7       35       36       37       38       39                 8       40       41       42       43       44                 9       45       46       47       48       49            Como é possível ver, nós criamos DataFrame a partir uma array de duas dimensões gerada utilizando Numpy.   Uma das operações mais úteis que podemos fazer com essa nova estrutura é, mais uma vez, fatiá-la. Para fazer isso, podemos utilizar o atributo iloc[] a fim de selecionar uma porção do DataFrame original.   # using the same \"my_dataFrame\" DataFrame # select the 3rd and 4th columns and the rows with indexes from 4 to 8 my_dataFrame[['3rd', '4th']].iloc[4:9]                           3rd       4th                       4       22       23                 5       27       28                 6       32       33                 7       37       38                 8       42       43            Perceba que, se você quiser selecionar mais de uma coluna, terá que utilizar um lista para agrupá-las.   A próxima alternativa para fatiar um DataFrame é criando uma máscara que utiliza algum tipo de condicional; por exemplo, se nós quisermos recuperar, na terceira coluna (3rd), os valores que são maiores que 20, nós podemos fazer o seguinte:   # create a mask mask = my_dataFrame['3rd'] &gt; 30  # apply the mask to the \"3rd\" column in order to slice the DataFrame considering the given condition my_dataFrame['3rd'][mask]   6    32 7    37 8    42 9    47 Name: 3rd, dtype: int64   Note que nós primeiro criamos a máscara, e então a aplicamos sobre o DataFrame, escolhendo tanto as colunas (3rd) quanto as linhas (aquelas que tem valor maior que 30) desejadas.   Finalmente, nós vamos ver alguns métodos da biblioteca Pandas; porém, como já dito anteriormente, eu recomendo fortemente que você leia a documentação oficial do Pandas.   A seguir, vamos criar um conjunto de dados para os nossos próximos exemplos.   # let's create a DataFrame for the next demonstrations  col_labels = ['Name', 'Age', 'Nationality']  name        = pd.Series(['André', 'James', 'Agata', 'María', 'Pedro', 'Juan', 'Paul']) age         = pd.Series([23, 27, 21, None, 27, 22, 25]) nationality = pd.Series(['Brazilian', 'American', 'Greek', 'Mexican', 'Brazilian', 'Mexican', 'British'])  people = {col_labels[0]: name,           col_labels[1]: age,           col_labels[2]: nationality}  df_people = pd.DataFrame(people) df_people.head()                           Name       Age       Nationality                       0       André       23.0       Brazilian                 1       James       27.0       American                 2       Agata       21.0       Greek                 3       María       NaN       Mexican                 4       Pedro       27.0       Brazilian            A primeira coisa a observar, é a ulização do médoto head(), que retorna, por padrão, apenas as 5 primeiras linhas do nosso banco de dados. É mais conveniente visualizar apenas as primeiras linhas do DataFrame quando o conjunto de dados com o qual se está trabalhando é grande demais. Além disso, uma das idades (Age) está “em branco” (isso é muito comum em aplicações do mundo real, e nós vamos ver como tratar esse tipo de problema).   Nós podemos começar lidando com o valor None. Existem algumas estratégias diferentes que podemos tomar; entretanto, a fim de manter esse tutorial o mais simples possível, vamos apenas eliminar a linha que contém esse problema. Para fazer isso, podemos utilizar o método dropna():   df_people.dropna(inplace = True) df_people                           Name       Age       Nationality                       0       André       23.0       Brazilian                 1       James       27.0       American                 2       Agata       21.0       Greek                 4       Pedro       27.0       Brazilian                 5       Juan       22.0       Mexican                 6       Paul       25.0       British            Como é possível de ser visto, nós removemos a linha com índice 3. Para fazer isso de forma permanente, foi necessário atribuir o valor True ao parâmetro inplace.   Agora, nós podemos ter uma visão geral do conjunto de dados utilizando o método info().   df_people.info()   &lt;class 'pandas.core.frame.DataFrame'&gt; Int64Index: 6 entries, 0 to 6 Data columns (total 3 columns): Name           6 non-null object Age            6 non-null float64 Nationality    6 non-null object dtypes: float64(1), object(2) memory usage: 192.0+ bytes   Veja que o método utlizado nós mostrou que temos 6 entradas não nulas para cada uma das 3 colunas.   A seguir, vamos assumir que queremos saber a média de idade das pessoas com nacionalidade brasileira (Brazilian). Para essa situação hipotética, a primeira coisa que temos que fazer é criar uma máscara para selecionar os invíduos que nasceram no Brasil.   # create a mask n_mask = df_people['Nationality'] == 'Brazilian'  # apply the mask df_people[n_mask]                           Name       Age       Nationality                       0       André       23.0       Brazilian                 4       Pedro       27.0       Brazilian            Com essas linhas de código, nós filtramos o DataFrame para mostrar apenas as pessoas com nacionalidade brasileira. Falta, então, calcular a média de suas idades:   average_age = df_people[n_mask].mean() average_age   Age    25.0 dtype: float64   Note que o resultado é uma estrutura do tipo Series. Dessa forma, se quisermos formatá-lo, podemos utilizar o atributo values, que retorna os valores do objeto em questão como uma array Numpy.   print(\"The average age of the Brazilian citizens is {:.0f} years.\".format(average_age.values[0]))   The average age of the Brazilian citizens is 25 years.   Conclusão   Numpy e Pandas são duas bibliotecas essenciais para se trabalhar com análise de dados. Numpy introduz objetos do tipo ndarray (arrays $n$ dimensionais) e o Pandas implementa duas novas estruturas de dados: Series e DataFrame. Dessa forma, se você quiser utilizar os conceitos de ciência de dados, aprendizagem de máquina, etc. nos seus projetos com Python, você deve aprender a utilizar essas excelentes ferramentas.   Qualquer dúvida, sugestão ou feedback, por favor, deixe um comentário abaixo.      Eu havia escrito esse texto, originalmente em inglês, em uma antiga versão do blog que já não existe mais. Pequenas correções e atualizações, além da própria tradução, foram feitas para que o conteúdo continuasse relevante.   ","categories": ["Tutorial"],
        "tags": ["python","ciencia-de-dados"],
        "url": "http://localhost:4000/introducao-numpy-pandas/",
        "teaser":null},{
        "title": "Visualização de Dados com Matplotlib",
        "excerpt":"Uma parte essencial do processo de análise de dados é a visualização parcial e final dos resultados que foram alcançados. Na maior parte das vezes, é muito mais fácil interpretar esse tipo de informação graficamente do que através de, apenas, tabelas ou números.   Entretanto, mais do que apenas ser capaz de plotar gráficos, é importante que o pesquisador (ou estudante, ou cientista de dados, etc.) represente esse conjunto de dados de uma forma que sua audiência consiga entender. Você precisa ter gráficos acessíveis, confiáveis e elegantes (Kirk, A. citado em Curso edX).   Em Python, o pacote mais básico para visualização de dados é o Matplotlib. Ele nos permite plotar diferentes tipos de gráficos com dezenas de opções de customização. Por esse motivo, nós o escolhemos para esse tutorial.      Toda a imagem mostrada acima é uma Figure criada pelo módulo matplotlib.pyplot; dentro dela, na área branca, estão compreendidos os eixos x e y, chamadas de Axes ou Subplot (existe uma pequena diferença entre esses dois termos, mas para a maioria dos casos, eles podem ser tratados como sinônimos). Além disso, no canto superior esquerdo, existe um pequeno menu que nos permite realizar algumas ações $-$ incluindo exportar o gráfico como imagem.   Observação: A partir desse ponto, eu não vou mais apresentar toda a janela mostrada na figura acima; ao invés disso, apenas os gráficos serão gerados.   Agora que sabemos o básico, vamos importar a biblioteca e verificar se ela está funcionando.   %matplotlib inline import matplotlib.pyplot as plt   Perceba que, na maior parte das situações, nós só temos que importar o módulo pyplot. Assim, se nenhuma mensagem de erro apareceu, o Matplotlib foi corretamente importado.   Observação 2: se você está utilizando o Jupyter Notebook para realizar seus testes, é necessário que o comando %matplotlib inline seja incluído antes de importar a biblioteca.   Como você deve imaginar, a primeira coisa que temos que fazer é criar uma Figure:   fig = plt.figure(figsize = (3, 6))   &lt;Figure size 216x432 with 0 Axes&gt;   Além de criar um objeto Figure e atribuí-lo à variável fig, nós defimos os valores para o parâmetro figsize, que, como o nome sugere, determina o tamanho da janela: $3 \\times 6$ polegadas.   Agora nós criamos, dentro do “container” fig, um objeto Axes. Para isso, basta utilizar o método add_subplot():   ax1 = fig.add_subplot(111)   Note que, mais uma vez, nós tivemos que passar o valor de um parâmetro para a função. Nesse caso, o 111 representa o número de objetos Axes que serão criados dentro de fig: uma array com 1 linha, 1 coluna e índice 1.   O próximo passo é definir os dados que serão utilizados para plotar o gráfico. Para esse primeiro exemplo, eu vou criar duas listas que ilustram o comportamento da função $f(x) = 2x$ com domínio em $\\lbrace 0, 1, \\cdots, 10 \\rbrace$:   x = [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10] y = [0, 2, 4, 6, 8, 10, 12, 14, 16, 18, 20]   Feito isso, agora só precisamos plotar esses valores em um sistema de coordenadas utilizando o comando plot(); e, por fim, chamar o método show() para mostrá-lo na tela:   # all the code togheter fig = plt.figure(figsize = (3, 6)) ax1 = fig.add_subplot(111) ax1.scatter(x, y) plt.show()      Observação 3: mais uma vez, se você está utilizando Jupyter Notebook, talvez seja necessário que todos os comandos estejam em uma única célula.   Em adição ao que acabamos de fazer, é possível modificar algumas característica do gráfico, veja a seguir:   # all the code togheter fig = plt.figure(figsize = (2, 4)) # intentionally smaller than the previous one ax1 = fig.add_subplot(111) ax1.scatter(x, y, label = 'f(x)', color = 'red')  # ax1 properties ax1.set_title('My Title') ax1.set_xlabel('X') ax1.set_ylabel('Y')  plt.legend(loc = 4) plt.show()      Nós incluímos informações importantes com essas últimas linhas de código. No método scatter(), nós adicionamos dois parâmetros: labele color. O primeiro deles é usado para identificar a curva que está sendo plotada (através do método legend()), enquanto que o segundo define a cor dos pontos.   Além disso, definimos algumas novas propriedades para o objeto ax1: o método set_title() define o título do gráfico, e os métodos set_xlabel e set_ylabel definem os rótulos que serão utilizados nos eixos $x$ e $y$, respectivamente.   A biblioteca Matplotlib, como mencionado no começo desse texto, é muito flexível; por isso, a fim de extrair todo o seu potencial, é importante que você leia a documentação oficial.   Finalmente, um outro exemplo, um pouco mais complexo, será apresentado. Primeiro, veja o seguinte código:   import numpy as np  # create a new figure fig = plt.figure(figsize = (10, 5))  # create two new Axes objects in the format of a '1 row x 2 columns' array ax1 = fig.add_subplot(121) ax2 = fig.add_subplot(122)  # create the data set that will be plotted x = np.linspace(0, np.pi * 2) y = np.sin(x) # y = f(x) = sin(x) z = np.cos(x) # z = g(x) = cos(x)  # plot f(x) and g(x) ax1.plot(x, y, label = 'sin', color = 'b') # 'b' stands for 'blue' ax2.plot(x, z, label = 'cos', color = 'r') # 'r' stands for 'red'  # set 'ax1' properties ax1.set_title('Trigonometric Functions - SINE') ax1.set_xlabel('Angle (in radian)') ax1.set_ylabel('Magnitude') ax1.axis([0, np.pi * 2, -1.25, 1.25]) # define the range of both axes # define ticks for each axis (3 auxiliary variables) xticks = [0, np.pi / 2, np.pi, np.pi * 1.5, np.pi * 2]                         # define the ticks values - 'X' axis xlabel = ['0', '$\\\\frac{\\\\pi}{2}$', '$\\\\pi$', '$\\\\frac{3\\\\pi}{2}$', '$2\\\\pi$'] # define the label values - 'X' axis yticks = [-1, -0.5, 0, 0.5, 1]                                                 # define the ticks values - 'Y' axis ax1.xaxis.set(ticks = xticks, ticklabels = xlabel) ax1.yaxis.set(ticks = yticks) ax1.legend(loc = 1)  # set 'ax1' properties ax2.set_title('Trigonometric Functions - COSINE') ax2.set_xlabel('Angle (in radian)') ax2.set_ylabel('Magnitude') ax2.axis([0, np.pi * 2, -1.25, 1.25]) # define the range of both axes # define ticks for each axis (3 auxiliary variables) xticks = [0, np.pi / 2, np.pi, np.pi * 1.5, np.pi * 2]                         # define the ticks values - 'X' axis xlabel = ['0', '$\\\\frac{\\\\pi}{2}$', '$\\\\pi$', '$\\\\frac{3\\\\pi}{2}$', '$2\\\\pi$'] # define the label values - 'X' axis yticks = [-1, -0.5, 0, 0.5, 1]                                                 # define the ticks values - 'Y' axis ax2.xaxis.set(ticks = xticks, ticklabels = xlabel) ax2.yaxis.set(ticks = yticks) ax2.legend(loc = 1)  plt.tight_layout() # fix the spaces between the two Axes plt.show()      Nós acabamos de criar uma Figure com dois Subplot’s dentro dela. As imagens da esquerda e da direita são definidas pelas funções seno e cosseno, respectivametne. Além disso, há algumas coisas novas aqui; por isso, os próximos parágrafos serão dedicados a esses detalhes.   Depois de importar, além do Matplotlib, o Numpy (veja aqui um pequeno tutorial sobre Numpy e Pandas), nós criamos uma Figure com um tamanho específico. Agora, utilizando esse objeto, que foi armazenado na variável fig, foram criados dois Subplot’s $-$ Importante: note que para o primeiro objeto, o valor do parâmetro foi 121(que significa 1 linha, 2 colunas e o índice 1), enquanto que para o segundo, esse número teve que ser definido como 122.   Nas linhas seguintes, a única coisa que fizemos foi criar os nossos vetores de dados x, y e z. Com o Numpy, nós geramos uma lista, atribuída a x, de valores igualmente espaçados entre $0$ e $2\\pi$; então, nas variáveis y e z, nós calculamos e salvamos os valores de seno e cosseno de x, respectivamente.   Depois disso tudo, diferentemente do primeiro exemplo, utilizamos o método plot() (ao invés de scatter()). Essa modificação faz com que o gráfico de pontos seja, agora, exibido como gráfico de linha.   Por fim, sobre as propriedades de ax1 e ax2, descreverei apenas os atributos e métodos que ainda não foram discutidos. A primeira novidade é o método axis(), que define os valores mínimo e máximo que serão mostrados em cada eixo do gráfico $-$ perceba que é necessário passar uma lista de números. Além disso, nós também criamos algumas variáveis que foram utilizadas para definir os parametros ticks e ticklabes dos métodos xaxis.set() e yaxis.set(). Esses métodos definem em quais pontos ao longo dos eixos você terá um indicador de valor.   Um pequeno detalhe é o de que foi necessário, antes de chamar o método show(), utilizar a função tight_layout() a fim de ajustar o tamanho e espaçamento dos gráficos.   Conclusão   Matplotlib é uma biblioteca muito flexível e poderosa que nos permite criar diferentes tipos de gráficos. Além disso, como mencionado anteriormente, existe uma galeria oficial cheia de exemplos reais criados a partir dessa ferramenta $-$ confira, e veja todas as possibilidades.   Qualquer dúvida, sugestão ou feedback, por favor, deixe um comentário abaixo.      Eu havia escrito esse texto, originalmente em inglês, em uma antiga versão do blog que já não existe mais. Pequenas correções e atualizações, além da própria tradução, foram feitas para que o conteúdo continuasse relevante.   ","categories": ["Tutorial"],
        "tags": ["python","ciencia-de-dados"],
        "url": "http://localhost:4000/visualizacao-de-dados-com-matplotlib/",
        "teaser":null},{
        "title": "[Parte 01] O que é Aprendizado (de Máquina) & PLA",
        "excerpt":"Quando se fala de Aprendizado de Máquina, há pelo menos duas interpretações para o que isso significa: a primeira delas diz respeito a um conjunto de técnicas e modelos estatísticos que são usados, primariamente, para se fazer inferência (estimação pontual dos parâmetros de interesse, contrução de intervalo de confiança, teste de hipótese, etc.); enquanto que a segunda abordagem, que será a utilizada daqui para frente, se preocupa em, principalmente, fazer predição sobre novas observações $-$ nesse caso, o(s) modelo(s) utilizado(s) pode(m), inclusive, não ter forma explícita (Izbicki, R.; dos Santos, T. M. Machine Learning sob a ótica estatística). Dito isso, podemos começar.   Componentes do aprendizado   A fim de dar contexto ao que vem a seguir, tome o seguinte exemplo: imagine que um banco contratou uma empresa de consultoria para ajudá-lo a determinar se, para cada cliente que pede um empréstimo, o banco deve ou não conceder esse crédito (aqui, um cliente é bom se, de alguma forma, faz com que o banco ganhe dinheiro; e é ruim, caso contrário). Para construir um modelo que resolve esse tipo de problema, o banco tem um conjunto de dados de clientes antigos, com várias de suas características (salário, estado civil, bens materiais, etc.), além de, se no passado, esses clientes fizeram a instituição ganhar ou perder dinheiro. De posse dessas informações, a empresa de consultoria pode escrever um modelo que ajuda o banco a predizer se clientes futuros darão (ou não) algum tipo de lucro.   Considerando esse exemplo, podemos dar nomes às componentes (do aprendizado) de interesse. Seja $\\mathbf{x}$ o vetor de entrada (informação que o banco tem de um cliente), então $f: \\mathcal{X} \\longrightarrow \\mathcal{Y}$ é a função alvo (que é desconhecida) $-$ onde $\\mathcal{X}$ é o espaço de entrada (para o caso onde existem $d$ características sobre um cliente, $\\mathcal{X}$ é o Espaço Euclidiano $d$-dimensional) e $\\mathcal{Y}$ é o espaço de saída (no exemplo, $\\mathcal{Y} = \\lbrace +1, -1 \\rbrace$; ou seja, o banco concede ou não o empréstimo). Além disso, temos o conjunto de dados com entradas e saídas, definido por $\\mathcal{D} = (\\mathbf{x}_1, y_1), \\cdots, (\\mathbf{x}_N, y_N)$ $-$ onde $y_n = f(\\mathbf{x}_n)$, tal que $n = 1, \\cdots, N$ $-$, e um algoritmo de aprendizagem $\\mathcal{A}$ que usa $\\mathcal{D}$ para determinar uma função $g: \\mathcal{X} \\longrightarrow \\mathcal{Y}$ que aproxima $f$. Nesse caso, o algoritmo “escolhe” uma função $g$ a partir de uma classe de funções que são relevantes para o problema (esse conjunto que contempla $g$ será denotado por $\\mathcal{H}$, e receberá o nome de Hypothesis Set).   Voltando ao exemplo, o banco irá, baseado em $g$, decidir para quais clientes realizará o empréstimo (lembre-se que $f$ é desconhecida). Nesse caso, o algoritmo $\\mathcal{A}$ selecionou $g \\in \\mathcal{H}$ a partir da análise do conjunto de dados $\\mathcal{D}$; na esperança que o comportamento de clientes futuros ainda possa ser modelado por essa função escolhida. A figura a seguir ilustra a relação entre todas essas componentes.    Figura 1 [fonte: “Learning from Data”] $-$ Componentes do aprendizado.   A Fig. 1 será utilizada como framework para tratarmos o “problema do aprendizado”. Mais tarde, esse esquema vai passar por alguns refinamentos, mas a base será a mesma:           Existe uma $f$ para ser aprendida (que é, e continuará sendo desconhecida para nós).            Temos um conjunto de dados $\\mathcal{D}$ gerados por essa função alvo.            O algoritmo de aprendizagem $\\mathcal{A}$ utiliza $\\mathcal{D}$ para encontrar uma função $g \\in \\mathcal{H}$ que aproxima bem $f$.       Um modelo de aprendizado simples   Sobre as componentes do aprendizado que acabamos de discutir, a função alvo $f$ e o conjunto de dados $\\mathcal{D}$ vêm do problema com o qual estamos lidando. Entretanto, o conjunto de possíveis soluções $\\mathcal{H}$ e o algoritmo de aprendizagem $\\mathcal{A}$ são ferramentas nós temos que escolher para determinar $g$; nesse sentido, eles ($\\mathcal{H}$ e $\\mathcal{A}$) são chamados de modelo de aprendizado.   Vejamos, então, um modelo de aprendizado simples: seja $\\mathcal{X} = \\mathbb{R}^d$ e $\\mathcal{Y} = \\lbrace +1, -1 \\rbrace$; onde $+1$ e $-1$, denotam “sim” e “não”, respectivamente. No exemplo do banco, diferentes coordenadas de $\\mathbf{x} \\in \\mathcal{X}$ representam cada uma das características do cliente (salário, estado civil, bens materiais, etc.); enquanto que o espaço de saída $\\mathcal{Y}$ faz referência ao fato de o banco conceder ou não o empréstimo. Em adição, vamos dizer que $\\mathcal{H}$ é composto por todas as funções $h \\in \\mathcal{H}$ que têm forma ditada por:     onde $\\mathbf{w}$ é um vetor de “pesos” e $\\mathbf{x} \\in \\mathcal{X}$, com $\\mathcal{X} = \\lbrace 1 \\rbrace \\times \\mathbb{R}^d$. O que está sendo feito aqui é simples: a família de funções $h(\\cdot)$ $-$ perceba que $h$ não está completamente definida, já $\\textbf{w}$ não é parâmetro da função $-$, atribui pesos $w_i$ para cada uma das $d$ características dos indivíduos. Dessa forma, podemos determinar a regra de que, se $\\sum_{i = 1}^{d} w_i x_i &gt; \\text{threshold}$, então o banco aprova o empréstimo; caso contrário, não. $h(\\mathbf{x})$ traduz essa ideia; além de assumir os valores $+1$ ou $-1$, como gostaríamos que fosse.   O modelo que acabamos de descrever é chamado de perceptron. O algoritmo de aprendizagem $\\mathcal{A}$ vai procurar por valores de $\\mathbf{w}$ ($w_0$ incluído) que se adaptam bem as dados. A escolha ótima será a nossa função $g$.   Observação: se o conjunto de dados for linearmente separável, então existirá um $\\mathbf{w}$ que classifica todas as observações corretamente.   Por fim, vamos ver então qual é esse algoritmo $\\mathcal{A}$. O algoritmo de aprendizagem nesse caso é chamado de perceptron learning algorithm (PLA), e funciona como descrito abaixo.   Para encontrar $\\mathbf{w}$ tal que todos os pontos estão corretamente classificados, vamos considerar um processo de iteração em $t$ $-$ tal que $t = 0, 1, 2, \\cdots$. Nesse caso, o vetor de “pesos” no $t$-ésimo instante será denotado por $\\mathbf{w}(t)$; aqui, $\\mathbf{w}(0)$ é escolhido arbitrariamente. Para cada etapa do processo, o algoritmo seleciona uma das obervações que não está classificada corretamente $-$ vamos chamá-la de $(\\mathbf{x}(t), y(t))$ $-$, e aplica a seguinte regra:     O que a regra que acabamos de definir faz é “mover” a reta $w_0 + w_1 x_1 + w_2 x_2 = 0$ (para o caso com $2$ dimensões) que divide os pontos do conjunto de dados; a fim de classificar corretamente a observação $(\\mathbf{x}(t), y(t))$.   Como dito anteriormente, se os dados são linearmente separáveis, o PLA converge, classificando corretamente todas as observações; o que implica em duas coisas interessantes:           Repare que, para cada etapa do processo de iteração, apesar de corrigir a observação que está sendo considerada, o algoritmo pode “bagunçar” a classificação (em um primeiro momento, correta) dos outros pontos; mas mesmo assim, sob a hipótese de que os dados são linearmente separáveis, o algoritmo converge (a demonstração pode ser vista aqui).            Para esse tipo de classificador que acabamos de detalhar, $\\mathcal{H}$ é uma classe infinita de funções; assim, dizer que, nesse caso, o algorimo converge, é o mesmo que dizer que, mesmo em um conjunto de cardinalidade infinita, foi necessário uma quantidade finita de iterações para encontrarmos uma solução ótima (no sentido de classificar corretamente todos os pontos) para o problema $-$ o que é, no mínimo, interessante.       Conclusão   Na primeira parte dessa série de textos, vimos o framework básico com o qual vamos trabalhar quando queremos modelar o processo de aprendizado (de máquina). Essas ideias serão revisitadas à exaustão e, por isso, são tão importantes. Por fim, vimos também como essas componentes do aprendizado podem nos guiar na construção de um modelo de classificação simples. Tal modelo, o “perceptron”, é de fato limitado; mas é um excelente primeiro passo que podemos dar. A próxima postagem será dedicada à implementação desse classificador em Python, bem como à discussão de um exemplo.   Qualquer dúvida, sugestão ou feedback, por favor, deixe um comentário abaixo.      Essa postagem faz parte de uma série de textos que tem o objetivo de estudar, principalmente, o curso “Learning from Data”, ministrado pelo Professor Yaser Abu-Mostafa. Outros materiais utilizados serão sempre referenciados.   ","categories": ["Machine Learning - Learning from Data"],
        "tags": [],
        "url": "http://localhost:4000/o-que-e-aprendizado/",
        "teaser":null},{
        "title": "[Parte 02] Implementação em Python: Perceptron",
        "excerpt":"Como mencionado na parte 01 dessa série de textos, essa postagem será dedicada à implementação do Perceptron Learning Algorithm (PLA) em Python, utilizando, para isso, a biblioteca Numpy. Discutiremos um exemplo e, ao final, vamos ver como utilizar a implementação desse mesmo algoritmo pela biblioteca Sklearn.   O código a seguir é baseado (feitas algumas modificações) nos capítulos iniciais do que é apresentado no livro Python Machine Learning.   Primeiro vamos à implementação do algoritmo, e depois discutiremos os trechos do que foi escrito. Considere a classe Perceptron a seguir:   import numpy as np  # Raw implementation class Perceptron():     \"\"\"     Perceptron learning algorithm implementation     \"\"\"          def __init__(self, eta = 1, random_seed = 1):         self.eta = eta         self.random_seed = random_seed              def fit(self, X, y):         rn = np.random.RandomState(self.random_seed)         self.w_ = rn.normal(loc = 0, scale = 0.01, size = X.shape[1] + 1)         errors = True                  while errors:             errors = 0             for X_i, y_i in zip(X, y):                 if(y_i != self.predict(X_i)):                     # update weights vector for misclassified points                     update = self.eta * y_i                     self.w_[1:] += update * X_i                     self.w_[0] += update                      errors += 1                              return self          def predict(self, X_i):         eval_func = np.dot(X_i, self.w_[1:]) + self.w_[0] # ATTENTION: this implemented arguments order is more intuitive         return np.where(eval_func &gt;= 0, 1, -1)   Note que, para criar uma instância da classe, são necessários dois parâmetros: o primeiro deles, eta, diz respeito a uma pequena generalização feita na regra de atualização do vetor $\\mathbf{w}$ (discutida no próximo parágrafo), enquanto que o parâmetro random_seed define uma semente para geração aleatória do vetor inicial de pesos.   Como acabei de dizer, podemos generalizar a regra de atualização de $\\mathbf{w}$ apresentada na parte 01 dessa série introduzindo o parâmetro $\\eta$. A regra, então, ficaria assim:     Perceba que para $\\eta = 1$, a regra é exatamente a mesma que vimos antes. Dessa forma, a única coisa que $\\eta$ faz é mexer no quanto a reta definida por $\\mathbf{w}$ “se move” para classificar corretamente o ponto considerado. Nesse sentido, perceba que, para $\\eta$ grande, a chance de eu “bagunçar” a classificação dos demais pontos também é grande; portanto, $\\eta$ maior não é necessariamente melhor (normalmente, $0 &lt; \\eta \\leq 1$).   Continuando, o método __init__() apenas inicializa os atributos eta e random_seed. O método fit() é o que, de fato, ajusta o modelo; ou seja, ajusta os valores do vetor $\\mathbf{w}$. Nesse caso, para os pontos que não estão classificados corretamente (y_i != self.predict(X_i)), o atributo w_ é atualizado de acordo com a regra que acabamos de discutir $-$ esse processo é realizado quantas vezes forem necessárias. Uma tecnicalidade importante é a de que o vetor de pesos não deve ser inicializado com todas as entradas nulas; caso isso aconteça, o termo update * X_i afetará somente a escala de $\\mathbf{w}$. Por fim, o método predict(), baseado na função $h(\\mathbf{x})$ definida no post anterior, faz a classificação de cada ponto (ou conjunto de pontos) X_i.   Para verificar o funcionamento do algoritmo, vamos utilizar o conjunto de dados Iris, que classifica três espécies de flores de acordo com o comprimento e largura de suas pétalas e sépalas. Veja as primeiras linhas do conjunto de dados:   %matplotlib inline import pandas as pd import matplotlib.pyplot as plt  # Iris Data Set df = pd.read_csv(\"https://bit.ly/2Mg0qkZ\", header = None, encoding = \"UTF\")  df.columns = ['sepal-length', 'sepal-width', 'petal-length', 'petal-width', 'category'] df.head()                           sepal-length       sepal-width       petal-length       petal-width       category                       0       5.1       3.5       1.4       0.2       Iris-setosa                 1       4.9       3.0       1.4       0.2       Iris-setosa                 2       4.7       3.2       1.3       0.2       Iris-setosa                 3       4.6       3.1       1.5       0.2       Iris-setosa                 4       5.0       3.6       1.4       0.2       Iris-setosa            Entretanto, para que consigamos visualizar facilmente o resultado do algoritmo, vamos nos concentrar em duas features: “Sepal length” e “Petal length”. Além disso, vamos denotar a espécie “Iris Setosa” (50 primeiras linhas) por $-1$ e a espécie “Iris Versicolor” (linhas 50 a 100) por $+1$. Nesse caso, não utilizaremos as informações da terceira espécie; já que o Perceptron é um classificador binário. Veja como ficaram os dados:   df = df.loc[0:100, ['sepal-length', 'petal-length', 'category']]  X = df.loc[0:100, ['sepal-length', 'petal-length']].values y = df.category.values y = np.where(y == 'Iris-setosa', -1, 1)  plt.scatter(X[0:50, 0], X[0:50, 1], color = \"red\", marker = \"o\", label = \"Iris-ventosa\") plt.scatter(X[50:100, 0], X[50:100, 1], color = \"green\", marker = \"s\", label = \"Iris-versicolor\") plt.xlabel('Sepal length [cm]') plt.ylabel('Petal length [cm]') plt.legend(loc = 2) plt.show()      Agora podemos ajustar o modelo:   my_perceptron = Perceptron() my_perceptron.fit(X, y)  print(\"Weights vector: {}.\".format(my_perceptron.w_))   Weights vector: [-1.98375655 -3.50611756  9.19471828].   Nesse caso, instanciamos um objeto da classe Perceptron e depois ajustamos o modelo baseado no conjunto de dados que acabamos de filtrar. Note, então, que o vetor w_ foi completamente determinado. Assim, o que podemos fazer é visualizar os resultados de forma gráfica. Para isso, utiizaremos a função a seguir, plot_decision_regions():   def plot_decision_regions(X, y, classifier, feature_names, resolution = 0.01):     # general settings     markers = [\"o\", \"s\", \"*\", \"x\", \"v\"]     colors  = (\"red\", \"green\", \"blue\", \"gray\", \"cyan\")     x1_min, x1_max = X[:, 0].min() - 0.5, X[:, 0].max() + 0.5     x2_min, x2_max = X[:, 1].min() - 0.5, X[:, 1].max() + 0.5     # define a grid     xx1, xx2 = np.meshgrid(np.arange(x1_min, x1_max, resolution),                            np.arange(x2_min, x2_max, resolution))     # classify each grid point     result = classifier.predict(np.array([xx1.ravel(), xx2.ravel()]).T)     result = result.reshape(xx1.shape)     # make a plot     plt.contourf(xx1, xx2, result, colors = colors[0:len(np.unique(y))], alpha = 0.5)     for index, value in enumerate(np.unique(y)): # plot each point &amp; 'enumerate()' returns index and value of the given array         plt.scatter(x = X[y == value, 0], y = X[y == value, 1], # select each X and y vectors by creating a mask                     color = colors[index],                     marker = markers[index],                     label = feature_names[index],                     edgecolor = 'black')   Agora podemos plotar o gráfico de interesse:   feature_names = ['Iris ventosa', 'Iris versicolor'] plot_decision_regions(X, y, my_perceptron, feature_names) plt.title('Fitted model with raw implementation') plt.xlabel('Sepal length [cm]') plt.ylabel('Petal length [cm]') plt.legend(loc = 2) plt.show()      Como podemos ver, o algoritmo classificou corretamente todas as flores. Entretanto, um ponto muito importante sobre o qual ainda não disctutimos, é a eficiência (ou acurácia) desse modelo para classificar novas observações. Esse tipo de medida será discutida (e implementada) ao longo dos próximos textos.   Antes de finalizar, vamos ver como ajustar esse mesmo modelo utilizando a implementação do Sklearn:   # Sklearn usage from sklearn.linear_model import Perceptron  sklearn_perceptron = Perceptron() sklearn_perceptron.fit(X, y)  print(\"Weight vector (without w_0): {}.\".format(sklearn_perceptron.coef_))   Weight vector (without w_0): [[-2.4  5. ]].   Como a classe Perceptron já está implementada na biblioteca, ajustar o modelo é super simples; basta, mais uma vez, utilizar o método fit(). O vetor de pesos é ligeiramente diferente, mas também é uma solução para o nosso problema $-$ veja o gráfico abaixo:   feature_names = ['Iris ventosa', 'Iris versicolor'] plot_decision_regions(X, y, sklearn_perceptron, feature_names) plt.title('Fiited model with Sklearn usage') plt.xlabel('Sepal length [cm]') plt.ylabel('Petal length [cm]') plt.legend(loc = 2) plt.show()      Conclusão   Nessa postagem vimos a implementação em Python do Perceptron Learning Algorithm (PLA) que havíamos discutido antes. Entretanto, a maior parte desses resultados em machine learning já estão disponíveis através da biblioteca Sklearn (veja a documentação) $-$ o que não nos impede, como forma de estudo, de escrever as nossas próprias versões dos algoritmos. Por fim, como foi brevemente mencionado, é importante que consigamos avaliar a efeciência dos nossos modelos; esse tópico começará a ser abordado no próximo post.   Qualquer dúvida, sugestão ou feedback, por favor, deixe um comentário abaixo.      Essa postagem faz parte de uma série de textos que tem o objetivo de estudar, principalmente, o curso “Learning from Data”, ministrado pelo Professor Yaser Abu-Mostafa. Outros materiais utilizados serão sempre referenciados.   ","categories": ["Machine Learning - Learning from Data"],
        "tags": [],
        "url": "http://localhost:4000/implementacao-perceptron/",
        "teaser":null},{
        "title": "[Parte 03] Memorizar não é Aprender",
        "excerpt":"O que nós fizemos até agora foi, dado um conjunto $\\mathcal{D}$, treinar um modelo que “explicasse” (no caso do Perceptron, “classificasse”) os dados $(\\mathbf{x}_1, y_1), \\cdots, (\\mathbf{x}_N, y_N)$. Porém, isso significa, de fato, aprender? Isto é, a função $g \\in \\mathcal{H}$ escolhida pelo algoritmo aproxima a função alvo $f$ no sentido de ter bom desempenho em explicar $\\mathbf{x} \\not\\in \\mathcal{D}$?   O que nós vamos fazer agora é introduzir uma componente aleatória no framework de aprendizado que começamos a discutir na parte 01 dessa série de textos $-$ que vai nos permitir responder “sim” às perguntas do parágrafo anterior.   Para , seja , com ; i.e., a probabilidade de que o valor de uma função fixa   avaliada em   com  escolhida antes de  ser gerado  seja diferente da função alvo $f$ avaliada no mesmo ponto. Por consequência, . Além disso, defina ; ou seja,  é a proporção de vezes que  é diferente de  para uma amostra . A ideia é que, desde que a  seja gerada aleatoriamente seguindo uma distribuição  (não necessariamente conhecida), então  aproxima bem . A relação a seguir, conhecida como Desigualdade de Hoeffding, quantifica essa aproximação:     O que a inequação acima diz é que a probabilidade de $\\nu$ estar arbitrariamente próximo de $\\mu$ é algo como “$1$ menos alguma coisa que decai exponencialmente com $N$”. O que é o mesmo que dizer que, para $N$ “grande”, $\\nu$ aproxima bem o comportamento de $\\mu$. Assim, a quantidade de vezes que $h$ erra na amostra $\\mathcal{D}$ é proporcional à quantidade de erros que $h$ cometeria fora de $\\mathcal{D}$. Veja abaixo um esquema atualizado das nossas componentes do aprendizado.    Figura 1 [fonte: “Learning from Data”] $-$ Framework de aprendizado atualizado com componente estocástica.   Dito tudo isso, se houvesse apenas uma função em $\\mathcal{H}$, seria fácil de verificar se $h$ tem bom desempenho em avaliar pontos fora de $\\mathcal{D}$; só que esse não é o caso $-$ na maior parte das vezes, $\\mathcal{H}$ tem cardinalidade infinita, inclusive. Isso nos motiva a introduzir uma nova notação:   Defina  e ; ou seja,  e  são, respectivamente, as quantidades  e  como função de . Então é óbvio que, para todo , , . O ganho em definir essa nova notação aparece no próximo parágrafo. Observação: o subscrito “” faz referência ao termo in-sample; da mesma forma, “” quer dizer out-of-sample.   A cota que temos até agora diz respeito a uma única função $h \\in \\mathcal{H}$ ; porém, se $\\mathcal{H}$ tem cardinalidade maior que $1$ (o que, na prática, é sempre verdade), podemos escrever uma relação parecida para uma função $g \\in \\mathcal{H}$ escolhida por $\\mathcal{A}$. Seja $\\mathcal{H}$ conjunto finito de tamanho $M$, então vale:     Nas equivalências acima, a primeira desigualdade é justificada por inclusão de eventos, a segunda por union bound, e a terceira, como já vimos, vem da Desigualdade de Hoeffding.   A princípio, essa cota que conseguimos para $g$ só faz sentido se $M$ for finito; já que o lado direito da desigualdade cresce com $M$. Entretanto, esse resultado pode ser generalizado para $\\mathcal{H}$ conjunto infinito.   Em resumo, é possível interpretar o resultado de que $\\mathbb{P}\\left[\\lvert E_{in}(g) - E_{out}(g)\\rvert &gt; \\epsilon\\right] \\leq 2 M e^{-2 \\epsilon^2 N}$ da seguinte forma: a depender de $M$ e $\\epsilon$, o nosso modelo consegue, de fato, aprender, pois a função $g \\in \\mathcal{H}$ escolhida por $\\mathcal{A}$ se aproxima de $f$ quando $N$ cresce $-$ no sentido de, se $E_{in}(g) \\approx 0$, ter probabilidade de erro arbitrariamente pequena para avaliar $\\mathbf{x} \\not\\in \\mathcal{D}$.   Conclusão   Vimos que, com a introdução de uma componente estocástica no nosso framework de aprendizado, é possível que nosso modelo aprenda (e não apenas memorize). Nesse caso, quando $N$ cresce, $E_{in}(g) \\approx E_{out}(g)$. Assim, se conseguirmos fazer com que $E_{in}(g) \\approx 0$, então teremos que $E_{out}(g) \\approx 0$; o que é o mesmo que dizer que se o algoritmo $\\mathcal{A}$ conseguir escolher uma função $g \\in \\mathcal{H}$ que tem bom desempenho em avaliar $\\mathbf{x} \\in \\mathcal{D}$, então $g$ também terá bons resultados para observações fora de $\\mathcal{D}$.   Qualquer dúvida, sugestão ou feedback, por favor, deixe um comentário abaixo.      Essa postagem faz parte de uma série de textos que tem o objetivo de estudar, principalmente, o curso “Learning from Data”, ministrado pelo Professor Yaser Abu-Mostafa. Outros materiais utilizados serão sempre referenciados.   ","categories": ["Machine Learning - Learning from Data"],
        "tags": [],
        "url": "http://localhost:4000/memorizar-nao-e-aprender/",
        "teaser":null},{
        "title": "[Parte 04] Modelos Lineares de Classificação & Implementação em Python do Pocket",
        "excerpt":"Na parte 03 dessa série de textos, discutimos se é possível que nossos algoritmos, de fato, aprendam; ou seja, se conseguimos determinar uma função $g \\in \\mathcal{H}$ que aproxima bem $f$ para pontos $\\mathbf{x} \\not\\in \\mathcal{D}$. Esse assunto ainda não foi esgotado, mas por hora vamos nos concentrar em estudar mais alguns algoritmos $-$ em especial, alguns modelos lineares.   Esse post vai ser um pouco diferente, no sentido de mesclar a apresentação teórica com a implementação prática (em Python) de um dos algoritmos de interesse: o Pocket Learning Algorithm (ou só Pocket) $-$ uma variação do Perceptron.   Fazendo referência ao PLA (Perceptron Learning Algorithm), que estudamos nas partes 01 e 02, uma de suas limitações era a de que os dados precisavam ser linearmente separáveis; caso contrário, o algoritmo não era capaz de classificar corretamente todos os pontos $\\mathbf{x} \\in \\mathcal{D}$, e, por consequência, não convergia. Perceba que essa é uma suposição bem forte, já que, na prática, os dados quase nunca tem essa característica. Uma solução para contornar esse problema seria a de limitar o número de iterações que o algoritmo poderia realizar antes de ser interrompido. Porém, dessa solução, surge um problema.   Lembre-se de que o Perceptron, na tentativa de ajustar o hiperplano definido por  que classifica corretamente um ponto , poderia “bagunçar” a classificação associada aos demais pontos. Em outras palavras, mais iterações não se traduzem em uma reta (para o caso de  dimensões) “melhor” (no sentido de ter  menor). Dito isso, uma ideia para tratar esse problema seria a de, a cada etapa do processo, verificar o erro in-sample e, nas situações nas quais ele for o menor, tomar o vetor  associado como o “escolhido”. Isso é exatamente o que o Pocket Learning Algorithm faz, veja o código a seguir:   # Raw implementation class Pocket:     \"\"\"     Pocket learning algorithm implementation     \"\"\"          def __init__(self, eta = 1, random_seed = 1, n_iterations = 100):         self.eta = eta         self.random_seed = random_seed         self.n_iterations = n_iterations           def fit(self, X, y):         rn = np.random.RandomState(self.random_seed)         self.w_ = rn.normal(loc = 0, scale = 0.01, size = X.shape[1] + 1)         counter = 0         errors = True                  partial_w = self.w_.copy()         partial_error_in_sample = 0         self.error_in_sample_ = 0                   while errors and (counter &lt; self.n_iterations):             errors = 0             error_freq = 0             for X_i, y_i in zip(X, y):                 if y_i != self.predict(X_i):                     # update weights for misclassified points                     update = self.eta * y_i                     self.w_[1:] += update * X_i                     self.w_[0] += update                     errors += 1                 for X_i, y_i in zip(X, y):                 if y_i != self.predict(X_i):                     # count misclassified points AFTER analyze all of them                      error_freq += 1                 partial_error_in_sample = (1 / X.shape[0]) * error_freq             if (counter == 0) or (partial_error_in_sample &lt; self.error_in_sample_):                 # update smallest error and best weights vector                 self.error_in_sample_ = partial_error_in_sample                   partial_w = self.w_.copy()             counter += 1                      self.w_ = partial_w.copy()         return self          def predict(self, X_i):         eval_func = np.dot(X_i, self.w_[1:]) + self.w_[0]         return np.where(eval_func &gt;= 0, 1, -1)   A classe Pocket é muito similar à classe Perceptron que havíamos criado anteriormente; o que faz sentido, já que o Pocket é uma modificação do Perceptron. A principal diferença está no método fit(). Perceba que agora o número de iterações não é definido apenas pela quantidade de vezes que o vetor $\\mathbf{w}$ tem que ser atualizado para que todos os pontos sejam corretamente classificados $-$ na verdade isso pode nem acontecer, já que, como dito, a suposição de que os dados são linearmente separáveis não é mais necessária. O atributo n_iterations cuida desse limite máximo.   Note também que, ao final de cada ciclo em que o algoritmo percorre todos os pontos $\\mathbf{x} \\in \\mathcal{D}$, o erro $E_{in}(h)$ (erro in-sample) é calculado e armazenado na variável partial_error_in_sample. Depois disso, no caso de ele ser o menor erro encontrado até o momento, essa quantidade é salva no atributo error_in_sample $-$ bem como o vetor $\\mathbf{w}$, que é armazenado em partial_w. Ao final, o vetor de pesos escolhido é aquele que teve o menor erro associado; ou seja, o vetor salvo em partial_w, que é então tranferido para o atributo w_.   Vamos ver agora como isso funciona em um conjunto de dados que não é linearmente separável. Considere o seguinte cenário: suponha que você quer classificar corretamente digitos númericos escritos a mão, como os mostrados na figura abaixo. Cada uma das imagens é composta por uma grade de $16 \\times 16$ pixels que assume valores entre $0$ e $255$; ou seja, teríamos um espaço Euclidiano $256$-dimensional de funções (possivelmente) real-avaliadas.    Figura 1 [fonte: “Learning from Data”] $-$ Dígitos numéricos escritos a mão.   A fim de diminuir essa quantidade de features (ou características, ou variáveis independentes, etc.), podemos considerar, apenas, alguma medida de intensidade e alguma medida de simetria dos pixels. Obviamente não estamos utilizando todas as informações, mas isso já deve ser o suficiente para termos bons resultados. No código a seguir, ajustaremos um modelo para classificar os dígitos $1$ e $5$ (lembre-se que o Pocket ainda é um classificador binário); veja:   %matplotlib inline import numpy as np import pandas as pd import matplotlib.pyplot as plt  df = pd.read_csv(\"http://www.amlbook.com/data/zip/features.train\", header = None, delimiter = r\"\\s+\") df.columns = ['number', 'intensity', 'symmetry'] df['number'] = df['number'].astype(int)  df.head(3)                           number       intensity       symmetry                       0       6       0.341092       -4.528937                 1       5       0.444131       -5.496812                 2       4       0.231002       -2.886750            mask = ((df.number == 1) | (df.number == 5)) # select only numbers '1' and '5' df = df[mask] df = df.reset_index(drop = True) df.head(3)                           number       intensity       symmetry                       0       5       0.444131       -5.496812                 1       1       0.123043       -0.707875                 2       1       0.113859       -0.931375            df.info()   &lt;class 'pandas.core.frame.DataFrame'&gt; RangeIndex: 1561 entries, 0 to 1560 Data columns (total 3 columns): number       1561 non-null int64 intensity    1561 non-null float64 symmetry     1561 non-null float64 dtypes: float64(2), int64(1) memory usage: 36.7 KB   Perceba que, depois de filtrar adequadamente o conjunto de dados, temos uma base com 1561 entradas que apresentam características (de intensidade e simetria dos pixels) dos números $1$ e $5$. Vamos, agora, plotar esses dados.   X = df.loc[:, ['intensity', 'symmetry']].values y = df.loc[:, 'number'].values y = np.where(y == 1, -1, 1) # maps 1 to -1, and 5 to 1  plt.scatter(X[y == -1, 0], X[y == -1, 1], color = \"red\", marker = \"o\", label = \"Number 1\") plt.scatter(X[y ==  1, 0], X[y ==  1, 1], color = \"green\", marker = \"s\", label = \"Number 5\") plt.xlabel(\"Intensity measure\") plt.ylabel(\"Symmetry measure\") plt.legend(loc = 1) plt.show()      A primeira coisa a se notar é que os dados não são linearmente separáveis. Dito isso, vamos, finalmente, ajustar o modelo:   my_pocket = Pocket(n_iterations = 100) my_pocket.fit(X, y)  print(\"Weights vector: {}.\".format(my_pocket.w_)) print(\"Smallest error in-sample: {}.\".format(my_pocket.error_in_sample_))   Weights vector: [-9.98375655 -1.494057   -4.21659422]. Smallest error in-sample: 0.0038436899423446506.   Nesse caso, estamos considerando o vetor $\\mathbf{w}$ associado ao menor erro $E_{in}(h)$ encontrado: 0.0038436899. Podemos, então, plotar o gráfico com as regiões de decisão; utilizando, para isso, a função plot_decision_regions já discutida na parte 02.   def plot_decision_regions(X, y, classifier, feature_names, resolution = 0.01, plot_lim = 0.25):     # general settings     markers = [\"o\", \"s\", \"*\", \"x\", \"v\"]     colors  = (\"red\", \"green\", \"blue\", \"gray\", \"cyan\")     x1_min, x1_max = X[:, 0].min() - plot_lim, X[:, 0].max() + plot_lim     x2_min, x2_max = X[:, 1].min() - plot_lim, X[:, 1].max() + plot_lim     # define a grid     xx1, xx2 = np.meshgrid(np.arange(x1_min, x1_max, resolution),                            np.arange(x2_min, x2_max, resolution))     # classify each grid point     result = classifier.predict(np.array([xx1.ravel(), xx2.ravel()]).T)     result = result.reshape(xx1.shape)     # make a plot     plt.contourf(xx1, xx2, result, colors = colors[0:len(np.unique(y))], alpha = 0.5)     for index, value in enumerate(np.unique(y)):          plt.scatter(x = X[y == value, 0], y = X[y == value, 1],                      color = colors[index],                     marker = markers[index],                     label = feature_names[index],                     edgecolor = 'black')   feature_names = ['Number 1', 'Number 5'] plot_decision_regions(X, y, my_pocket, feature_names, plot_lim = 0.15) plt.title(\"Fitted model with Pocket Learning Algorithm\") plt.xlabel(\"Intensity measure\") plt.ylabel(\"Symmetry measure\") plt.legend(loc = 1) plt.show()      Como podemos observar, o Pocket encontrou uma reta que minimiza (considerando as cem primeiras iterações) o erro amostral $-$ o que, como discutido na parte 03, é um dos passos necessários para dizermos que o nosso algoritmo aprendeu.   Conclusão   Vimos ao longo do texto um generalização para o Perceptron, chamada Pocket. Esses dois algoritmos fazem parte de uma classe maior de modelos lineares, e são, portanto, classificadores lineares. No próximo post vamos estudar o modelo de regressão $-$ nesse caso, a função alvo $f: \\mathcal{X} \\rightarrow \\mathcal{Y}$ terá contradominio nos números reais.   Qualquer dúvida, sugestão ou feedback, por favor, deixe um comentário abaixo.      Essa postagem faz parte de uma série de textos que tem o objetivo de estudar, principalmente, o curso “Learning from Data”, ministrado pelo Professor Yaser Abu-Mostafa. Outros materiais utilizados serão sempre referenciados.   ","categories": ["Machine Learning - Learning from Data"],
        "tags": [],
        "url": "http://localhost:4000/modelos-lineares-de-classificacao-e-pocket/",
        "teaser":null},{
        "title": "[Parte 05] Modelo de Regressão Linear & Implementação em Python",
        "excerpt":"Continuando a discussão sobre modelos lineares, assunto que começamos a estudar na parte 04 dessa série de textos, vamos, nesse post, falar do modelo de regressão. A principal diferença entre esse tipo de modelo e os classificadores que estudamos anteriormente é que agora a função alvo $f$ é real-avaliada $-$ que é o mesmo que dizer que $\\mathcal{Y} \\subset \\mathbb{R}$.   Para dar contexto ao problema, considere o seguinte exemplo: você é professor de uma turma de Ensino Médio e, ao longo do ano, aplica três provas de 20 pontos cada. Depois de os alunos realizarem os dois primeiros testes, você deseja construir um modelo que lhe permita predizer a nota dos alunos na terceira prova. Perceba que, nesse caso, não estamos tentando “classificar” a terceira nota $-$ aqui, $y \\in [0, 20]$. Para resolver esse tipo de tarefa, faremos uso de um modelo (linear) de regressão. Observação 1: inúmeras outras características dos alunos poderiam ser utilizadas como preditores (exemplo: horas de estudo, número de faltas ao longo do ano, etc.), mas para simplicidade do modelo, vamos nos atentar, somente, às notas nas duas primeiras avaliações.   Nesse caso, a classe de funções $h \\in \\mathcal{H}$ será defina por:     Perceba que $h$, como acabamos de definir, é muito parececido com a classe funções que utilizamos quando dicutimos o Perceptron; porém, ao invés do sinal $-$ $\\text{sign}(\\cdot)$ $-$, estamos interessado no valor de $\\mathbf{w}^{\\text{T}}\\mathbf{x}$.   Continuando, da mesma forma que fizemos quando estudamos o modelo Pocket, o que queremos nesse caso é minimizar o erro amostral $-$ $E_{in}(h)$ $-$, associado ao modelo. Nesse sentido, utilizaremos uma medida de erro clássica para análise de regressão: o erro quadrático. Defina $E_{out}(h) = \\mathbb{E}\\left[(h(\\mathbf{x}) - y)^2\\right]$ $-$ nesse caso, o valor esperado é calculado com respeito à distruição $P(\\mathbf{x}, y)$. Porém, como não temos acesso à medida de erro $E_{out}(h)$, como discutimos na parte 03, uma alternativa é minimar o erro in-sample.   Assim, podemos escrever que . Nesse sentido, nossa missão é encontrar  tal que  é mínimo. Veja:     Derivando $E_{in}(\\mathbf{w})$; ou seja, calculando o vetor gradiente $\\nabla E_{in}(\\mathbf{w})$, obtemos:     Igualando $\\nabla E_{in}(\\mathbf{w})$ ao vetor $\\mathbf{0}$, temos que:     Assim, se $X^{\\text{T}}X$ for invertível, então $\\mathbf{w} = (X^{\\text{T}} X)^{-1} X^{\\text{T}} \\mathbf{y}$; onde $X^{\\dagger} = (X^{\\text{T}} X)^{-1} X^{\\text{T}}$ é conhecida como pseudo-inversa de $X$. Aqui, $(X^{\\text{T}} X)^{-1}$ existirá sempre que nenhuma coluna de $X$ for combinação linear das outras; na prática, se $N$ for muito maior que $d + 1$, então isso quase sempre será satisfeito.   Aqui, dois pontos são importantes. Obervação 2: note que obtemos uma solução analítica para minimizar $E_{in}(\\mathbf{w})$ $-$ para o caso do Pocket, por exemplo, esse não era o caso. Observação 3: perceba que $E_{in}(\\mathbf{w})$ é função de $\\mathbf{w}$, e não de $X$ (que, nessa situação, é constante).   Agora que temos um solução para o problema de minimazação do erro, podemos implementar o algoritmo. A classe LinearRegression cuida disso.   # Raw implementation class LinearRegression:     \"\"\"     Linear Regression Algorithm     \"\"\"     def __ini__(self):         pass          def fit(self, X, y):         Z = np.array([1 for x in np.arange(X.shape[0])])         X = np.c_[Z, X] # create an array by including each component as a column         X_dagger = np.linalg.pinv(X) # find the pseudo-inverse matrix         self.w_  = np.dot(X_dagger, y)          return self          def predict(self, X):         return np.dot(X, self.w_[1:]) + self.w_[0]   Perceba que no método fit() calculamos a pseudo-inversa de $X$ através da função pinv() (implementada pelo o módulo de álgebra linear do Numpy). Depois disso, bastou calcularmos o vetor de pesos w_ definido por $\\mathbf{w} =  X^{\\dagger} \\mathbf{y}$. O método predict() apenas implementa a função $h(\\mathbf{x})$.   Agora, para ajustarmos o modelo, considere o exemplo das notas de três provas feitas por alunos do Ensino Médio discutido no começo do texto. Veja os dados:   %matplotlib inline import numpy as np import pandas as pd import matplotlib.pyplot as plt  df = pd.read_csv(\"student-mat.csv\", sep = \";\") df = df.loc[:, ['G1', 'G2', 'G3']] df.head(3)                           G1       G2       G3                       0       5       6       6                 1       5       5       6                 2       7       8       10            df.info()   &lt;class 'pandas.core.frame.DataFrame'&gt; RangeIndex: 395 entries, 0 to 394 Data columns (total 3 columns): G1    395 non-null int64 G2    395 non-null int64 G3    395 non-null int64 dtypes: int64(3) memory usage: 9.4 KB   Perceba que temos $395$ entradas não nulas para cada uma das três provas. Nesse caso, G1 e G2 serão nossos preditores, e G3 será fará o papel da variável dependente. Vamos, então, visualizar como os dados se comportam:   X = df.loc[:, ['G1', 'G2']].values y = df.loc[:, 'G3'].values  from mpl_toolkits.mplot3d import Axes3D  fig = plt.figure(figsize = (6, 6)) ax  = fig.add_subplot(111, projection = '3d') ax.scatter(X[:, 0], X[:, 1], y, color = \"red\", marker = \"o\")  ax.set_xlim3d(0, 20) ax.set_ylim3d(0, 20) ax.set_zlim3d(0, 20)  ticks = np.arange(0, 24, 4) ax.xaxis.set(ticks = ticks) ax.yaxis.set(ticks = ticks) ax.zaxis.set(ticks = ticks)  ax.set_xlabel(\"G1\") ax.set_ylabel(\"G2\") ax.set_zlabel(\"G3\")  ax.view_init(30, 150)  plt.tight_layout() plt.show()      Note que, ao menos a primeira vista, os dados da amostra aparentam ter comportamento linear; o que nos permite prosseguir com o ajuste do modelo:   my_regression = LinearRegression() my_regression.fit(X, y) print(\"Weights vector: {}.\".format(my_regression.w_))   Weights vector: [-1.83001214  0.15326859  0.98686684].   Veja que o vetor de pesos, nesse caso com $3$ coordenadas ($w_0$, $w_1$ e $w_2$, respectivamente) foi facilmente determinado. Para conseguirmos visualizar o plano definido por esse vetor, podemos plotar o seguinte gráfico:   g1 = np.arange(0, 20, 0.1) g2 = np.arange(0, 20, 0.1) g1, g2 = np.meshgrid(g1, g2) g3 = my_regression.predict(np.c_[np.ravel(g1), np.ravel(g2)]) g3 = g3.reshape(g1.shape)  fig = plt.figure(figsize = (6, 6)) ax  = fig.add_subplot(111, projection = '3d') ax.plot_surface(g1, g2, g3, color = \"red\", alpha = 0.5) ax.scatter(X[:, 0], X[:, 1], y, color = \"red\", marker = \"o\", edgecolor = \"black\")  ax.set_xlim3d(0, 20) ax.set_ylim3d(0, 20) ax.set_zlim3d(0, 20)  ticks = np.arange(0, 24, 4) ax.xaxis.set(ticks = ticks) ax.yaxis.set(ticks = ticks) ax.zaxis.set(ticks = ticks)  ax.set_title(\"Fitted model with raw implementation\", pad = 15) ax.set_xlabel(\"G1\") ax.set_ylabel(\"G2\") ax.set_zlabel(\"G3\")  ax.view_init(30, 150) # ax.invert_xaxis()  plt.tight_layout() plt.show()      Nesse caso, o plano parece representar bem o conjunto de pontos. Entretanto, ainda não temos uma análise quantitativa desse tipo de medida $-$ como dito em posts anteriores, ainda vamos chegar lá: na discussão da acurácia dos modelos que escrevemos.   Um pequeno teste que podemos fazer é o de predizer, de acordo com o modelo ajustado, qual nota dois alunos arbitrários tirariam na prova G3 (com base em suas notas G1 e G2).   print(\"O aluno A teve notas G1 = 6.5 e G2 = 17. Assim, espera-se que ele tire {:.2f} pontos na última prova.\".format(my_regression.predict(np.array([6.5, 17])))) print(\"\\n\") print(\"O aluno B teve notas G1 = 17 e G2 = 6.5. Assim, espera-se que ele tire {:.2f} pontos na última prova.\".format(my_regression.predict(np.array([17, 6.5]))))   O aluno A teve notas G1 = 6.5 e G2 = 17. Assim, espera-se que ele tire 15.94 pontos na última prova.   O aluno B teve notas G1 = 17 e G2 = 6.5. Assim, espera-se que ele tire 7.19 pontos na última prova.   Uma observação interessante nesse caso é a de que a nota G3 é mais afetada pela nota G2 do que por G1 $-$ o que faz total sentido, já que, como vimos, $w_2 &gt; w_1$.   Por fim, vamos utilizar a implementação do Sklearn para o modelo de regressão linear. Confira o código a seguir:   # Sklearn usage from sklearn.linear_model import LinearRegression  sklearn_regression = LinearRegression() sklearn_regression.fit(X, y)  print(\"Weights vector - intercept: {} &amp; coefficients: {}.\".format(sklearn_regression.intercept_, sklearn_regression.coef_))   Weights vector - intercept: -1.8300121405807381 &amp; coefficients: [0.15326859 0.98686684].   Nesse caso, como obtivemos uma solução analítica para $\\mathbf{w}$, os resultados são exatamente iguais aos que encontramos.   Conclusão   Nesse texto discutimos o importante modelo de regressão linear, que nos permite então, trabalhar com uma função alvo $f: \\mathcal{X} \\rightarrow \\mathcal{Y}$, com $\\mathcal{Y} \\subset \\mathbb{R}$. Como vimos, nesse caso há uma solução analítica para $\\mathbf{w}$, o que nem sempre é o caso. Além disso, fizemos a implementação do algoritmo em Python $-$ em contraponto à utilização direta do Sklearn (que também foi feita no final do texto). Na próxima postagem, discutiremos como trabalhar com transformações não lineares.   Qualquer dúvida, sugestão ou feedback, por favor, deixe um comentário abaixo.      Essa postagem faz parte de uma série de textos que tem o objetivo de estudar, principalmente, o curso “Learning from Data”, ministrado pelo Professor Yaser Abu-Mostafa. Outros materiais utilizados serão sempre referenciados.   ","categories": ["Machine Learning - Learning from Data"],
        "tags": [],
        "url": "http://localhost:4000/modelo-de-regressao-linear/",
        "teaser":null}]
