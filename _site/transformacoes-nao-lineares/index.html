<!doctype html>
<!--
  Minimal Mistakes Jekyll Theme 4.17.2 by Michael Rose
  Copyright 2013-2019 Michael Rose - mademistakes.com | @mmistakes
  Free for personal and commercial use under the MIT license
  https://github.com/mmistakes/minimal-mistakes/blob/master/LICENSE
-->
<html lang="pt" class="no-js">
  <head>
    <meta charset="utf-8">

<!-- begin _includes/seo.html --><title>[Parte 06] Transformações NÃO-lineares &amp; Implementação em Python - Blog do André</title>
<meta name="description" content="Como vimos até agora nessa série de textos, modelos lineares (tanto de classificação quanto de regressão) utilizam a quantidade $\sum_{i = 0}^{d} w_i x_i$ para calcular a função $h \in \mathcal{H}$. Note que essa expressão é linear para os $x_i$’s e $w_i$’s; porém, como discutimos na parte 05, os $x_i$’s podem, do ponto de vista do algoritmo, ser encaradados como constantes (pense que o conjunto de dados $\mathcal{D}$, no momento que vamos ajustar o modelo, já está definido). Dessa forma, basta que a expressão que estamos considerando seja linear para o vetor de pesos $-$ o que, em outras palavras, significa dizer que podemos aplicar tranformações não-lineares em $\mathbf{x} \in \mathcal{D}$.">


  <meta name="author" content="André V. R. Amaral">


<meta property="og:type" content="article">
<meta property="og:locale" content="pt_BR">
<meta property="og:site_name" content="Blog do André">
<meta property="og:title" content="[Parte 06] Transformações NÃO-lineares &amp; Implementação em Python">
<meta property="og:url" content="http://localhost:4000/transformacoes-nao-lineares/">


  <meta property="og:description" content="Como vimos até agora nessa série de textos, modelos lineares (tanto de classificação quanto de regressão) utilizam a quantidade $\sum_{i = 0}^{d} w_i x_i$ para calcular a função $h \in \mathcal{H}$. Note que essa expressão é linear para os $x_i$’s e $w_i$’s; porém, como discutimos na parte 05, os $x_i$’s podem, do ponto de vista do algoritmo, ser encaradados como constantes (pense que o conjunto de dados $\mathcal{D}$, no momento que vamos ajustar o modelo, já está definido). Dessa forma, basta que a expressão que estamos considerando seja linear para o vetor de pesos $-$ o que, em outras palavras, significa dizer que podemos aplicar tranformações não-lineares em $\mathbf{x} \in \mathcal{D}$.">







  <meta property="article:published_time" content="2020-01-16T00:00:00-03:00">





  

  


<link rel="canonical" href="http://localhost:4000/transformacoes-nao-lineares/">




<script type="application/ld+json">
  {
    "@context": "https://schema.org",
    
      "@type": "Person",
      "name": "André",
      "url": "http://localhost:4000/"
    
  }
</script>






<!-- end _includes/seo.html -->


<link href="/feed.xml" type="application/atom+xml" rel="alternate" title="Blog do André Feed">

<!-- https://t.co/dKP3o1e -->
<meta name="viewport" content="width=device-width, initial-scale=1.0">

<script>
  document.documentElement.className = document.documentElement.className.replace(/\bno-js\b/g, '') + ' js ';
</script>

<!-- For all browsers -->
<link rel="stylesheet" href="/assets/css/main.css">

<!--[if IE]>
  <style>
    /* old IE unsupported flexbox fixes */
    .greedy-nav .site-title {
      padding-right: 3em;
    }
    .greedy-nav button {
      position: absolute;
      top: 0;
      right: 0;
      height: 100%;
    }
  </style>
<![endif]-->



    <!-- start custom head snippets -->

<!-- insert favicons. use https://realfavicongenerator.net/ -->

<link rel="shortcut icon" href="../../assets/images/favicon.ico" type="image/x-icon">

<!-- end custom head snippets -->


    <script type="text/x-mathjax-config">
      MathJax.Hub.Config({
        tex2jax: {
          inlineMath: [ ['$','$'], ["\\(","\\)"] ],
          processEscapes: true
        }
      });
    </script>
    
  </head>

  <body class="layout--single wide">
    <nav class="skip-links">
  <h2 class="screen-reader-text">Skip links</h2>
  <ul>
    <li><a href="#site-nav" class="screen-reader-shortcut">Skip to primary navigation</a></li>
    <li><a href="#main" class="screen-reader-shortcut">Skip to content</a></li>
    <li><a href="#footer" class="screen-reader-shortcut">Skip to footer</a></li>
  </ul>
</nav>

    <!--[if lt IE 9]>
<div class="notice--danger align-center" style="margin: 0;">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience.</div>
<![endif]-->

    

<div class="masthead">
  <div class="masthead__inner-wrap">
    <div class="masthead__menu">
      <nav id="site-nav" class="greedy-nav">
        
        <a class="site-title" href="/">
          Blog do André
          <span class="site-subtitle">Probabilidade, estatística e mais.</span>
        </a>
        <ul class="visible-links"><li class="masthead__menu-item">
              <a href="/categorias/" >Categorias</a>
            </li><li class="masthead__menu-item">
              <a href="/busca/" >Busca</a>
            </li></ul>
        
        <button class="greedy-nav__toggle hidden" type="button">
          <span class="visually-hidden">Toggle menu</span>
          <div class="navicon"></div>
        </button>
        <ul class="hidden-links hidden"></ul>
      </nav>
    </div>
  </div>
</div>


    <div class="initial-content">
      



<div id="main" role="main">
  
  <div class="sidebar sticky">
  


<div itemscope itemtype="https://schema.org/Person">

  
    <div class="author__avatar">
      

      
        <img src="/assets/images/profile_picture.jpeg" alt="André V. R. Amaral" itemprop="image">
      
    </div>
  

  <div class="author__content">
    
      <h3 class="author__name" itemprop="name">André V. R. Amaral</h3>
    
    
      <div class="author__bio" itemprop="description">
        <p>Mestrando em Estatística pela <a href="http://www.est.ufmg.br/portal/">Universidade Federal de Minas Gerais</a>.</p>

      </div>
    
  </div>

  <div class="author__urls-wrapper">
    <button class="btn btn--inverse">Informações</button>
    <ul class="author__urls social-icons">
      

      
        
          
            <li><a href="/sobre/" rel="nofollow noopener noreferrer"><i class="far fa-fw fa-question-circle" aria-hidden="true"></i> Sobre</a></li>
          
        
          
            <li><a href="mailto:avramaral@gmail.com" rel="nofollow noopener noreferrer"><i class="fas fa-fw fa-envelope-square" aria-hidden="true"></i> E-mail</a></li>
          
        
          
            <li><a href="https://github.com/avramaral" rel="nofollow noopener noreferrer"><i class="fab fa-fw fa-github" aria-hidden="true"></i> GitHub</a></li>
          
        
          
            <li><a href="https://twitter.com/avramaral" rel="nofollow noopener noreferrer"><i class="fab fa-fw fa-twitter" aria-hidden="true"></i> Twitter</a></li>
          
        
          
            <li><a href="https://www.linkedin.com/in/andre-victor-ribeiro-amaral/" rel="nofollow noopener noreferrer"><i class="fab fa-fw fa-linkedin-in" aria-hidden="true"></i> LinkedIn</a></li>
          
        
          
            <li><a href="https://www.youtube.com/channel/UC5RVscKF68DWYixtJPrBccQ" rel="nofollow noopener noreferrer"><i class="fab fa-fw fa-youtube" aria-hidden="true"></i> YouTube</a></li>
          
        
      

      

      

      

      

      

      

      

      

      

      

      

      

      

      

      

      

      

      

      

      

      

      

      

      

      <!--
  <li>
    <a href="http://link-to-whatever-social-network.com/user/" itemprop="sameAs" rel="nofollow noopener noreferrer">
      <i class="fas fa-fw" aria-hidden="true"></i> Custom Social Profile Link
    </a>
  </li>
-->
    </ul>
  </div>
</div>

  
  </div>


  <article class="page" itemscope itemtype="https://schema.org/CreativeWork">
    <meta itemprop="headline" content="[Parte 06] Transformações NÃO-lineares &amp; Implementação em Python">
    <meta itemprop="description" content="Como vimos até agora nessa série de textos, modelos lineares (tanto de classificação quanto de regressão) utilizam a quantidade $\sum_{i = 0}^{d} w_i x_i$ para calcular a função $h \in \mathcal{H}$. Note que essa expressão é linear para os $x_i$’s e $w_i$’s; porém, como discutimos na parte 05, os $x_i$’s podem, do ponto de vista do algoritmo, ser encaradados como constantes (pense que o conjunto de dados $\mathcal{D}$, no momento que vamos ajustar o modelo, já está definido). Dessa forma, basta que a expressão que estamos considerando seja linear para o vetor de pesos $-$ o que, em outras palavras, significa dizer que podemos aplicar tranformações não-lineares em $\mathbf{x} \in \mathcal{D}$.">
    <meta itemprop="datePublished" content="January 16, 2020">
    

    <div class="page__inner-wrap">
      
        <header>
          <h1 id="page-title" class="page__title" itemprop="headline">[Parte 06] Transformações NÃO-lineares &amp; Implementação em Python
</h1>
          
            <p class="page__meta"><i class="far fa-clock" aria-hidden="true"></i> 




  15 minuto(s) de leitura

</p>
          
        </header>
      

      <section class="page__content" itemprop="text">
        
        <p>Como vimos até agora <a href="/categorias/#machine-learning-learning-from-data">nessa série de textos</a>, modelos lineares (tanto de classificação quanto de regressão) utilizam a quantidade $\sum_{i = 0}^{d} w_i x_i$ para calcular a função $h \in \mathcal{H}$. Note que essa expressão é linear para os $x_i$’s e $w_i$’s; porém, como discutimos na <a href="/modelo-de-regressao-linear/">parte 05</a>, os $x_i$’s podem, do ponto de vista do algoritmo, ser encaradados como constantes (pense que o conjunto de dados $\mathcal{D}$, no momento que vamos ajustar o modelo, já está definido). Dessa forma, basta que a expressão que estamos considerando seja linear para o vetor de pesos $-$ o que, em outras palavras, significa dizer que podemos aplicar tranformações não-lineares em $\mathbf{x} \in \mathcal{D}$.</p>

<p>Nessa postagem vamos discutir (e implementar) dois exemplos: um de classificação $-$ utilizando o algoritmo Perceptron $-$, e outro de regressão; ambos com transformações não lineares aplicadas no conjunto de dados.</p>

<h3 id="classificação">Classificação</h3>

<p>Para o primeiro caso, vamos gerar um conjunto de dados que será classificado de acordo com a posição de um ponto dentro (ou fora) de um circunferência com centro na origem.</p>

<p>Veja como o conjunto de dados foi gerado, bem como uma representação gráfica dos pontos.</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="o">%</span><span class="n">matplotlib</span> <span class="n">inline</span>
<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="n">np</span>
<span class="kn">import</span> <span class="nn">pandas</span> <span class="k">as</span> <span class="n">pd</span>
<span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="k">as</span> <span class="n">plt</span>

<span class="n">rn</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">RandomState</span><span class="p">(</span><span class="mi">999</span><span class="p">)</span>
<span class="n">x1</span> <span class="o">=</span> <span class="n">rn</span><span class="o">.</span><span class="n">normal</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mf">1.00</span><span class="p">,</span> <span class="mi">100</span><span class="p">)</span>
<span class="n">x2</span> <span class="o">=</span> <span class="n">rn</span><span class="o">.</span><span class="n">normal</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mf">1.00</span><span class="p">,</span> <span class="mi">100</span><span class="p">)</span>

<span class="n">mask_in</span>  <span class="o">=</span> <span class="p">((</span><span class="n">x1</span> <span class="o">**</span> <span class="mi">2</span><span class="p">)</span> <span class="o">+</span> <span class="p">(</span><span class="n">x2</span> <span class="o">**</span> <span class="mi">2</span><span class="p">)</span> <span class="o">-</span> <span class="mf">1.00</span> <span class="o">&lt;</span> <span class="mi">0</span><span class="p">)</span>
<span class="n">mask_out</span> <span class="o">=</span> <span class="p">((</span><span class="n">x1</span> <span class="o">**</span> <span class="mi">2</span><span class="p">)</span> <span class="o">+</span> <span class="p">(</span><span class="n">x2</span> <span class="o">**</span> <span class="mi">2</span><span class="p">)</span> <span class="o">-</span> <span class="mf">1.44</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="p">)</span> <span class="o">&amp;</span> <span class="p">((</span><span class="n">x1</span> <span class="o">**</span> <span class="mi">2</span><span class="p">)</span> <span class="o">+</span> <span class="p">(</span><span class="n">x2</span> <span class="o">**</span> <span class="mi">2</span><span class="p">)</span> <span class="o">-</span> <span class="mf">4.00</span> <span class="o">&lt;</span> <span class="mi">0</span><span class="p">)</span> 

<span class="n">x1_in</span>  <span class="o">=</span> <span class="n">x1</span><span class="p">[</span><span class="n">mask_in</span><span class="p">]</span>
<span class="n">x2_in</span>  <span class="o">=</span> <span class="n">x2</span><span class="p">[</span><span class="n">mask_in</span><span class="p">]</span>
<span class="n">x1_out</span> <span class="o">=</span> <span class="n">x1</span><span class="p">[</span><span class="n">mask_out</span><span class="p">]</span>
<span class="n">x2_out</span> <span class="o">=</span> <span class="n">x2</span><span class="p">[</span><span class="n">mask_out</span><span class="p">]</span>

<span class="n">X</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">c_</span><span class="p">[</span><span class="n">x1_in</span><span class="o">.</span><span class="n">tolist</span><span class="p">()</span> <span class="o">+</span> <span class="n">x1_out</span><span class="o">.</span><span class="n">tolist</span><span class="p">(),</span> <span class="n">x2_in</span><span class="o">.</span><span class="n">tolist</span><span class="p">()</span> <span class="o">+</span> <span class="n">x2_out</span><span class="o">.</span><span class="n">tolist</span><span class="p">()])</span>
<span class="n">y</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">asarray</span><span class="p">([</span><span class="n">np</span><span class="o">.</span><span class="n">where</span><span class="p">(</span><span class="n">y</span> <span class="o">&lt;</span> <span class="n">x1_in</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span> <span class="k">for</span> <span class="n">y</span> <span class="ow">in</span> <span class="n">np</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="n">x1_in</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">+</span> <span class="n">x1_out</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">])])</span>

<span class="n">plt</span><span class="o">.</span><span class="n">scatter</span><span class="p">(</span><span class="n">X</span><span class="p">[:</span><span class="n">x1_in</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="mi">0</span><span class="p">],</span> <span class="n">X</span><span class="p">[:</span><span class="n">x1_in</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="mi">1</span><span class="p">],</span> <span class="n">color</span> <span class="o">=</span> <span class="s">"red"</span><span class="p">,</span> <span class="n">marker</span> <span class="o">=</span> <span class="s">"o"</span><span class="p">,</span> <span class="n">label</span> <span class="o">=</span> <span class="s">"In"</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">scatter</span><span class="p">(</span><span class="n">X</span><span class="p">[</span><span class="n">x1_in</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]:,</span> <span class="mi">0</span><span class="p">],</span> <span class="n">X</span><span class="p">[</span><span class="n">x1_in</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]:,</span> <span class="mi">1</span><span class="p">],</span> <span class="n">color</span> <span class="o">=</span> <span class="s">"green"</span><span class="p">,</span> <span class="n">marker</span> <span class="o">=</span> <span class="s">"s"</span><span class="p">,</span> <span class="n">label</span> <span class="o">=</span> <span class="s">"Out"</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">axis</span><span class="p">(</span><span class="s">"scaled"</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">xlim</span><span class="p">(</span><span class="o">-</span><span class="mf">2.25</span><span class="p">,</span> <span class="mf">2.25</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">ylim</span><span class="p">(</span><span class="o">-</span><span class="mf">2.25</span><span class="p">,</span> <span class="mf">2.25</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s">"original $x_1$"</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s">"original $x_2$"</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">legend</span><span class="p">(</span><span class="n">loc</span> <span class="o">=</span> <span class="mi">1</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</code></pre></div></div>

<p><img src="/assets/images/transformacoes-nao-lineares_files/transformacoes-nao-lineares_4_0.png" alt="png" /></p>

<p>Nesse exemplo, pontos sorteados segundo uma distribuição $N(0, 1)$ para cada uma das coordenadas foram definidos como <code class="highlighter-rouge">In</code> $-$ caso o ponto esteja dentro da circunferência de raio $1$ $-$ ou <code class="highlighter-rouge">Out</code> $-$ caso o ponto esteja fora da circunferência de raio $1.2$ e dentro da circunferência de raio $2$. Obviamente, essas duas classes <strong>não</strong> são linearmente separáveis.</p>

<p>Assim, vamos aplicar uma transformação nos pontos de $\mathbf{x}$ tal que $\phi: (x_1, x_2) \rightarrow ({x_1}^2, {x_2}^2)$, para todo $\mathbf{x} \in \mathcal{D}$. Veja, agora, como os dados transformados podem ser representados:</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">X_transformed</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">power</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="mi">2</span><span class="p">)</span>

<span class="n">plt</span><span class="o">.</span><span class="n">scatter</span><span class="p">(</span><span class="n">X_transformed</span><span class="p">[:</span><span class="n">x1_in</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="mi">0</span><span class="p">],</span> <span class="n">X_transformed</span><span class="p">[:</span><span class="n">x1_in</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="mi">1</span><span class="p">],</span> <span class="n">color</span> <span class="o">=</span> <span class="s">"red"</span><span class="p">,</span> <span class="n">marker</span> <span class="o">=</span> <span class="s">"o"</span><span class="p">,</span> <span class="n">label</span> <span class="o">=</span> <span class="s">"In"</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">scatter</span><span class="p">(</span><span class="n">X_transformed</span><span class="p">[</span><span class="n">x1_in</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]:,</span> <span class="mi">0</span><span class="p">],</span> <span class="n">X_transformed</span><span class="p">[</span><span class="n">x1_in</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]:,</span> <span class="mi">1</span><span class="p">],</span> <span class="n">color</span> <span class="o">=</span> <span class="s">"green"</span><span class="p">,</span> <span class="n">marker</span> <span class="o">=</span> <span class="s">"s"</span><span class="p">,</span> <span class="n">label</span> <span class="o">=</span> <span class="s">"Out"</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">axis</span><span class="p">(</span><span class="s">"scaled"</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">xlim</span><span class="p">(</span><span class="o">-</span><span class="mf">0.25</span><span class="p">,</span> <span class="mf">4.25</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">ylim</span><span class="p">(</span><span class="o">-</span><span class="mf">0.25</span><span class="p">,</span> <span class="mf">4.25</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s">"transformed $x_1$"</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s">"transformed $x_2$"</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">legend</span><span class="p">(</span><span class="n">loc</span> <span class="o">=</span> <span class="mi">1</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</code></pre></div></div>

<p><img src="/assets/images/transformacoes-nao-lineares_files/transformacoes-nao-lineares_7_0.png" alt="png" /></p>

<p>Feita as transformação nos dados de acordo com a nossa função $\phi$, para todo $\mathcal{x} \in \mathcal{D}$ (nesse caso, por construção), o meu conjunto de pontos é linearmente separável. Sendo assim, posso aplicar, por exemplo, o Perceptron (utilizando o Sklearn $-$ caso queira ver a implementação completa do algoritmo, consulte a <a href="/implementacao-perceptron/">parte 02</a>):</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">from</span> <span class="nn">sklearn.linear_model</span> <span class="kn">import</span> <span class="n">Perceptron</span>

<span class="n">perceptron</span> <span class="o">=</span> <span class="n">Perceptron</span><span class="p">()</span>
<span class="n">perceptron</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_transformed</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span>

<span class="k">print</span><span class="p">(</span><span class="s">"Intercept weight: {}."</span><span class="o">.</span><span class="nb">format</span><span class="p">(</span><span class="n">perceptron</span><span class="o">.</span><span class="n">intercept_</span><span class="p">))</span>
<span class="k">print</span><span class="p">(</span><span class="s">"Weights vector: {}."</span><span class="o">.</span><span class="nb">format</span><span class="p">(</span><span class="n">perceptron</span><span class="o">.</span><span class="n">coef_</span><span class="p">))</span>
</code></pre></div></div>

<div class="highlighter-rouge"><div class="highlight"><pre class="highlight"><code>Intercept weight: [-2.].
Weights vector: [[2.36966542 1.48327095]].
</code></pre></div></div>

<p>De posse do modelo ajustado; i.e., do vetor $\mathbf{w}$ completamente definido, podemos plotar as regiões de decisão, utilizando a função <code class="highlighter-rouge">plot_decision_regions()</code> introduzida, pela primeira vez, na <a href="/implementacao-perceptron/">parte 02</a>.</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># modified function to admit data transformation
</span><span class="k">def</span> <span class="nf">plot_decision_regions</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">classifier</span><span class="p">,</span> <span class="n">feature_names</span><span class="p">,</span> <span class="n">modified</span> <span class="o">=</span> <span class="bp">False</span><span class="p">,</span> <span class="n">transf1</span> <span class="o">=</span> <span class="k">lambda</span> <span class="n">x</span><span class="p">:</span> <span class="n">x</span><span class="p">,</span> <span class="n">transf2</span> <span class="o">=</span> <span class="bp">None</span><span class="p">,</span> <span class="n">resolution</span> <span class="o">=</span> <span class="mf">0.01</span><span class="p">,</span> <span class="n">axis_lim</span> <span class="o">=</span> <span class="mi">1</span><span class="p">):</span>
    <span class="c1"># general settings
</span>    <span class="n">markers</span> <span class="o">=</span> <span class="p">[</span><span class="s">"o"</span><span class="p">,</span> <span class="s">"s"</span><span class="p">,</span> <span class="s">"*"</span><span class="p">,</span> <span class="s">"x"</span><span class="p">,</span> <span class="s">"v"</span><span class="p">]</span>
    <span class="n">colors</span>  <span class="o">=</span> <span class="p">(</span><span class="s">"red"</span><span class="p">,</span> <span class="s">"green"</span><span class="p">,</span> <span class="s">"blue"</span><span class="p">,</span> <span class="s">"gray"</span><span class="p">,</span> <span class="s">"cyan"</span><span class="p">)</span>
    <span class="n">x1_min</span><span class="p">,</span> <span class="n">x1_max</span> <span class="o">=</span> <span class="n">X</span><span class="p">[:,</span> <span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="nb">min</span><span class="p">()</span> <span class="o">-</span> <span class="n">axis_lim</span><span class="p">,</span> <span class="n">X</span><span class="p">[:,</span> <span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="nb">max</span><span class="p">()</span> <span class="o">+</span> <span class="n">axis_lim</span>
    <span class="n">x2_min</span><span class="p">,</span> <span class="n">x2_max</span> <span class="o">=</span> <span class="n">X</span><span class="p">[:,</span> <span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="nb">min</span><span class="p">()</span> <span class="o">-</span> <span class="n">axis_lim</span><span class="p">,</span> <span class="n">X</span><span class="p">[:,</span> <span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="nb">max</span><span class="p">()</span> <span class="o">+</span> <span class="n">axis_lim</span>
    <span class="c1"># define a grid
</span>    <span class="n">xx1</span><span class="p">,</span> <span class="n">xx2</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">meshgrid</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="n">x1_min</span><span class="p">,</span> <span class="n">x1_max</span><span class="p">,</span> <span class="n">resolution</span><span class="p">),</span>
                           <span class="n">np</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="n">x2_min</span><span class="p">,</span> <span class="n">x2_max</span><span class="p">,</span> <span class="n">resolution</span><span class="p">))</span>
    <span class="c1"># tranform the point that will be predicted, but NOT the one which will be plotted
</span>    <span class="k">if</span> <span class="n">modified</span><span class="p">:</span>
        <span class="k">if</span> <span class="n">transf2</span> <span class="o">==</span> <span class="bp">None</span><span class="p">:</span>
            <span class="n">transf2</span> <span class="o">=</span> <span class="n">transf1</span>
        <span class="n">xx1_mod</span> <span class="o">=</span> <span class="n">transf1</span><span class="p">(</span><span class="n">xx1</span><span class="p">)</span>
        <span class="n">xx2_mod</span> <span class="o">=</span> <span class="n">transf2</span><span class="p">(</span><span class="n">xx2</span><span class="p">)</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="n">xx1_mod</span> <span class="o">=</span> <span class="n">xx1</span>
        <span class="n">xx2_mod</span> <span class="o">=</span> <span class="n">xx2</span>      
    <span class="c1"># classify each grid point
</span>    <span class="n">result</span> <span class="o">=</span> <span class="n">classifier</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="n">xx1_mod</span><span class="o">.</span><span class="n">ravel</span><span class="p">(),</span> <span class="n">xx2_mod</span><span class="o">.</span><span class="n">ravel</span><span class="p">()])</span><span class="o">.</span><span class="n">T</span><span class="p">)</span>
    <span class="n">result</span> <span class="o">=</span> <span class="n">result</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="n">xx1_mod</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>
    <span class="c1"># make a plot
</span>    <span class="n">plt</span><span class="o">.</span><span class="n">contourf</span><span class="p">(</span><span class="n">xx1</span><span class="p">,</span> <span class="n">xx2</span><span class="p">,</span> <span class="n">result</span><span class="p">,</span> <span class="n">colors</span> <span class="o">=</span> <span class="n">colors</span><span class="p">[</span><span class="mi">0</span><span class="p">:</span><span class="nb">len</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">unique</span><span class="p">(</span><span class="n">y</span><span class="p">))],</span> <span class="n">alpha</span> <span class="o">=</span> <span class="mf">0.5</span><span class="p">)</span>
    <span class="k">for</span> <span class="n">index</span><span class="p">,</span> <span class="n">value</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">unique</span><span class="p">(</span><span class="n">y</span><span class="p">)):</span> <span class="c1"># plot each point &amp; 'enumerate()' returns index and value of the given array
</span>        <span class="n">plt</span><span class="o">.</span><span class="n">scatter</span><span class="p">(</span><span class="n">x</span> <span class="o">=</span> <span class="n">X</span><span class="p">[</span><span class="n">y</span> <span class="o">==</span> <span class="n">value</span><span class="p">,</span> <span class="mi">0</span><span class="p">],</span> <span class="n">y</span> <span class="o">=</span> <span class="n">X</span><span class="p">[</span><span class="n">y</span> <span class="o">==</span> <span class="n">value</span><span class="p">,</span> <span class="mi">1</span><span class="p">],</span> <span class="c1"># select each X and y vectors by creating a mask
</span>                    <span class="n">color</span> <span class="o">=</span> <span class="n">colors</span><span class="p">[</span><span class="n">index</span><span class="p">],</span>
                    <span class="n">marker</span> <span class="o">=</span> <span class="n">markers</span><span class="p">[</span><span class="n">index</span><span class="p">],</span>
                    <span class="n">label</span> <span class="o">=</span> <span class="n">feature_names</span><span class="p">[</span><span class="n">index</span><span class="p">],</span>
                    <span class="n">edgecolor</span> <span class="o">=</span> <span class="s">'black'</span><span class="p">)</span>
</code></pre></div></div>

<p>Perceba que a função foi levemente modificada para comportar dois novos parâmetros: <code class="highlighter-rouge">transf1</code> e <code class="highlighter-rouge">transf2</code> (além do <code class="highlighter-rouge">modified</code>, que é, apenas, uma tecnicalidade). Esses variáveis recebem uma função responsável pela transformação de cada uma das <em>features</em> do nosso conjunto de dados (por exemplo, uma transformação como a definida por $\phi(\mathbf{x})$). Mas antes de utilizarmos esse novo artifício, vamos ver como ficam as regiões de decisão para os dados transformados:</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">feature_names</span> <span class="o">=</span> <span class="p">[</span><span class="s">"In"</span><span class="p">,</span> <span class="s">"Out"</span><span class="p">]</span>
<span class="n">plot_decision_regions</span><span class="p">(</span><span class="n">X_transformed</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">perceptron</span><span class="p">,</span> <span class="n">feature_names</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="s">"Fitted model using transformed $X$"</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s">"Transformed $x_1$"</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s">"Transformed $x_2$"</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">axis</span><span class="p">(</span><span class="s">"scaled"</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">xlim</span><span class="p">(</span><span class="o">-</span><span class="mf">0.25</span><span class="p">,</span> <span class="mf">4.25</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">ylim</span><span class="p">(</span><span class="o">-</span><span class="mf">0.25</span><span class="p">,</span> <span class="mf">4.25</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">legend</span><span class="p">(</span><span class="n">loc</span> <span class="o">=</span> <span class="mi">1</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</code></pre></div></div>

<p><img src="/assets/images/transformacoes-nao-lineares_files/transformacoes-nao-lineares_13_0.png" alt="png" /></p>

<p>Por enquanto, nada de novo; como era de se esperar, os dados foram corretamente classificados e separados.</p>

<p>Agora o que podemos fazer (que é, de fato, a parte interessante) é contruir as regiões de decisão para os dados <strong>originais</strong>; nesse caso, utilizaremos os parâmetros <code class="highlighter-rouge">transf1</code> e <code class="highlighter-rouge">transf2</code> passando, como argumento, a função <code class="highlighter-rouge">lambda: x: x ** 2</code> $-$ ou seja, do mesmo modo que definimos $\phi$. Veja:</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">feature_names</span> <span class="o">=</span> <span class="p">[</span><span class="s">"In"</span><span class="p">,</span> <span class="s">"Out"</span><span class="p">]</span>
<span class="n">plot_decision_regions</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">perceptron</span><span class="p">,</span> <span class="n">feature_names</span><span class="p">,</span> <span class="bp">True</span><span class="p">,</span> <span class="k">lambda</span> <span class="n">x</span><span class="p">:</span> <span class="n">np</span><span class="o">.</span><span class="n">power</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="mi">2</span><span class="p">))</span>
<span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="s">"Fitted model using original $X$"</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s">"Original $x_1$"</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s">"Original $x_2$"</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">axis</span><span class="p">(</span><span class="s">"scaled"</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">xlim</span><span class="p">(</span><span class="o">-</span><span class="mf">2.25</span><span class="p">,</span> <span class="mf">2.25</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">ylim</span><span class="p">(</span><span class="o">-</span><span class="mf">2.25</span><span class="p">,</span> <span class="mf">2.25</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">legend</span><span class="p">(</span><span class="n">loc</span> <span class="o">=</span> <span class="mi">1</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</code></pre></div></div>

<p><img src="/assets/images/transformacoes-nao-lineares_files/transformacoes-nao-lineares_15_0.png" alt="png" /></p>

<p>Tomando esse tipo de estratégia, nós conseguimos, como pode ser visto acima, classificar dois grupos de pontos que, à princípio, não eram linearmente separáveis.</p>

<h3 id="regressão">Regressão</h3>

<p>Agora, nesse segundo exemplo, vamos estudar um problema de regressão. Para isso, considere o seguinte cenário: suponha que as informações “salário” e “felicidade” (para alguma medida arbitrária que captura esse sentimento) foram coletadas a partir de um grupo de $100$ indivíduos; suponha, ainda, que o salário dessas pessoas segue distribuição $\text{Gamma}(2, 5000)$ (para uma distribuição desse tipo, temos média $10\times 10^3$ e assimetria à direita) $-$ veja o histograma a seguir.</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">rn</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">RandomState</span><span class="p">(</span><span class="mi">1</span><span class="p">)</span>
<span class="n">X</span>  <span class="o">=</span> <span class="n">rn</span><span class="o">.</span><span class="n">gamma</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="mi">5000</span><span class="p">,</span> <span class="mi">100</span><span class="p">)</span>
<span class="n">X</span>  <span class="o">=</span> <span class="n">X</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="mi">100</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">hist</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">color</span> <span class="o">=</span> <span class="s">"red"</span><span class="p">,</span> <span class="n">alpha</span> <span class="o">=</span> <span class="mf">0.5</span><span class="p">,</span> <span class="n">bins</span> <span class="o">=</span> <span class="mi">10</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s">"Salary (</span><span class="err">\</span><span class="s">$)"</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s">"Frequency"</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">xticks</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mf">45e3</span><span class="p">,</span> <span class="mf">5e3</span><span class="p">))</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</code></pre></div></div>

<p><img src="/assets/images/transformacoes-nao-lineares_files/transformacoes-nao-lineares_19_0.png" alt="png" /></p>

<p>Assim, temos vários indivíduos que ganham salários em torno dos dez mil reais, e alguns outros poucos trabalhadores que ganham quantias muito maiores do que essa.</p>

<p>Agora, suponha que a “felicidade” depende do “salário”, mas essa relação não é linear; ou seja, depois de uma determinada quantidade de dinheiro, receber mais não se traduz em ser proporcionalmente mais feliz. Podemos representar essa dependência através da função $\log(\cdot)$.</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">y</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">log</span><span class="p">(</span><span class="n">X</span><span class="p">)</span> <span class="o">+</span> <span class="n">rn</span><span class="o">.</span><span class="n">normal</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mf">0.2</span><span class="p">,</span> <span class="mi">100</span><span class="p">)</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="mi">100</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">scatter</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">marker</span> <span class="o">=</span> <span class="s">"o"</span><span class="p">,</span> <span class="n">color</span> <span class="o">=</span> <span class="s">"red"</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="s">"Salary (</span><span class="err">\</span><span class="s">$) vs. Happiness"</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s">"Salary (</span><span class="err">\</span><span class="s">$)"</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s">"Happiness measure"</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">xticks</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mf">45e3</span><span class="p">,</span> <span class="mf">5e3</span><span class="p">))</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</code></pre></div></div>

<p><img src="/assets/images/transformacoes-nao-lineares_files/transformacoes-nao-lineares_22_0.png" alt="png" /></p>

<p>No código acima, perceba perceba que a “felicidade”, como função do “salário”, foi somada a valores que vêm de uma distruição $N(0, 0.04)$ $-$ esse termo será denominado por “ruído” ($\epsilon$), e refere-se à diferença entre os valores observado e <strong>real</strong> (não observável) da variável dependente. Lembre-se de que, quando falamos de regressão linear, estamos interessados em estudar um modelo do tipo: $y = w_0 + w_1 x_1 + \cdots + w_d x_d + \epsilon$.</p>

<p>Visualmente (e por construção, nesse caso), a relação descrita acima <strong>não</strong> é linear; nesse caso, faz sentido aplicarmos alguma transformação na variável independente.</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">X_transformed</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">log</span><span class="p">(</span><span class="n">X</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">scatter</span><span class="p">(</span><span class="n">X_transformed</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">marker</span> <span class="o">=</span> <span class="s">"s"</span><span class="p">,</span> <span class="n">color</span> <span class="o">=</span> <span class="s">"green"</span><span class="p">,</span> <span class="n">alpha</span> <span class="o">=</span> <span class="mf">0.75</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="s">"Transformed Salary ($</span><span class="err">\</span><span class="s">log$ of </span><span class="err">\</span><span class="s">$) vs. Happiness"</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s">"Transformed Salary ($</span><span class="err">\</span><span class="s">log$ of </span><span class="err">\</span><span class="s">$)"</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s">"Happiness measure"</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</code></pre></div></div>

<p><img src="/assets/images/transformacoes-nao-lineares_files/transformacoes-nao-lineares_25_0.png" alt="png" /></p>

<p>Note que, aplicando $\log(\cdot)$ em $x$, obtemos algo que se aproxima mais de uma relação linear. Nesse caso, podemos ajustar o modelo de regressão (utilizando o Sklearn $-$ caso queira ver a implementação completa do algoritmo, consulte a <a href="/modelo-de-regressao-linear/">parte 05</a>). Primeiro, ajustaremos o modelo considerando $x$ e, depois, considerando $\log(x)$.</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">from</span> <span class="nn">sklearn.linear_model</span> <span class="kn">import</span> <span class="n">LinearRegression</span>

<span class="n">regression_original</span> <span class="o">=</span> <span class="n">LinearRegression</span><span class="p">()</span>
<span class="n">regression_original</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span>

<span class="n">x_min</span> <span class="o">=</span> <span class="n">X</span><span class="p">[:,</span> <span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="nb">min</span><span class="p">()</span>
<span class="n">x_max</span> <span class="o">=</span> <span class="n">X</span><span class="p">[:,</span> <span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="nb">max</span><span class="p">()</span>
<span class="n">x_values</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="n">x_min</span><span class="p">,</span> <span class="n">x_max</span><span class="p">,</span> <span class="mi">100</span><span class="p">)</span>
<span class="n">y_values</span> <span class="o">=</span> <span class="n">regression_original</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">asarray</span><span class="p">(</span><span class="n">x_values</span><span class="p">)</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">x_values</span><span class="p">),</span> <span class="mi">1</span><span class="p">))</span>
<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">x_values</span><span class="p">,</span> <span class="n">y_values</span><span class="p">,</span> <span class="n">color</span> <span class="o">=</span> <span class="s">"darkred"</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">scatter</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">marker</span> <span class="o">=</span> <span class="s">"o"</span><span class="p">,</span> <span class="n">color</span> <span class="o">=</span> <span class="s">"red"</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="s">"Fitted Regression for Salary"</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s">"Salary (</span><span class="err">\</span><span class="s">$)"</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s">"Happiness measure"</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">xticks</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mf">45e3</span><span class="p">,</span> <span class="mf">5e3</span><span class="p">))</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</code></pre></div></div>

<p><img src="/assets/images/transformacoes-nao-lineares_files/transformacoes-nao-lineares_27_0.png" alt="png" /></p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">regression_transformed</span> <span class="o">=</span> <span class="n">LinearRegression</span><span class="p">()</span>
<span class="n">regression_transformed</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_transformed</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span>

<span class="n">x_min</span> <span class="o">=</span> <span class="n">X_transformed</span><span class="p">[:,</span> <span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="nb">min</span><span class="p">()</span>
<span class="n">x_max</span> <span class="o">=</span> <span class="n">X_transformed</span><span class="p">[:,</span> <span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="nb">max</span><span class="p">()</span>
<span class="n">x_values</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="n">x_min</span><span class="p">,</span> <span class="n">x_max</span><span class="p">,</span> <span class="mf">0.01</span><span class="p">)</span>
<span class="n">y_values</span> <span class="o">=</span> <span class="n">regression_transformed</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">asarray</span><span class="p">(</span><span class="n">x_values</span><span class="p">)</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">x_values</span><span class="p">),</span> <span class="mi">1</span><span class="p">))</span>
<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">x_values</span><span class="p">,</span> <span class="n">y_values</span><span class="p">,</span> <span class="n">color</span> <span class="o">=</span> <span class="s">"darkgreen"</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">scatter</span><span class="p">(</span><span class="n">X_transformed</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">marker</span> <span class="o">=</span> <span class="s">"s"</span><span class="p">,</span> <span class="n">color</span> <span class="o">=</span> <span class="s">"green"</span><span class="p">,</span> <span class="n">alpha</span> <span class="o">=</span> <span class="mf">0.75</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="s">"Fitted regression for $</span><span class="err">\</span><span class="s">log$ of Salary"</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s">"Transformed Salary ($</span><span class="err">\</span><span class="s">log$ of </span><span class="err">\</span><span class="s">$)"</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s">"Happiness measure"</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</code></pre></div></div>

<p><img src="/assets/images/transformacoes-nao-lineares_files/transformacoes-nao-lineares_28_0.png" alt="png" /></p>

<p>Perceba que o primeiro modelo ajustado, com a variável $x$ original (indicado pelo gráfico de título <code class="highlighter-rouge">Fitted Regression for Salary</code>) não representa bem o conjunto de dados (no próximo parágrafo, vamos analisar isso quantitativamente). Ao passo que, quando transformamos $x$, aplicando, nesse caso, a função $\log(\cdot)$, obtemos uma reta (visualmente) melhor ajustada.</p>

<p>Uma medida que podemos utilizar para quantificar a intuição de “qual modelo se ajusta melhor aos dados” é a quantidade $R^2$ (R-squared); que, a grosso modo, diz o quanto da variação de $y$ é explicada pela regressão. Vamos aproveitar a função <code class="highlighter-rouge">score()</code> implementada na classe <code class="highlighter-rouge">LinearRegression</code> para obter essa medida.</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">r2_original</span> <span class="o">=</span> <span class="n">regression_original</span><span class="o">.</span><span class="n">score</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span>
<span class="k">print</span><span class="p">(</span><span class="s">"R-squared for the original model: {}."</span><span class="o">.</span><span class="nb">format</span><span class="p">(</span><span class="n">r2_original</span><span class="p">))</span>
<span class="k">print</span><span class="p">(</span><span class="s">"Intercept: {} &amp; Coefficients: {}."</span><span class="o">.</span><span class="nb">format</span><span class="p">(</span><span class="n">regression_original</span><span class="o">.</span><span class="n">intercept_</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">regression_original</span><span class="o">.</span><span class="n">coef_</span><span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">]))</span>
</code></pre></div></div>

<div class="highlighter-rouge"><div class="highlight"><pre class="highlight"><code>R-squared for the original model: 0.7538771643539155.
Intercept: 7.975309624979791 &amp; Coefficients: 9.828555226466561e-05.
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">r2_transformed</span> <span class="o">=</span> <span class="n">regression_transformed</span><span class="o">.</span><span class="n">score</span><span class="p">(</span><span class="n">X_transformed</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span>
<span class="k">print</span><span class="p">(</span><span class="s">"R-squared for the 'tranformed' model: {}."</span><span class="o">.</span><span class="nb">format</span><span class="p">(</span><span class="n">r2_transformed</span><span class="p">))</span>
<span class="k">print</span><span class="p">(</span><span class="s">"Intercept: {} &amp; Coefficients: {}."</span><span class="o">.</span><span class="nb">format</span><span class="p">(</span><span class="n">regression_transformed</span><span class="o">.</span><span class="n">intercept_</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">regression_transformed</span><span class="o">.</span><span class="n">coef_</span><span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">]))</span>
</code></pre></div></div>

<div class="highlighter-rouge"><div class="highlight"><pre class="highlight"><code>R-squared for the 'tranformed' model: 0.9431020022916391.
Intercept: 0.12929691342341698 &amp; Coefficients: 0.9867610189477893.
</code></pre></div></div>

<p>Mais uma vez, o primeiro resultado diz respeito ao modelo que considera $x$, enquanto que o segundo, ao modelo que considera $\log(x)$ como variável independente. Perceba que, quando aplicamos a tranformação no nosso preditor “salário”, obtemos um $R^2$ maior $-$ que é, <strong>quase</strong> sempre, melhor.</p>

<p>Um ponto importante é como devemos interpretar, quando olhamos para o segundo modelo, o coeficiente que obtemos; aqui, $w_1 \approx 0.987$. Nesse caso, podemos dizer que $1\%$ de aumento do salário, resulta em aumento de, aproximadamente, $\frac{0.987}{100} = 0.00987$ “<em>unidades</em> de felicidade”.</p>

<h2 id="conclusão">Conclusão</h2>

<p>No começo do texto vimos que, para aplicar os modelos lineares que estudamos até agora (seja de classificação, seja de regressão), basta que, olhando para a expressão $\sum_{i = 0}^{d} w_i x_i$, os $w_i$’s sejam lineares; ou seja, podemos aplicar transformações não-lineares no conjunto de dados $X$. Nesse sentido, vimos dois exemplos (implementados em Python), nos quais transformações do tipo $(\cdot)^2$ e $\log(\cdot)$ foram aplicadas. No próximo post vamos falar um pouco mais sobre medidas de erro.</p>

<p>Qualquer dúvida, sugestão ou <em>feedback</em>, por favor, deixe um comentário abaixo.</p>

<blockquote>
  <p>Essa postagem faz parte de uma <a href="/categorias/#machine-learning-learning-from-data">série</a> de textos que tem o objetivo de estudar, principalmente, o curso “<a href="http://www.work.caltech.edu/telecourse.html">Learning from Data</a>”, ministrado pelo Professor Yaser Abu-Mostafa. Outros materiais utilizados serão sempre referenciados.</p>
</blockquote>

        
      </section>

      <footer class="page__meta">
        
        


        
          <p class="page__date"><strong><i class="fas fa-fw fa-calendar-alt" aria-hidden="true"></i> Atualizado em:</strong> <time datetime="2020-01-16T00:00:00-03:00">January 16, 2020</time></p>
        
      </footer>

      

      
  <nav class="pagination">
    
      <a href="/modelo-de-regressao-linear/" class="pagination--pager" title="[Parte 05] Modelo de Regressão Linear &amp; Implementação em Python
">Anterior</a>
    
    
      <a href="/erro-e-ruido/" class="pagination--pager" title="[Parte 07] Erro e Ruído
">Próxima</a>
    
  </nav>

    </div>

    
      <div class="page__comments">
  
  
      <h4 class="page__comments-title">Deixe um comentário</h4>
      <section id="disqus_thread"></section>
    
</div>

    
  </article>

  
  
    <div class="page__related">
      <h4 class="page__related-title">Talvez você também goste</h4>
      <div class="grid__wrapper">
        
          



<div class="grid__item">
  <article class="archive__item" itemscope itemtype="https://schema.org/CreativeWork">
    
    <h2 class="archive__item-title" itemprop="headline">
      
        <a href="/vies-variancia-tradeoff/" rel="permalink">[Parte 10] Trade-off entre Viés-Variância
</a>
      
    </h2>
    
      <p class="page__meta"><i class="far fa-clock" aria-hidden="true"></i> 




  9 minuto(s) de leitura

</p>
    
    <p class="archive__item-excerpt" itemprop="description">Continuando com a discussão, introduzida na parte 09 dessa série de textos, de que deve existir um “meio termo” sobre o tamanho de $\mathcal{H}$ $-$ lembre-se: se $\mathcal{H}$ é muito grande, conseguimos diminuir o termo $E_{in}$; porém, somos penalizados na generalização do modelo para dados fora de $\mathcal{D}$....</p>
  </article>
</div>

        
          



<div class="grid__item">
  <article class="archive__item" itemscope itemtype="https://schema.org/CreativeWork">
    
    <h2 class="archive__item-title" itemprop="headline">
      
        <a href="/dimensao-vc/" rel="permalink">[Parte 09] Dimensão de Vapnik-Chervonenkis
</a>
      
    </h2>
    
      <p class="page__meta"><i class="far fa-clock" aria-hidden="true"></i> 




  9 minuto(s) de leitura

</p>
    
    <p class="archive__item-excerpt" itemprop="description">Continuando a discussão que começamos na última parte da nossa série de textos, vamos estudar mais propriedades associadas ao que demos o nome de “Teoria da Generalização”; ou, em outras palavras, ao estudo de como os nossos modelos podem ser generalizados para conjuntos de dados fora de $\mathcal{D}$.
</p>
  </article>
</div>

        
          



<div class="grid__item">
  <article class="archive__item" itemscope itemtype="https://schema.org/CreativeWork">
    
    <h2 class="archive__item-title" itemprop="headline">
      
        <a href="/teoria-da-generalizacao/" rel="permalink">[Parte 08] Teoria da Generalização
</a>
      
    </h2>
    
      <p class="page__meta"><i class="far fa-clock" aria-hidden="true"></i> 




  9 minuto(s) de leitura

</p>
    
    <p class="archive__item-excerpt" itemprop="description">Ao longo dessa e da próxima postagem da nossa série de textos, vamos estabelecer e estudar a distinção que tem que existir entre o conjunto de dados utilizados para treinar o nosso modelo, e o conjunto de dados utilizado para testá-lo.
</p>
  </article>
</div>

        
          



<div class="grid__item">
  <article class="archive__item" itemscope itemtype="https://schema.org/CreativeWork">
    
    <h2 class="archive__item-title" itemprop="headline">
      
        <a href="/erro-e-ruido/" rel="permalink">[Parte 07] Erro e Ruído
</a>
      
    </h2>
    
      <p class="page__meta"><i class="far fa-clock" aria-hidden="true"></i> 




  6 minuto(s) de leitura

</p>
    
    <p class="archive__item-excerpt" itemprop="description">Formalizando alguns conceitos sobre os quais já falamos ao longo dessa série de textos, essa postagem será dedicada à discussão de: 1) Como quantificar o quão bem a hipótese final $g \in \mathcal{H}$ se aproxima da função alvo $f$? 2) Como lidar com o “ruído” associado à $f$?
</p>
  </article>
</div>

        
      </div>
    </div>
  
  
</div>

    </div>

    

    <div id="footer" class="page__footer">
      <footer>
        <!-- start custom footer snippets -->

<!-- end custom footer snippets -->
        <div class="page__footer-follow">
  <ul class="social-icons">
    
      <li><strong>Informações:</strong></li>
    

    
      
        
          <li><a href="https://github.com/avramaral" rel="nofollow noopener noreferrer"><i class="fab fa-fw fa-github" aria-hidden="true"></i> GitHub</a></li>
        
      
        
          <li><a href="https://twitter.com/avramaral" rel="nofollow noopener noreferrer"><i class="fab fa-fw fa-twitter" aria-hidden="true"></i> Twitter</a></li>
        
      
        
          <li><a href="https://www.linkedin.com/in/andre-victor-ribeiro-amaral/" rel="nofollow noopener noreferrer"><i class="fab fa-fw fa-linkedin-in" aria-hidden="true"></i> LinkedIn</a></li>
        
      
        
          <li><a href="https://www.youtube.com/channel/UC5RVscKF68DWYixtJPrBccQ" rel="nofollow noopener noreferrer"><i class="fab fa-fw fa-youtube" aria-hidden="true"></i> YouTube</a></li>
        
      
    

    
  </ul>
</div>

<div class="page__footer-copyright">&copy; 2020 André. Desenvolvido com <a href="https://jekyllrb.com" rel="nofollow">Jekyll</a> &amp; <a href="https://mademistakes.com/work/minimal-mistakes-jekyll-theme/" rel="nofollow">Minimal Mistakes</a>.</div>

      </footer>
    </div>

    
  <script src="/assets/js/main.min.js"></script>
  <script src="https://kit.fontawesome.com/4eee35f757.js"></script>







    
  <script>
    var disqus_config = function () {
      this.page.url = "http://localhost:4000/transformacoes-nao-lineares/";  // Replace PAGE_URL with your page's canonical URL variable
      this.page.identifier = "/transformacoes-nao-lineares"; // Replace PAGE_IDENTIFIER with your page's unique identifier variable
    };
    (function() { // DON'T EDIT BELOW THIS LINE
      var d = document, s = d.createElement('script');
      s.src = 'https://blog-do-andre.disqus.com/embed.js';
      s.setAttribute('data-timestamp', +new Date());
      (d.head || d.body).appendChild(s);
    })();
  </script>
<noscript>Please enable JavaScript to view the <a href="https://disqus.com/?ref_noscript">comments powered by Disqus.</a></noscript>


  





    <script src="https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML" type="text/javascript"></script>

  </body>
</html>
